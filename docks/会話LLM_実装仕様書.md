
```markdown
# ä¼šè©±LLM_IMPLEMENTATION.md
## â€• äººé–“ã‚‰ã—ã„å¯¾è©±ã‚’å®Ÿç¾ã™ã‚‹ãƒãƒ«ãƒLLMä¼šè©±ã‚·ã‚¹ãƒ†ãƒ  å®Ÿè£…ä»•æ§˜æ›¸ â€•
ï¼ˆLangGraph / Ollama / Serper API / Neo4jï¼‰

**ãƒãƒ¼ã‚¸ãƒ§ãƒ³ 3.0.0** - æ„Ÿæƒ…ãƒ»è¨˜æ†¶ãƒ»æˆé•·ã‚’æŒã¤AIå¯¾è©±ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼

---

## 1. å®Ÿè£…ç›®çš„

æœ¬ä»•æ§˜æ›¸ã¯ã€Œä¼šè©±LLM_ä»•æ§˜.mdï¼ˆv3.0ï¼‰ã€ã§å®šç¾©ã•ã‚ŒãŸ
**äººé–“ã‚‰ã—ã„å¯¾è©±ã‚’å®Ÿç¾ã™ã‚‹ãƒãƒ«ãƒLLMä¼šè©±ã‚·ã‚¹ãƒ†ãƒ **ã®
**å®Ÿè£…æ§‹æˆãƒ»ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä»•æ§˜ãƒ»è¨­å®šé …ç›®ãƒ»æ–°æ©Ÿèƒ½ã®å®Ÿè£…æ–¹æ³•**ã‚’è¨˜è¿°ã™ã‚‹ã€‚

### v3.0ã®ä¸»ãªè¿½åŠ å®Ÿè£…

1. **æ„Ÿæƒ…ãƒ¢ãƒ‡ãƒ«** - Plutchikã®8åŸºæœ¬æ„Ÿæƒ…
2. **é€£æƒ³è¨˜æ†¶** - Neo4jã‚°ãƒ©ãƒ•DBã«ã‚ˆã‚‹æ¦‚å¿µãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
3. **è‡ªå·±çœå¯Ÿ** - ãƒ¡ã‚¿èªçŸ¥ã‚·ã‚¹ãƒ†ãƒ 
4. **é©å¿œçš„å¯¾è©±** - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«æœ€é©åŒ–
5. **è¨˜æ†¶ã®é‡è¦åº¦åˆ¤å®š** - æ„Ÿæƒ…ãƒ»æ–°è¦æ€§ãƒ™ãƒ¼ã‚¹
6. **å¯¾è©±ã®ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯** - çŸ›ç›¾æ¤œå‡º
7. **ãƒšãƒ«ã‚½ãƒŠä¸€è²«æ€§** - ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ç¶­æŒ
8. **è‡ªç„¶ãªã‚¿ã‚¤ãƒŸãƒ³ã‚°** - äººé–“ã‚‰ã—ã„å¾…ã¡æ™‚é–“

---

## 2. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹æˆï¼ˆv3.0æ‹¡å¼µç‰ˆï¼‰

```
Llm_Multi_Chat/
â”œâ”€â”€ main.py                       # ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
â”œâ”€â”€ config.py                     # è¨­å®šãƒ»ç’°å¢ƒå¤‰æ•°ç®¡ç†ï¼ˆæ‹¡å¼µæ€§è€ƒæ…®ï¼‰
â”œâ”€â”€ conversation_state.py         # ä¼šè©±çŠ¶æ…‹ãƒ»å±¥æ­´ç®¡ç†
â”œâ”€â”€ llm_nodes.py                  # å„ã‚­ãƒ£ãƒ©LLMãƒãƒ¼ãƒ‰å‡¦ç†
â”œâ”€â”€ utils.py                      # ãƒ­ã‚°ãƒ»ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ»æ¤œè¨¼
â”œâ”€â”€ check_system.py               # ã‚·ã‚¹ãƒ†ãƒ è¨ºæ–­
â”œâ”€â”€ requirements.txt              # ä¾å­˜é–¢ä¿‚
â”œâ”€â”€ env_example.txt               # ç’°å¢ƒå¤‰æ•°ä¾‹
â”‚
â”œâ”€â”€ core/                         # v3.0 ã‚³ã‚¢ã‚·ã‚¹ãƒ†ãƒ 
â”‚   â”œâ”€â”€ emotional_state.py        # æ„Ÿæƒ…ãƒ¢ãƒ‡ãƒ«
â”‚   â”œâ”€â”€ associative_memory.py     # é€£æƒ³è¨˜æ†¶
â”‚   â”œâ”€â”€ self_reflection.py        # è‡ªå·±çœå¯Ÿ
â”‚   â”œâ”€â”€ dialogue_coherence.py     # å¯¾è©±ä¸€è²«æ€§
â”‚   â”œâ”€â”€ persona_consistency.py    # ãƒšãƒ«ã‚½ãƒŠç¶­æŒ
â”‚   â”œâ”€â”€ adaptive_style.py         # é©å¿œçš„å¯¾è©±ã‚¹ã‚¿ã‚¤ãƒ«
â”‚   â”œâ”€â”€ memory_salience.py        # è¨˜æ†¶é‡è¦åº¦åˆ¤å®š
â”‚   â”œâ”€â”€ topic_tracker.py          # ãƒˆãƒ”ãƒƒã‚¯è¿½è·¡
â”‚   â”œâ”€â”€ natural_pacing.py         # è‡ªç„¶ãªã‚¿ã‚¤ãƒŸãƒ³ã‚°
â”‚   â””â”€â”€ plugin_manager.py         # ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ãƒãƒãƒ¼ã‚¸ãƒ£ï¼ˆPhase 3ï¼‰
â”‚
â”œâ”€â”€ personas/                     # å„ã‚­ãƒ£ãƒ©ã®è¨­å®šYAML
â”œâ”€â”€ adapters/                     # LoRA / Adapteræ ¼ç´
â”œâ”€â”€ kb/                           # çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ETLã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”œâ”€â”€ memory/                       # è¨˜æ†¶ç®¡ç†
â”‚   â”œâ”€â”€ short_term.py             # çŸ­æœŸè¨˜æ†¶
â”‚   â”œâ”€â”€ mid_term.py               # ä¸­æœŸè¨˜æ†¶ï¼ˆRedis/DuckDBï¼‰
â”‚   â”œâ”€â”€ long_term.py              # é•·æœŸè¨˜æ†¶ï¼ˆVectorDB/SQLï¼‰
â”‚   â”œâ”€â”€ knowledge_base.py         # çŸ¥è­˜ãƒ™ãƒ¼ã‚¹
â”‚   â””â”€â”€ association_visualization.py  # 3Då¯è¦–åŒ–ï¼ˆv3.0ï¼‰
â”‚
â”œâ”€â”€ security/                     # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å±¤ï¼ˆPhase 2ï¼‰
â”‚   â”œâ”€â”€ auth.py                   # èªè¨¼ãƒ»èªå¯
â”‚   â”œâ”€â”€ encryption.py             # ãƒ‡ãƒ¼ã‚¿æš—å·åŒ–
â”‚   â””â”€â”€ audit_log.py              # ç›£æŸ»ãƒ­ã‚°
â”‚
â”œâ”€â”€ api/                          # REST/WebSocket APIï¼ˆPhase 3ï¼‰
â”‚   â”œâ”€â”€ routes.py                 # ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå®šç¾©
â”‚   â”œâ”€â”€ middleware.py             # èªè¨¼ãƒ»ãƒ¬ãƒ¼ãƒˆåˆ¶é™
â”‚   â””â”€â”€ websocket.py              # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€šä¿¡
â”‚
â”œâ”€â”€ plugins/                      # ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ï¼ˆPhase 3ï¼‰
â”‚   â”œâ”€â”€ base.py                   # ãƒ—ãƒ©ã‚°ã‚¤ãƒ³åŸºåº•ã‚¯ãƒ©ã‚¹
â”‚   â”œâ”€â”€ weather.py                # å¤©æ°—ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ä¾‹
â”‚   â””â”€â”€ translate.py              # ç¿»è¨³ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ä¾‹
â”‚
â”œâ”€â”€ tests/                        # ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆï¼ˆPhase 2ï¼‰
â”‚   â”œâ”€â”€ unit/                     # ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ
â”‚   â”œâ”€â”€ integration/              # çµ±åˆãƒ†ã‚¹ãƒˆ
â”‚   â””â”€â”€ performance/              # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
â”‚
â”œâ”€â”€ static/                       # é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆHTML/CSS/JSï¼‰
â”‚   â”œâ”€â”€ css/                      # ã‚¹ã‚¿ã‚¤ãƒ«ã‚·ãƒ¼ãƒˆ
â”‚   â”œâ”€â”€ js/                       # JavaScript
â”‚   â””â”€â”€ templates/                # HTMLãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
â”‚
â””â”€â”€ README.md


---

## 2.1 æ‹¡å¼µæ€§ã‚’è€ƒæ…®ã—ãŸåˆæ‰‹è¨­è¨ˆãƒ‘ã‚¿ãƒ¼ãƒ³

**æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯: Python + HTML + CSS**

### 2.1.1 ãƒ—ãƒ©ã‚°ã‚¤ãƒ³å‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

**Phase 1ã‹ã‚‰å®Ÿè£…**

```python
# core/plugin_manager.py
class PluginInterface:
    """ãƒ—ãƒ©ã‚°ã‚¤ãƒ³åŸºåº•ã‚¯ãƒ©ã‚¹ï¼ˆåˆæ‰‹ã‹ã‚‰å®šç¾©ï¼‰"""
    
    def on_message(self, message: str, context: dict) -> Optional[dict]:
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å—ä¿¡æ™‚ã®ãƒ•ãƒƒã‚¯"""
        pass
    
    def on_response(self, response: str, context: dict) -> str:
        """å¿œç­”ç”Ÿæˆå¾Œã®ãƒ•ãƒƒã‚¯"""
        return response
    
    def on_memory_store(self, memory: dict) -> dict:
        """è¨˜æ†¶ä¿å­˜å‰ã®ãƒ•ãƒƒã‚¯"""
        return memory

class PluginManager:
    """ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ãƒãƒãƒ¼ã‚¸ãƒ£ï¼ˆPhase 1ã‹ã‚‰çµ„ã¿è¾¼ã¿ï¼‰"""
    
    def __init__(self):
        self.plugins: List[PluginInterface] = []
    
    def register(self, plugin: PluginInterface):
        """ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ç™»éŒ²ï¼ˆå‹•çš„ãƒ­ãƒ¼ãƒ‰å¯¾å¿œï¼‰"""
        self.plugins.append(plugin)
    
    def trigger(self, hook: str, *args, **kwargs):
        """å…¨ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã®ãƒ•ãƒƒã‚¯ã‚’å®Ÿè¡Œ"""
        for plugin in self.plugins:
            method = getattr(plugin, hook, None)
            if method:
                result = method(*args, **kwargs)
                if result is not None:
                    return result
```

**Phase 3ã§è¿½åŠ å®Ÿè£…:**
```python
# plugins/weather.pyï¼ˆPhase 3ã§è¿½åŠ ï¼‰
class WeatherPlugin(PluginInterface):
    def on_message(self, message, context):
        if "å¤©æ°—" in message:
            return {"action": "weather_api", "location": "Tokyo"}
```

---

### 2.1.2 è¨­å®šãƒ™ãƒ¼ã‚¹æ‹¡å¼µï¼ˆconfig.pyï¼‰

**Phase 1ã‹ã‚‰å®Ÿè£…**

```python
# config.py
class Config:
    """ç’°å¢ƒå¤‰æ•°+YAMLè¨­å®šã®çµ±åˆç®¡ç†ï¼ˆæ‹¡å¼µæ€§è€ƒæ…®ï¼‰"""
    
    def __init__(self):
        # Phase 1: åŸºæœ¬è¨­å®š
        self.load_env()
        self.load_yaml()
        
        # Phase 2ä»¥é™ã®æ‹¡å¼µãƒã‚¤ãƒ³ãƒˆï¼ˆåˆæ‰‹ã‹ã‚‰å®šç¾©ï¼‰
        self.security = SecurityConfig()  # Phase 2ã§å®Ÿè£…
        self.api = APIConfig()             # Phase 3ã§å®Ÿè£…
        self.plugins = []                  # Phase 3ã§å®Ÿè£…
    
    def load_yaml(self, path="config.yaml"):
        """YAMLè¨­å®šã®å‹•çš„èª­ã¿è¾¼ã¿"""
        with open(path) as f:
            config = yaml.safe_load(f)
            self._merge_config(config)

class SecurityConfig:
    """Phase 2ã§å®Ÿè£…ã™ã‚‹ãŒã€Phase 1ã‹ã‚‰æ§‹é€ å®šç¾©"""
    def __init__(self):
        self.encryption_enabled = False  # Phase 1: OFF
        self.auth_enabled = False        # Phase 2: ON
        self.jwt_secret = None           # Phase 2ã§è¨­å®š
```

**config.yamlï¼ˆPhase 1ã‹ã‚‰æ‹¡å¼µå¯èƒ½ï¼‰**
```yaml
# Phase 1è¨­å®š
ollama:
  host: "http://localhost:11434"
  models:
    fast: "llama3-jp-8b"

# Phase 2ã§è¿½åŠ ï¼ˆåˆæ‰‹ã‹ã‚‰å®šç¾©å¯èƒ½ï¼‰
security:
  encryption: false  # Phase 2ã§true
  auth: false        # Phase 2ã§true

# Phase 3ã§è¿½åŠ 
api:
  enabled: false     # Phase 3ã§true
  rate_limit: 100
```

---

### 2.1.3 ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ†é›¢è¨­è¨ˆ

**Phase 1ã‹ã‚‰å®Ÿè£…**

```python
# memory/base.pyï¼ˆPhase 1ã‹ã‚‰æŠ½è±¡åŒ–ï¼‰
class MemoryBackend(ABC):
    """è¨˜æ†¶ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®æŠ½è±¡åŸºåº•ã‚¯ãƒ©ã‚¹"""
    
    @abstractmethod
    def store(self, key: str, value: Any):
        pass
    
    @abstractmethod
    def retrieve(self, key: str) -> Any:
        pass

# memory/short_term.pyï¼ˆPhase 1å®Ÿè£…ï¼‰
class ShortTermMemory(MemoryBackend):
    def __init__(self):
        self.storage = {}  # RAM
    
    def store(self, key, value):
        self.storage[key] = value

# memory/mid_term.pyï¼ˆPhase 1å®Ÿè£…ï¼‰
class MidTermMemory(MemoryBackend):
    def __init__(self):
        self.redis = redis.Redis()  # Phase 1ã‹ã‚‰å®Ÿè£…
    
    def store(self, key, value):
        self.redis.setex(key, 86400, value)
```

**Phase 2ã§è¿½åŠ ï¼ˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹å¤‰æ›´ä¸è¦ï¼‰:**
```python
# memory/encrypted_backend.pyï¼ˆPhase 2ã§è¿½åŠ ï¼‰
class EncryptedMemory(MemoryBackend):
    def __init__(self, backend: MemoryBackend):
        self.backend = backend
        self.cipher = AES256()
    
    def store(self, key, value):
        encrypted = self.cipher.encrypt(value)
        self.backend.store(key, encrypted)
```

---

### 2.1.4 ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°åŸºç›¤ï¼ˆPhase 1ã‹ã‚‰ï¼‰

```python
# utils/error_handler.py
class ErrorHandler:
    """Phase 1ã‹ã‚‰æ‹¡å¼µå¯èƒ½ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°"""
    
    def __init__(self):
        self.fallback_strategies = {}
    
    def register_fallback(self, error_type: Type[Exception], strategy: Callable):
        """Phase 3ã§ã‚«ã‚¹ã‚¿ãƒ æˆ¦ç•¥è¿½åŠ """
        self.fallback_strategies[error_type] = strategy
    
    def handle(self, error: Exception) -> Any:
        """ã‚¨ãƒ©ãƒ¼ç¨®åˆ¥ã«å¿œã˜ãŸå‡¦ç†"""
        strategy = self.fallback_strategies.get(type(error))
        if strategy:
            return strategy(error)
        else:
            # Phase 1: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå‡¦ç†
            logger.error(f"Unhandled error: {error}")
            return None

# Phase 1ã‹ã‚‰ç™»éŒ²
error_handler = ErrorHandler()
error_handler.register_fallback(TimeoutError, lambda e: "å°‘ã—å¾…ã£ã¦ãã ã•ã„")
```

---

### 2.1.5 ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æŠ½è±¡åŒ–ãƒ¬ã‚¤ãƒ¤ãƒ¼

**Phase 1ã‹ã‚‰å®Ÿè£…**

```python
# core/db_adapter.py
class DatabaseAdapter(ABC):
    """Phase 1ã‹ã‚‰æ‹¡å¼µå¯èƒ½ãªDBæŠ½è±¡åŒ–"""
    
    @abstractmethod
    def connect(self):
        pass
    
    @abstractmethod
    def execute(self, query: str, params: tuple):
        pass

# Phase 1å®Ÿè£…
class SQLiteAdapter(DatabaseAdapter):
    def connect(self):
        self.conn = sqlite3.connect("app.db")
    
    def execute(self, query, params):
        return self.conn.execute(query, params)

# Phase 3ã§è¿½åŠ ï¼ˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹å¤‰æ›´ä¸è¦ï¼‰
class PostgreSQLAdapter(DatabaseAdapter):
    def connect(self):
        self.conn = psycopg2.connect(os.getenv("DATABASE_URL"))
```

---

### 2.1.6 WebUIæ§‹é€ ï¼ˆHTML + CSS + JSï¼‰

**Phase 1ã‹ã‚‰æ‹¡å¼µå¯èƒ½**

```html
<!-- static/templates/index.htmlï¼ˆPhase 1ï¼‰ -->
<!DOCTYPE html>
<html>
<head>
    <link rel="stylesheet" href="/static/css/main.css">
</head>
<body>
    <div id="chat-container">
        <!-- Phase 1: åŸºæœ¬ãƒãƒ£ãƒƒãƒˆ -->
        <div id="messages"></div>
        <input id="input" type="text">
    </div>
    
    <!-- Phase 3: 3Då¯è¦–åŒ–ï¼ˆåˆæ‰‹ã‹ã‚‰divç¢ºä¿ï¼‰ -->
    <div id="visualization-panel" style="display:none;">
        <!-- Phase 3ã§å®Ÿè£… -->
    </div>
    
    <script src="/static/js/app.js"></script>
</body>
</html>
```

```css
/* static/css/main.cssï¼ˆPhase 1ã‹ã‚‰æ‹¡å¼µå¯èƒ½ï¼‰ */
:root {
    /* Phase 1: åŸºæœ¬ã‚«ãƒ©ãƒ¼ */
    --primary-color: #4A90E2;
    
    /* Phase 4: ãƒ†ãƒ¼ãƒåˆ‡ã‚Šæ›¿ãˆç”¨ï¼ˆåˆæ‰‹ã‹ã‚‰å®šç¾©ï¼‰ */
    --dark-bg: #1E1E1E;
    --light-bg: #FFFFFF;
}

/* Phase 1å®Ÿè£… */
#chat-container {
    width: 100%;
    max-width: 800px;
}

/* Phase 3ã§æœ‰åŠ¹åŒ– */
#visualization-panel {
    width: 400px;
    height: 400px;
}
```

---

### 2.1.7 ãƒ†ã‚¹ãƒˆåŸºç›¤ï¼ˆPhase 1ã‹ã‚‰ï¼‰

```python
# tests/conftest.pyï¼ˆPhase 1ã‹ã‚‰å®šç¾©ï¼‰
import pytest

@pytest.fixture
def mock_llm():
    """Phase 1ã‹ã‚‰ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒƒã‚¯LLM"""
    class MockLLM:
        def generate(self, prompt):
            return "ãƒ†ã‚¹ãƒˆå¿œç­”"
    return MockLLM()

@pytest.fixture
def test_config():
    """Phase 1ã‹ã‚‰æ‹¡å¼µå¯èƒ½ãªãƒ†ã‚¹ãƒˆè¨­å®š"""
    return {
        "phase_1": {"ollama_enabled": True},
        "phase_2": {"encryption": False},  # Phase 2ã§æœ‰åŠ¹åŒ–
        "phase_3": {"api_enabled": False}  # Phase 3ã§æœ‰åŠ¹åŒ–
    }
```

---

### 2.1.8 ãƒ•ã‚§ãƒ¼ã‚ºåˆ¥å®Ÿè£…ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

| Phase | åˆæ‰‹ã‹ã‚‰å®Ÿè£… | Phase Xã§æœ‰åŠ¹åŒ– |
|-------|-------------|----------------|
| **Phase 1** | ãƒ—ãƒ©ã‚°ã‚¤ãƒ³I/Få®šç¾© | - |
| | ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°åŸºç›¤ | - |
| | DBæŠ½è±¡åŒ–ãƒ¬ã‚¤ãƒ¤ãƒ¼ | - |
| | è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€  | - |
| | WebUIåŸºæœ¬æ§‹é€  | - |
| **Phase 2** | SecurityConfigå®šç¾© | æš—å·åŒ–ãƒ»èªè¨¼å®Ÿè£… |
| | TestSuiteæ§‹é€  | å…¨ãƒ†ã‚¹ãƒˆå®Ÿè£… |
| **Phase 3** | APIConfigå®šç¾© | REST/WSå®Ÿè£… |
| | PluginManagerå®Ÿè£… | ãƒ—ãƒ©ã‚°ã‚¤ãƒ³è¿½åŠ  |

---

**æ‹¡å¼µã®åŸå‰‡:**

1. **Phase 1**: ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ãƒ»æŠ½è±¡ã‚¯ãƒ©ã‚¹ãƒ»è¨­å®šæ§‹é€ ã‚’å®šç¾©
2. **Phase 2+**: å®Ÿè£…è¿½åŠ ï¼ˆæ—¢å­˜ã‚³ãƒ¼ãƒ‰å¤‰æ›´æœ€å°é™ï¼‰
3. **äº’æ›æ€§ç¶­æŒ**: å¤ã„ã‚³ãƒ¼ãƒ‰ãŒå‹•ãç¶šã‘ã‚‹è¨­è¨ˆ

```

---

## 3. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ï¼ˆ`config.py`ï¼‰

```python
class Config:
    def __init__(self):
        self.ollama_host = os.getenv("OLLAMA_HOST", "http://127.0.0.1:11434")
        self.serper_api_key = os.getenv("SERPER_API_KEY", "")
        
        self.models = {
            "fast": "7shi/llm-jp-3-ezo-humanities:3.7b-instruct-q8_0",
            "medium": "amoral-gemma3:latest",
            "search": "dsasai/llama3-elyza-jp-8b:latest"
        }

        self.max_turns = 6
        self.enable_search = True
````

**ä¸»ãªæ©Ÿèƒ½**

* ãƒ¢ãƒ‡ãƒ«è¨­å®šã®ä¸€å…ƒç®¡ç†
* APIã‚­ãƒ¼ã¨Ollamaæ¥ç¶šå…ˆã®å®šç¾©
* è¨­å®šæ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ï¼ˆ`validate_config()`ï¼‰

---

## 4. ä¼šè©±çŠ¶æ…‹ç®¡ç†ï¼ˆ`conversation_state.py`ï¼‰

```python
class ConversationState:
    def __init__(self):
        self.history = []
        self.current_turn = 0
        self.max_turns = 6
        self.start_time = datetime.now()

    def add_turn(self, speaker: str, message: str):
        self.history.append({"speaker": speaker, "msg": message})
        self.current_turn += 1

    def summarize(self):
        # å±¥æ­´ã‚’è¦ç´„ã—ã¦ä¸­æœŸãƒ¡ãƒ¢ãƒªã¸è»¢é€
        return summarize_conversation(self.history)
```

**æ©Ÿèƒ½**

* ä¼šè©±å±¥æ­´ã®ä¿æŒ
* ã‚¿ãƒ¼ãƒ³æ•°ã®è¿½è·¡ã¨è‡ªå‹•ãƒªã‚»ãƒƒãƒˆ
* è¦ç´„ç”Ÿæˆãƒ»ä¸­æœŸãƒ¡ãƒ¢ãƒªè»¢é€ï¼ˆflushï¼‰

---

## 5. LLMãƒãƒ¼ãƒ‰å®Ÿè£…ï¼ˆ`llm_nodes.py`ï¼‰

### 5.1 ãƒ«ãƒŸãƒŠ

```python
def conversation_lumina(state: ConversationState):
    prompt = f"""
    ã‚ãªãŸã¯è¦ªã—ã¿ã‚„ã™ãæ´å¯ŸåŠ›ã®ã‚ã‚‹AIã€Œãƒ«ãƒŸãƒŠã€ã§ã™ã€‚
    æ¬¡ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«è‡ªç„¶ã§æ¸©ã‹ã¿ã®ã‚ã‚‹è¿”ç­”ã‚’ã—ã¦ãã ã•ã„ã€‚
    ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {state.history[-1]['msg']}
    è¿”ç­”:
    """
    return ollama.chat(model=config.models["fast"], messages=[{"role":"user","content":prompt}])
```

### 5.2 ã‚¯ãƒ©ãƒªã‚¹

```python
def conversation_claris(state: ConversationState):
    prompt = f"""
    ã‚ãªãŸã¯ç†è«–çš„ã§ç©ã‚„ã‹ãªAIã€Œã‚¯ãƒ©ãƒªã‚¹ã€ã§ã™ã€‚
    ä»¥ä¸‹ã®å†…å®¹ã‚’ä¸å¯§ã«æ•´ç†ã—ã€èƒŒæ™¯ã‚„æ§‹é€ ã‚’è§£èª¬ã—ã¦ãã ã•ã„ã€‚
    ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {state.history[-1]['msg']}
    """
    return ollama.chat(model=config.models["medium"], messages=[{"role":"user","content":prompt}])
```

### 5.3 ãƒã‚¯ã‚¹ï¼ˆæ¤œç´¢æ©Ÿèƒ½ä»˜ãï¼‰

```python
def conversation_nox(state: ConversationState):
    msg = state.history[-1]["msg"]
    search_keywords = ["èª¿ã¹ã¦", "æœ€æ–°æƒ…å ±", "ãƒ‹ãƒ¥ãƒ¼ã‚¹", "æ¤œç´¢"]
    if any(k in msg for k in search_keywords):
        result = serper_search(msg)
        context = result["summary"]
    else:
        context = ""
    prompt = f"""
    ã‚ãªãŸã¯ã‚¯ãƒ¼ãƒ«ã§æƒ…å ±æ•´ç†ã«å„ªã‚ŒãŸAIã€Œãƒã‚¯ã‚¹ã€ã§ã™ã€‚
    ä»¥ä¸‹ã®ç™ºè©±ã¨æ¤œç´¢çµæœã‚’è¦ç´„ã—ã€æ­£ç¢ºãªæƒ…å ±ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚
    ç™ºè©±: {msg}
    æ¤œç´¢çµæœ: {context}
    """
    return ollama.chat(model=config.models["search"], messages=[{"role":"user","content":prompt}])
```

---

## 6. LangGraphæ§‹æˆï¼ˆ`main.py`ï¼‰

```python
class MultiLLMChat:
    def __init__(self):
        self.state = ConversationState()
        self.nodes = {
            "lumina": conversation_lumina,
            "claris": conversation_claris,
            "nox": conversation_nox
        }
        self.graph = self._build_graph()
        self.compiled = self.graph.compile()

    def _build_graph(self):
        g = StateGraph()
        g.add_node("lumina", self.nodes["lumina"])
        g.add_node("claris", self.nodes["claris"])
        g.add_node("nox", self.nodes["nox"])
        g.add_edge("lumina", "claris")
        g.add_edge("claris", "nox")
        g.add_edge("nox", "lumina")
        return g

    def run(self):
        self.compiled.invoke(self.state)
```

---

## 7. ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ç¾¤ï¼ˆ`utils.py`ï¼‰

### 7.1 ãƒ­ã‚°ç®¡ç†

```python
class Logger:
    def log_conversation(self, msg, llm, turn):
        self.logger.info(f"[Turn {turn}] [{llm}] {msg}")
```

### 7.2 ã‚·ã‚¹ãƒ†ãƒ æ¤œè¨¼

```python
class SystemChecker:
    @staticmethod
    def check_ollama_connection():
        return requests.get(f"{config.ollama_host}/api/version").status_code == 200
```

### 7.3 ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½

```python
class ConversationExporter:
    @staticmethod
    def export_to_json(data, filename=None):
        with open(filename or f"chat_{ts()}.json", "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
```

---

## 8. ã‚·ã‚¹ãƒ†ãƒ ãƒã‚§ãƒƒã‚¯ï¼ˆ`check_system.py`ï¼‰

```python
def main():
    print("=== System Check ===")
    print("Ollama:", SystemChecker.check_ollama_connection())
    print("Models:", SystemChecker.check_models_availability(config.models))
    print("API Key:", bool(config.serper_api_key))
```

å®Ÿè¡Œï¼š

```bash
python check_system.py
```

---

## 9. ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †

### 1. ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
pip install -r requirements.txt
```

### 2. ãƒ¢ãƒ‡ãƒ«æº–å‚™

```bash
ollama pull 7shi/llm-jp-3-ezo-humanities:3.7b-instruct-q8_0
ollama pull amoral-gemma3:latest
ollama pull dsasai/llama3-elyza-jp-8b:latest
```

### 3. APIã‚­ãƒ¼è¨­å®š

```bash
set SERPER_API_KEY=your_key_here   # Windows
export SERPER_API_KEY=your_key_here # Linux/Mac
```

### 4. å®Ÿè¡Œ

```bash
python main.py
```

---

## 10. æ¤œç´¢ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆ`serper_search`ï¼‰

```python
def serper_search(query: str) -> dict:
    url = "https://google.serper.dev/search"
    headers = {"X-API-KEY": config.serper_api_key, "Content-Type": "application/json"}
    payload = {"q": query, "num": 3}
    resp = requests.post(url, headers=headers, json=payload).json()
    summary = " / ".join([r["title"] for r in resp.get("organic", [])[:3]])
    return {"summary": summary, "source": resp.get("organic", [])[0]["link"]}
```

---

## 11. KPIæ›´æ–°ãƒ»æˆé•·ãƒ­ã‚¸ãƒƒã‚¯

```python
def update_kpi(character: str, event: str):
    db = sqlite3.connect("meta.db")
    cur = db.cursor()
    cur.execute(
        "INSERT INTO kpi_log (char,event,ts) VALUES (?,?,?)",
        (character, event, datetime.now())
    )
    db.commit()
```

KPIç´¯ç© â†’ ãƒ¬ãƒ™ãƒ«è¨ˆç®—ï¼š

```python
level = floor(sqrt(total_kpi / 10))
```

---

## 12. é–‹ç™ºãƒ»é‹ç”¨ãƒã‚¤ãƒ³ãƒˆ

| ã‚«ãƒ†ã‚´ãƒª   | æ¨å¥¨è¨­å®š                       |
| ------ | -------------------------- |
| GPUãƒ¡ãƒ¢ãƒª | 12GBä»¥ä¸Šï¼ˆLoRAåˆ©ç”¨æ™‚16GBæ¨å¥¨ï¼‰      |
| ä¸¦åˆ—å‡¦ç†   | asyncio + LangGraphä¸¦åˆ—ãƒãƒ¼ãƒ‰   |
| æ°¸ç¶šåŒ–    | Redisè‡ªå‹•flush + DuckDB é€±æ¬¡åœ§ç¸® |
| ç›£è¦–     | logs/*.log + KPIãƒ¡ãƒˆãƒªã‚¯ã‚¹      |
| ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ— | MinIOåŒæœŸï¼RDB snapshot       |

---

## 13. ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

| å•é¡Œ          | å¯¾å¿œç­–                   |
| ----------- | --------------------- |
| Ollamaæ¥ç¶šä¸å¯  | `ollama serve` ã‚’å®Ÿè¡Œ    |
| ãƒ¢ãƒ‡ãƒ«æœªç™»éŒ²      | `ollama pull <model>` |
| APIã‚­ãƒ¼ç„¡åŠ¹     | Serperã‚­ãƒ¼ã‚’å†å–å¾—          |
| æ¤œç´¢çµæœç©º       | ã‚¯ã‚¨ãƒªãƒ•ã‚£ãƒ«ã‚¿ã‚’å†è¨­å®š           |
| LangGraphä¾‹å¤– | ãƒãƒ¼ãƒ‰é–“å‹ä¸ä¸€è‡´ã‚’ç¢ºèª           |

---

## 14. ä»Šå¾Œã®æ‹¡å¼µäºˆå®š

* WebUIï¼ˆStreamlit / FastAPIï¼‰çµ±åˆ
* ä¼šè©±å±¥æ­´ã®æ°¸ç¶šæ¤œç´¢æ©Ÿèƒ½
* DuckDBï¼‹VectorDBçµ±åˆãƒ“ãƒ¥ãƒ¼ã‚¢
* ãƒãƒ«ãƒãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚»ãƒƒã‚·ãƒ§ãƒ³å¯¾å¿œ
* KPIâ†’LoRAè‡ªå‹•å†å­¦ç¿’

---

---

## 15. v3.0æ–°æ©Ÿèƒ½ã®å®Ÿè£…è©³ç´°

### 15.1 æ„Ÿæƒ…ãƒ¢ãƒ‡ãƒ«ã®å®Ÿè£…

**ãƒ•ã‚¡ã‚¤ãƒ«:** `core/emotional_state.py`

```python
class EmotionalState:
    """å„ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®æ„Ÿæƒ…çŠ¶æ…‹ç®¡ç†"""
    
    def __init__(self, character_name):
        self.character = character_name
        self.emotions = {
            "joy": 0.5, "trust": 0.5, "fear": 0.0, "surprise": 0.0,
            "sadness": 0.0, "disgust": 0.0, "anger": 0.0, "anticipation": 0.5
        }
        self.mood_history = []
    
    def update_from_conversation(self, user_input, context):
        user_emotion = analyze_sentiment(user_input)
        if user_emotion["valence"] < 0:
            self.emotions["sadness"] += 0.2
            self.emotions["trust"] += 0.1
        else:
            self.emotions["joy"] += 0.2
        self._decay_emotions()
```

### 15.2 é€£æƒ³è¨˜æ†¶ã®å®Ÿè£…

**ãƒ•ã‚¡ã‚¤ãƒ«:** `core/associative_memory.py`

**ä¾å­˜é–¢ä¿‚:**
```bash
pip install neo4j py2neo
```

**Neo4jæ¥ç¶šè¨­å®š:**
```python
from neo4j import GraphDatabase

class AssociativeMemory:
    def __init__(self):
        self.driver = GraphDatabase.driver(
            "bolt://localhost:7687",
            auth=("neo4j", "password")
        )
```

### 15.3 è‡ªå·±çœå¯Ÿã®å®Ÿè£…

**ãƒ•ã‚¡ã‚¤ãƒ«:** `core/self_reflection.py`

```python
class SelfReflection:
    def reflect_on_conversation(self, conversation_history):
        reflection_prompt = f"""
        ä»¥ä¸‹ã®ä¼šè©±ã‚’æŒ¯ã‚Šè¿”ã‚Šã€æ”¹å–„ç‚¹ã‚’åˆ†æã—ã¦ãã ã•ã„:
        {format_conversation(conversation_history)}
        """
        reflection = llm.generate(reflection_prompt)
        self._store_reflection(reflection)
        return reflection
```
### 15.4 é€£æƒ³ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯3Då¯è¦–åŒ–ã®å®Ÿè£…

**ãƒ•ã‚¡ã‚¤ãƒ«:** `core/memory/association_visualization.py`

#### 15.4.1 æ¦‚è¦

é€£æƒ³è¨˜æ†¶ã®æ§‹é€ ã‚’è¦–è¦šçš„ã«ç†è§£ãƒ»æ¢ç´¢ã§ãã‚‹ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãª3Då¯è¦–åŒ–ãƒ‘ãƒãƒ«ã€‚

**ä¸»ãªæ©Ÿèƒ½:**
- ON/OFFåˆ‡ã‚Šæ›¿ãˆå¯èƒ½ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆOFFï¼‰
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°
- ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–æ“ä½œï¼ˆã‚ºãƒ¼ãƒ ãƒ»å›è»¢ãƒ»ãƒãƒ¼ãƒ‰ã‚¯ãƒªãƒƒã‚¯ï¼‰
- ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆPNG/HTMLï¼‰

#### 15.4.2 å®Ÿè£…ã‚¯ãƒ©ã‚¹

```python
import plotly.graph_objects as go
import networkx as nx
from typing import Optional, Dict, List

class AssociationVisualizationPanel:
    """
    é€£æƒ³ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯3Då¯è¦–åŒ–ãƒ‘ãƒãƒ«
    
    ãƒ¯ãƒ¼ãƒ‰é–“ã®è·é›¢ã‚’è¦–è¦šåŒ–ã—ã€è¿‘ã„æ¦‚å¿µã‚’ã‚ˆãæ€ã„å‡ºã™ä»•çµ„ã¿ã‚’å®Ÿè£…ã€‚
    ã‚¹ã‚¿ãƒ¼å‹æ§‹é€ ã§ä¸­å¿ƒæ¦‚å¿µã‹ã‚‰é–¢é€£æ¦‚å¿µã‚’æ”¾å°„çŠ¶ã«é…ç½®ã€‚
    """
    
    def __init__(self, association_memory):
        self.association = association_memory
        self.is_visible = False  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆOFF
        self.fig = None
        self.auto_update = False
        self.center_concept = None
        self.depth = 3
        self.threshold = 0.3
        self.max_nodes = 50  # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è€ƒæ…®
        
    def toggle(self) -> bool:
        """ãƒ‘ãƒãƒ«ã®ON/OFFåˆ‡ã‚Šæ›¿ãˆ"""
        self.is_visible = not self.is_visible
        if self.is_visible:
            self._initialize_visualization()
        else:
            self._cleanup()
        return self.is_visible
        
    def update_center(self, concept: str, max_depth: int = 3):
        """
        ä¸­å¿ƒæ¦‚å¿µã‚’å¤‰æ›´ã—ã¦ã‚°ãƒ©ãƒ•ã‚’æ›´æ–°
        
        Args:
            concept: ä¸­å¿ƒã¨ãªã‚‹æ¦‚å¿µ
            max_depth: æ¢ç´¢æ·±åº¦ï¼ˆ1-5ãƒ›ãƒƒãƒ—ï¼‰
        """
        if not self.is_visible:
            return
            
        self.center_concept = concept
        self.depth = max_depth
        
        # é€£æƒ³ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‹ã‚‰é–¢é€£æ¦‚å¿µã‚’å–å¾—
        related = self.association.explore_associations(
            concept, max_depth=max_depth
        )
        
        # 3Dã‚°ãƒ©ãƒ•ã‚’æç”»ï¼ˆPlotly + NetworkXï¼‰
        self.fig = self._create_3d_graph(concept, related)
        
    def _create_3d_graph(self, center: str, associations: List[Dict]) -> go.Figure:
        """
        3Dã‚°ãƒ©ãƒ•æç”»ï¼ˆForce-Directed Layoutï¼‰
        
        è·é›¢ã®è¨ˆç®—:
        - è·é›¢ = 1.0 - ã‚¨ãƒƒã‚¸é‡ã¿
        - è¿‘ã„æ¦‚å¿µï¼ˆé‡ã¿é«˜ï¼‰= è·é›¢å° = ãƒãƒ¼ãƒ‰å¤§ãã„
        """
        # NetworkXã‚°ãƒ©ãƒ•æ§‹ç¯‰
        G = nx.Graph()
        G.add_node(center, distance=0)
        
        for assoc in associations[:self.max_nodes]:
            G.add_node(assoc['concept'], distance=assoc['distance'])
            G.add_edge(
                center if assoc['distance'] == 1 else assoc['parent'],
                assoc['concept'],
                weight=assoc['strength']
            )
        
        # 3Dé…ç½®è¨ˆç®—ï¼ˆForce-Directed Layoutï¼‰
        pos = nx.spring_layout(G, dim=3, k=0.5, iterations=50)
        
        # ã‚¨ãƒƒã‚¸æç”»ãƒ‡ãƒ¼ã‚¿
        edge_traces = self._create_edge_traces(G, pos)
        
        # ãƒãƒ¼ãƒ‰æç”»ãƒ‡ãƒ¼ã‚¿
        node_trace = self._create_node_trace(G, pos, center)
        
        # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨­å®š
        layout = go.Layout(
            title=f"é€£æƒ³ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯: {center}",
            showlegend=False,
            scene=dict(
                xaxis=dict(showgrid=False, zeroline=False, visible=False),
                yaxis=dict(showgrid=False, zeroline=False, visible=False),
                zaxis=dict(showgrid=False, zeroline=False, visible=False),
                bgcolor='rgba(0,0,0,0)'
            ),
            margin=dict(l=0, r=0, t=40, b=0),
            hovermode='closest'
        )
        
        fig = go.Figure(data=edge_traces + [node_trace], layout=layout)
        return fig
    
    def _create_edge_traces(self, G, pos) -> List[go.Scatter3d]:
        """ã‚¨ãƒƒã‚¸æç”»ãƒ‡ãƒ¼ã‚¿ä½œæˆï¼ˆå¼·åº¦ã§è‰²ãƒ»å¤ªã•å¤‰æ›´ï¼‰"""
        edge_traces = []
        for edge in G.edges(data=True):
            x0, y0, z0 = pos[edge[0]]
            x1, y1, z1 = pos[edge[1]]
            strength = edge[2]['weight']
            
            edge_trace = go.Scatter3d(
                x=[x0, x1, None],
                y=[y0, y1, None],
                z=[z0, z1, None],
                mode='lines',
                line=dict(
                    width=strength * 5,
                    color=self._get_edge_color(strength)
                ),
                hoverinfo='text',
                hovertext=f"å¼·åº¦: {strength:.2f}",
                showlegend=False
            )
            edge_traces.append(edge_trace)
        return edge_traces
    
    def _create_node_trace(self, G, pos, center) -> go.Scatter3d:
        """ãƒãƒ¼ãƒ‰æç”»ãƒ‡ãƒ¼ã‚¿ä½œæˆï¼ˆè·é›¢ã§è‰²ãƒ»ã‚µã‚¤ã‚ºå¤‰æ›´ï¼‰"""
        node_x, node_y, node_z = [], [], []
        node_text, node_colors, node_sizes = [], [], []
        
        for node in G.nodes(data=True):
            x, y, z = pos[node[0]]
            node_x.append(x)
            node_y.append(y)
            node_z.append(z)
            
            distance = node[1].get('distance', 999)
            node_text.append(node[0])
            node_colors.append(self._get_node_color(distance))
            node_sizes.append(self._get_node_size(distance))
        
        return go.Scatter3d(
            x=node_x, y=node_y, z=node_z,
            mode='markers+text',
            marker=dict(
                size=node_sizes,
                color=node_colors,
                line=dict(width=2, color='white')
            ),
            text=node_text,
            textposition="top center",
            textfont=dict(size=10),
            hoverinfo='text',
            hovertext=[
                f"{node[0]}<br>è·é›¢: {node[1].get('distance', 'N/A')}"
                for node in G.nodes(data=True)
            ]
        )
    
    def _get_edge_color(self, strength: float) -> str:
        """ã‚¨ãƒƒã‚¸è‰²ï¼ˆå¼·åº¦ãƒ™ãƒ¼ã‚¹ï¼‰"""
        if strength > 0.7:
            return 'rgba(255, 0, 0, 0.8)'  # å¼·ã„: èµ¤
        elif strength > 0.4:
            return 'rgba(255, 165, 0, 0.6)'  # ä¸­: ã‚ªãƒ¬ãƒ³ã‚¸
        else:
            return 'rgba(128, 128, 128, 0.3)'  # å¼±ã„: ã‚°ãƒ¬ãƒ¼
    
    def _get_node_color(self, distance: int) -> str:
        """ãƒãƒ¼ãƒ‰è‰²ï¼ˆè·é›¢ãƒ™ãƒ¼ã‚¹ï¼‰"""
        if distance == 0:
            return '#FF0000'  # ä¸­å¿ƒ: èµ¤
        elif distance == 1:
            return '#FFA500'  # 1ãƒ›ãƒƒãƒ—: ã‚ªãƒ¬ãƒ³ã‚¸
        elif distance == 2:
            return '#FFFF00'  # 2ãƒ›ãƒƒãƒ—: é»„
        else:
            return '#00FF00'  # 3ãƒ›ãƒƒãƒ—: ç·‘
    
    def _get_node_size(self, distance: int) -> int:
        """ãƒãƒ¼ãƒ‰ã‚µã‚¤ã‚ºï¼ˆè·é›¢ãƒ™ãƒ¼ã‚¹ï¼šè¿‘ã„ã»ã©å¤§ãã„ï¼‰"""
        return max(20 - distance * 5, 5)
    
    def export(self, filepath: str, format: str = "png"):
        """
        ã‚°ãƒ©ãƒ•ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        
        Args:
            filepath: ä¿å­˜å…ˆãƒ‘ã‚¹
            format: 'png' ã¾ãŸã¯ 'html'
        """
        if not self.fig:
            return
            
        if format == "png":
            self.fig.write_image(filepath, width=1920, height=1080)
        elif format == "html":
            self.fig.write_html(filepath)
```

#### 15.4.3 ä½¿ç”¨ä¾‹

```python
# åˆæœŸåŒ–
viz = AssociationVisualizationPanel(association_memory)

# ON/OFFåˆ‡ã‚Šæ›¿ãˆ
viz.toggle()  # True (è¡¨ç¤º)

# ä¼šè©±ä¸­ã®è‡ªå‹•æ›´æ–°
# ãƒ¦ãƒ¼ã‚¶ãƒ¼: ã€Œã‚¤ãƒ³ã‚»ãƒ—ã‚·ãƒ§ãƒ³ã«ã¤ã„ã¦è©±ã—ã¦ã€
viz.update_center("ã‚¤ãƒ³ã‚»ãƒ—ã‚·ãƒ§ãƒ³", max_depth=3)
# â†’ ã€Œå¤¢ã€ã€Œè¨˜æ†¶ã€ã€Œãƒãƒ¼ãƒ©ãƒ³ã€ã€Œæ™‚é–“ã€ãŒè¿‘ãã«è¡¨ç¤ºã•ã‚Œã‚‹

# ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
viz.export("association_graph.png", format="png")
viz.export("association_graph.html", format="html")
```

#### 15.4.4 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ä»•æ§˜

- **æœ€å¤§ãƒãƒ¼ãƒ‰æ•°:** 50ï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è€ƒæ…®ï¼‰
- **æ›´æ–°é »åº¦:** 1ç§’/å›
- **æç”»ã‚¨ãƒ³ã‚¸ãƒ³:** Plotly WebGLï¼ˆé«˜é€Ÿæç”»ï¼‰
- **CPUè² è·:** æœ€å°é™

#### 15.4.5 æŠ€è¡“çš„ãƒã‚¤ãƒ³ãƒˆ

1. **è·é›¢ã®è¨ˆç®—**
   - è·é›¢ = 1.0 - ã‚¨ãƒƒã‚¸é‡ã¿
   - è¿‘ã„æ¦‚å¿µï¼ˆé‡ã¿é«˜ï¼‰= è·é›¢å° = ãƒãƒ¼ãƒ‰å¤§ãã„

2. **åŠ›å­¦ãƒ¢ãƒ‡ãƒ«**
   - NetworkXã®`spring_layout`ã§ãƒãƒ¼ãƒ‰é…ç½®
   - é–¢é€£æ€§ã®å¼·ã„æ¦‚å¿µã»ã©è¿‘ãã«é…ç½®
   - è¦–è¦šçš„ã«ã€Œã‚ˆãæ€ã„å‡ºã™ã€ã‚’è¡¨ç¾

3. **ã‚¹ã‚¿ãƒ¼å‹æ§‹é€ **
   - ä¸­å¿ƒæ¦‚å¿µã‚’åŸç‚¹ã«ã€é–¢é€£æ¦‚å¿µã‚’æ”¾å°„çŠ¶ã«é…ç½®
   - æ·±åº¦1: ç›´æ¥é–¢é€£ï¼ˆæœ€ã‚‚è¿‘ã„ï¼‰
   - æ·±åº¦2-3: é–“æ¥é–¢é€£ï¼ˆã‚„ã‚„é ã„ï¼‰

4. **WebGLæç”»**
   - Plotlyã®`plotly.graph_objects.Scatter3d`ã§é«˜é€Ÿæç”»

---


---

## 16. ä¾å­˜é–¢ä¿‚ã®æ›´æ–°ï¼ˆv3.0ï¼‰

**requirements.txt**

```txt
# ã‚³ã‚¢
langchain>=0.1.0
langgraph>=0.0.20
ollama>=0.1.0

# è¨˜æ†¶å±¤
redis>=5.0.0
duckdb>=0.9.0
psycopg2-binary>=2.9.0
pinecone-client>=2.2.0
# ã¾ãŸã¯ qdrant-client>=1.7.0

# é€£æƒ³è¨˜æ†¶
neo4j>=5.14.0
py2neo>=2021.2.3

# æ„Ÿæƒ…åˆ†æ
transformers>=4.30.0
torch>=2.0.0

# 3Då¯è¦–åŒ–
plotly>=5.17.0
networkx>=3.1
kaleido>=0.2.1  # PNG/PDFã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆç”¨

# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
numpy>=1.24.0
pandas>=2.0.0
pyyaml>=6.0
requests>=2.31.0

# Webæ¤œç´¢
google-serper>=0.1.0

# éŸ³å£°ãƒ»ç”»åƒï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
openai-whisper>=20230314
pillow>=10.0.0

# ETL
apache-airflow>=2.7.0

# ç›£è¦–
prometheus-client>=0.17.0
```

---

## 17. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆv3.0ï¼‰

### 17.1 Neo4jï¼ˆé€£æƒ³è¨˜æ†¶ï¼‰

```bash
# DockerçµŒç”±
docker run -d \
  --name neo4j \
  -p 7474:7474 -p 7687:7687 \
  -e NEO4J_AUTH=neo4j/password \
  neo4j:latest
```

### 17.2 PostgreSQLï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼‰

```bash
docker run -d \
  --name postgres \
  -p 5432:5432 \
  -e POSTGRES_PASSWORD=password \
  -e POSTGRES_DB=llm_multi_chat \
  postgres:15
```

### 17.3 Redisï¼ˆä¸­æœŸè¨˜æ†¶ï¼‰

```bash
docker run -d \
  --name redis \
  -p 6379:6379 \
  redis:7-alpine
```

---

## 18. é–‹ç™ºãƒ»é‹ç”¨ãƒã‚¤ãƒ³ãƒˆï¼ˆv3.0æ›´æ–°ï¼‰

| ã‚«ãƒ†ã‚´ãƒª | æ¨å¥¨è¨­å®š | å‚™è€ƒ |
|---------|---------|------|
| GPUãƒ¡ãƒ¢ãƒª | 16GBä»¥ä¸Š | æ„Ÿæƒ…åˆ†æãƒ¢ãƒ‡ãƒ«å«ã‚€ |
| CPU | 8ã‚³ã‚¢ä»¥ä¸Š | Neo4jæ¨å¥¨ |
| RAM | 32GBä»¥ä¸Š | ã‚°ãƒ©ãƒ•DB + ãƒ™ã‚¯ãƒˆãƒ«DB |
| ä¸¦åˆ—å‡¦ç† | asyncio + LangGraph | è¤‡æ•°ã‚­ãƒ£ãƒ©åŒæ™‚å¿œç­” |
| æ°¸ç¶šåŒ– | Redis + DuckDB + Neo4j | éšå±¤è¨˜æ†¶ |
| ç›£è¦– | Prometheus + Grafana | KPI + æ„Ÿæƒ…çŠ¶æ…‹ |
| ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ— | MinIO + RDB Snapshot | é€±æ¬¡æ¨å¥¨ |

---

## 19. v3.0ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰ã‚¬ã‚¤ãƒ‰

### æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰v3.0ã¸

1. **ä¾å­˜é–¢ä¿‚ã®è¿½åŠ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«**
```bash
pip install neo4j py2neo transformers torch
```

2. **Neo4jã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—**
```bash
docker-compose up -d neo4j
```

3. **æ–°æ©Ÿèƒ½ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®è¿½åŠ **
```bash
mkdir -p core memory
# core/ä»¥ä¸‹ã«æ–°æ©Ÿèƒ½å®Ÿè£…
```

4. **æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®ç§»è¡Œ**
```python
python migrate_to_v3.py
```

---

**å®Ÿè£…å®Œäº†æ—¥:** 2024-12
**v3.0æ›´æ–°æ—¥:** 2025-11-11
**ãƒãƒ¼ã‚¸ãƒ§ãƒ³:** 3.0.0ï¼ˆäººé–“ã‚‰ã—ã„å¯¾è©±ã‚·ã‚¹ãƒ†ãƒ å®Œå…¨ç‰ˆï¼‰
**ãƒ©ã‚¤ã‚»ãƒ³ã‚¹:** MIT
**é–‹ç™º:** LUMINA SYSTEM DEVELOPMENT TEAM

**v3.0ã®ä¸»ãªè¿½åŠ å®Ÿè£…:**
- âœ¨ æ„Ÿæƒ…ãƒ¢ãƒ‡ãƒ«ï¼ˆ8åŸºæœ¬æ„Ÿæƒ…ï¼‰
- ğŸ§  é€£æƒ³è¨˜æ†¶ï¼ˆNeo4j Graph DBï¼‰
- ğŸª è‡ªå·±çœå¯Ÿã‚·ã‚¹ãƒ†ãƒ 
- ğŸ­ é©å¿œçš„å¯¾è©±ã‚¹ã‚¿ã‚¤ãƒ«
- ğŸ”— å¯¾è©±ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯
- â±ï¸ è‡ªç„¶ãªã‚¿ã‚¤ãƒŸãƒ³ã‚°åˆ¶å¾¡
- ğŸŒˆ è¨˜æ†¶é‡è¦åº¦åˆ¤å®š
- ğŸ”„ ãƒˆãƒ”ãƒƒã‚¯è¿½è·¡
- ğŸ“Š é€£æƒ³ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯3Då¯è¦–åŒ–ãƒ‘ãƒãƒ«


---

## 16. v3.1æ–°æ©Ÿèƒ½ã®å®Ÿè£…è©³ç´°ï¼ˆAPIãƒ»MCPãƒ»è‡ªå¾‹ã‚µãƒ¼ãƒï¼‰

### 16.1 REST/WebSocket APIå®Ÿè£…

**ãƒ•ã‚¡ã‚¤ãƒ«:** `api/routes.py`, `api/middleware.py`, `api/websocket.py`

**å„ªå…ˆåº¦:** é«˜ï¼ˆPhase 1æ‹¡å¼µï¼‰  
**å·¥æ•°:** 2é€±é–“

#### 16.1.1 ä¾å­˜é–¢ä¿‚è¿½åŠ 

```bash
# requirements.txt ã«è¿½åŠ 
fastapi==0.104.1
uvicorn[standard]==0.24.0
pydantic==2.5.0
python-jose[cryptography]==3.3.0
python-multipart==0.0.6
websockets==12.0
redis==5.0.1
```

#### 16.1.2 FastAPIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åŸºæœ¬æ§‹é€ 

**ãƒ•ã‚¡ã‚¤ãƒ«:** `api/main.py`

```python
from fastapi import FastAPI, WebSocket, Depends, HTTPException, status
from fastapi.middleware.cors import CORSMiddleware
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
from enum import Enum
import jwt
from datetime import datetime, timedelta
import redis

app = FastAPI(title="ä¼šè©±LLM API", version="3.1.0")

# CORSè¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "https://yourdomain.com"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Redisæ¥ç¶šï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™ç”¨ï¼‰
redis_client = redis.Redis(host='localhost', port=6379, db=0, decode_responses=True)
```

#### 16.1.3 èªè¨¼å®Ÿè£…

**ãƒ•ã‚¡ã‚¤ãƒ«:** `api/auth.py`

```python
from jose import JWTError, jwt
from passlib.context import CryptContext
from datetime import datetime, timedelta

SECRET_KEY = "your-secret-key-here"  # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—æ¨å¥¨
ALGORITHM = "HS256"
ACCESS_TOKEN_EXPIRE_MINUTES = 60

pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")

def create_access_token(data: dict, expires_delta: timedelta = None):
    to_encode = data.copy()
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(minutes=15)
    to_encode.update({"exp": expire})
    encoded_jwt = jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)
    return encoded_jwt

def verify_token(credentials: HTTPAuthorizationCredentials):
    try:
        payload = jwt.decode(credentials.credentials, SECRET_KEY, algorithms=[ALGORITHM])
        user_id: str = payload.get("sub")
        if user_id is None:
            raise HTTPException(status_code=401, detail="Invalid token")
        return user_id
    except JWTError:
        raise HTTPException(status_code=401, detail="Invalid token")
```

#### 16.1.4 ãƒ¬ãƒ¼ãƒˆåˆ¶é™å®Ÿè£…

**ãƒ•ã‚¡ã‚¤ãƒ«:** `api/rate_limit.py`

```python
from fastapi import HTTPException
import redis

redis_client = redis.Redis(host='localhost', port=6379, db=0, decode_responses=True)

def check_rate_limit(user_id: str, role: str = "free"):
    """
    ãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒã‚§ãƒƒã‚¯
    - Free: 100ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/åˆ†
    - Pro: 1000ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/åˆ†
    """
    limit = 100 if role == "free" else 1000
    key = f"rate_limit:{user_id}"
    
    current = redis_client.get(key)
    if current is None:
        redis_client.setex(key, 60, 1)
    else:
        count = int(current)
        if count >= limit:
            raise HTTPException(status_code=429, detail="Rate limit exceeded")
        redis_client.incr(key)
```

#### 16.1.5 WebSocketå®Ÿè£…

**ãƒ•ã‚¡ã‚¤ãƒ«:** `api/websocket.py`

```python
from fastapi import WebSocket, WebSocketDisconnect
from typing import Dict
import asyncio

class ConnectionManager:
    def __init__(self):
        self.active_connections: Dict[str, WebSocket] = {}
    
    async def connect(self, websocket: WebSocket, user_id: str):
        await websocket.accept()
        self.active_connections[user_id] = websocket
    
    def disconnect(self, user_id: str):
        self.active_connections.pop(user_id, None)
    
    async def send_personal_message(self, message: dict, user_id: str):
        if user_id in self.active_connections:
            await self.active_connections[user_id].send_json(message)

manager = ConnectionManager()

@app.websocket("/api/v1/stream")
async def websocket_chat(websocket: WebSocket):
    await websocket.accept()
    user_id = None
    
    try:
        # èªè¨¼
        auth_data = await websocket.receive_json()
        if auth_data.get("type") != "auth":
            await websocket.send_json({"type": "error", "message": "Authentication required"})
            await websocket.close()
            return
        
        user_id = verify_token_ws(auth_data["token"])
        await manager.connect(websocket, user_id)
        await websocket.send_json({"type": "auth_success", "user_id": user_id})
        
        # ä¼šè©±ãƒ«ãƒ¼ãƒ—
        while True:
            data = await websocket.receive_json()
            
            if data.get("type") == "message":
                # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¿œç­”
                async for chunk in stream_conversation(
                    user_id=user_id,
                    message=data["content"],
                    thread_id=data.get("thread_id")
                ):
                    await websocket.send_json({
                        "type": "chunk",
                        "content": chunk["text"],
                        "character": chunk["character"]
                    })
                
                await websocket.send_json({
                    "type": "done",
                    "message_id": chunk["message_id"],
                    "thread_id": chunk["thread_id"]
                })
    
    except WebSocketDisconnect:
        if user_id:
            manager.disconnect(user_id)
    except Exception as e:
        await websocket.send_json({"type": "error", "message": str(e)})
```

#### 16.1.6 å®Ÿè£…ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] FastAPIåŸºæœ¬æ§‹é€ å®Ÿè£…
- [ ] Pydanticãƒ¢ãƒ‡ãƒ«å®šç¾©ï¼ˆ`api/models.py`ï¼‰
- [ ] JWTèªè¨¼å®Ÿè£…
- [ ] ãƒ¬ãƒ¼ãƒˆåˆ¶é™ï¼ˆRedisï¼‰
- [ ] WebSocketã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
- [ ] CORSè¨­å®š
- [ ] ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
- [ ] OpenAPIä»•æ§˜æ›¸è‡ªå‹•ç”Ÿæˆ
- [ ] Postmanã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆ

---

### 16.2 MCP (Model Context Protocol) å¯¾å¿œå®Ÿè£…

**ãƒ•ã‚¡ã‚¤ãƒ«:** `mcp/server.py`, `mcp/client.py`

**å„ªå…ˆåº¦:** ä¸­ï¼ˆPhase 1æ‹¡å¼µï¼‰  
**å·¥æ•°:** 1é€±é–“

#### 16.2.1 ä¾å­˜é–¢ä¿‚è¿½åŠ 

```bash
# requirements.txt ã«è¿½åŠ 
mcp==0.9.0
```

#### 16.2.2 MCP Serverå®Ÿè£…

**ãƒ•ã‚¡ã‚¤ãƒ«:** `mcp/server.py`

```python
from mcp.server import Server
from mcp.types import TextContent, Tool, Resource
from typing import Any, Sequence

class LlmMultiChatMCPServer(Server):
    """ä¼šè©±LLMã‚·ã‚¹ãƒ†ãƒ ã‚’MCP Serverã¨ã—ã¦å…¬é–‹"""
    
    def __init__(self):
        super().__init__(name="llm-multi-chat-server")
        self.register_tools()
        self.register_resources()
    
    def register_tools(self):
        """ãƒ„ãƒ¼ãƒ«ç™»éŒ²"""
        
        @self.tool()
        async def chat_with_character(
            character: str,
            message: str,
            thread_id: str | None = None
        ) -> str:
            """
            ç‰¹å®šã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¨ä¼šè©±
            
            Args:
                character: ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åï¼ˆlumina/clarisse/noxï¼‰
                message: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                thread_id: ã‚¹ãƒ¬ãƒƒãƒ‰IDï¼ˆç¶™ç¶šä¼šè©±ï¼‰
            
            Returns:
                å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆ
            """
            from conversation_state import execute_conversation
            
            response = await execute_conversation(
                user_id="mcp_user",
                message=message,
                character=character,
                thread_id=thread_id
            )
            return response["content"]
        
        @self.tool()
        async def search_memories(
            query: str,
            limit: int = 10
        ) -> list[dict[str, Any]]:
            """
            è¨˜æ†¶æ¤œç´¢
            
            Args:
                query: æ¤œç´¢ã‚¯ã‚¨ãƒª
                limit: æœ€å¤§ä»¶æ•°
            
            Returns:
                è¨˜æ†¶ãƒªã‚¹ãƒˆ
            """
            from memory.long_term import search_vector_db
            
            results = await search_vector_db(
                user_id="mcp_user",
                query=query,
                limit=limit
            )
            return results
        
        @self.tool()
        async def get_knowledge_base(
            kb_name: str,
            topic: str
        ) -> str:
            """
            çŸ¥è­˜ãƒ™ãƒ¼ã‚¹æ¤œç´¢
            
            Args:
                kb_name: çŸ¥è­˜ãƒ™ãƒ¼ã‚¹åï¼ˆmovie/history/gossip/techï¼‰
                topic: ãƒˆãƒ”ãƒƒã‚¯
            
            Returns:
                é–¢é€£æƒ…å ±
            """
            from memory.knowledge_base import query_knowledge_base
            
            results = await query_knowledge_base(kb_name, topic)
            return "\n\n".join([r["content"] for r in results])
        
        @self.tool()
        async def autonomous_search(
            query: str,
            max_results: int = 5
        ) -> str:
            """
            è‡ªå¾‹çš„Webæ¤œç´¢
            
            Args:
                query: æ¤œç´¢ã‚¯ã‚¨ãƒª
                max_results: æœ€å¤§ä»¶æ•°
            
            Returns:
                æ¤œç´¢çµæœã‚µãƒãƒªãƒ¼
            """
            from core.autonomous_search import perform_autonomous_search
            
            results = await perform_autonomous_search(query, max_results)
            return summarize_search_results(results)
    
    def register_resources(self):
        """ãƒªã‚½ãƒ¼ã‚¹ç™»éŒ²"""
        
        @self.resource("character://lumina")
        async def get_lumina_info() -> TextContent:
            """ãƒ«ãƒŸãƒŠã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«"""
            return TextContent(
                type="text",
                text="ãƒ«ãƒŸãƒŠ: ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ãªå¸ä¼šå½¹ã€‚æ´å¯Ÿå‹ã§é›‘è«‡ãƒ»æ¨è«–ãŒå¾—æ„ã€‚"
            )
        
        @self.resource("character://clarisse")
        async def get_clarisse_info() -> TextContent:
            """ã‚¯ãƒ©ãƒªã‚¹ã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«"""
            return TextContent(
                type="text",
                text="ã‚¯ãƒ©ãƒªã‚¹: ç©ã‚„ã‹ãªç†è«–æ´¾ã€‚æ§‹é€ åŒ–ãƒ»è§£èª¬ãŒå¾—æ„ã€‚"
            )
        
        @self.resource("character://nox")
        async def get_nox_info() -> TextContent:
            """ãƒã‚¯ã‚¹ã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«"""
            return TextContent(
                type="text",
                text="ãƒã‚¯ã‚¹: ã‚¯ãƒ¼ãƒ«ãªæƒ…å ±ãƒãƒ³ã‚¿ãƒ¼ã€‚æ¤œè¨¼ãƒ»è¦ç´„ç‰¹åŒ–ã€‚"
            )
        
        @self.resource("memory://recent")
        async def get_recent_memories() -> TextContent:
            """æœ€è¿‘ã®è¨˜æ†¶"""
            from memory.long_term import get_recent_memories
            
            memories = await get_recent_memories(user_id="mcp_user", limit=10)
            text = "\n".join([m["summary"] for m in memories])
            return TextContent(type="text", text=text)

# MCP Serverèµ·å‹•
if __name__ == "__main__":
    import asyncio
    from mcp.server.stdio import stdio_server
    
    async def main():
        server = LlmMultiChatMCPServer()
        async with stdio_server() as (read_stream, write_stream):
            await server.run(
                read_stream,
                write_stream,
                server.create_initialization_options()
            )
    
    asyncio.run(main())
```

#### 16.2.3 MCP Serverèµ·å‹•æ–¹æ³•

```bash
# stdioæ–¹å¼ã§MCP Serverèµ·å‹•
python mcp/server.py

# Claude Desktopé€£æºè¨­å®šï¼ˆ~/.config/Claude/claude_desktop_config.jsonï¼‰
{
  "mcpServers": {
    "llm-multi-chat": {
      "command": "python",
      "args": ["c:/GenerativeAI/LlmMultiChat3/mcp/server.py"]
    }
  }
}
```

#### 16.2.4 å®Ÿè£…ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] MCP ServeråŸºæœ¬å®Ÿè£…
- [ ] 4ã¤ã®ãƒ„ãƒ¼ãƒ«å®Ÿè£…ï¼ˆchat/search/kb/autonomous_searchï¼‰
- [ ] 4ã¤ã®ãƒªã‚½ãƒ¼ã‚¹å®Ÿè£…ï¼ˆcharacterÃ—3 + memoryï¼‰
- [ ] stdioé€šä¿¡å®Ÿè£…
- [ ] Claude Desktopé€£æºãƒ†ã‚¹ãƒˆ
- [ ] MCPãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä½œæˆ

---

### 16.3 è‡ªå¾‹çš„å¤–éƒ¨ã‚µãƒ¼ãƒãƒ»æƒ…å ±åé›†ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè£…

**ãƒ•ã‚¡ã‚¤ãƒ«:** `core/autonomous_search.py`, `core/knowledge_updater.py`

**å„ªå…ˆåº¦:** é«˜ï¼ˆPhase 1æ‹¡å¼µï¼‰  
**å·¥æ•°:** 2é€±é–“

#### 16.3.1 ä¾å­˜é–¢ä¿‚è¿½åŠ 

```bash
# requirements.txt ã«è¿½åŠ 
langchain==0.1.0
langchain-community==0.0.13
apscheduler==3.10.4
wikipedia==1.4.0
```

#### 16.3.2 è‡ªå¾‹ã‚µãƒ¼ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè£…

**ãƒ•ã‚¡ã‚¤ãƒ«:** `core/autonomous_search.py`

```python
from langchain.agents import AgentExecutor, create_react_agent
from langchain.tools import Tool
from langchain_community.utilities import GoogleSerperAPIWrapper, WikipediaAPIWrapper
from langchain.prompts import PromptTemplate
from typing import List, Dict, Any
import asyncio

class AutonomousSearchAgent:
    """è‡ªå¾‹çš„å¤–éƒ¨ã‚µãƒ¼ãƒãƒ»æƒ…å ±åé›†ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"""
    
    def __init__(self):
        self.serper = GoogleSerperAPIWrapper()
        self.wikipedia = WikipediaAPIWrapper()
        self.tools = self._create_tools()
        self.agent = self._create_agent()
    
    def _create_tools(self) -> List[Tool]:
        """ãƒ„ãƒ¼ãƒ«å®šç¾©"""
        return [
            Tool(
                name="web_search",
                func=self.serper.run,
                description="Webæ¤œç´¢ã€‚æœ€æ–°æƒ…å ±ã®å–å¾—ã«ä½¿ç”¨ã€‚"
            ),
            Tool(
                name="knowledge_base_query",
                func=self._query_kb,
                description="æ—¢å­˜çŸ¥è­˜ãƒ™ãƒ¼ã‚¹æ¤œç´¢ã€‚movie/history/gossip/techã‹ã‚‰æ¤œç´¢ã€‚"
            ),
            Tool(
                name="wikipedia_search",
                func=self.wikipedia.run,
                description="Wikipediaæ¤œç´¢ã€‚è©³ç´°ãªç™¾ç§‘äº‹å…¸æƒ…å ±ã®å–å¾—ã€‚"
            ),
            Tool(
                name="save_to_kb",
                func=self._save_to_kb,
                description="çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã¸ä¿å­˜ã€‚é‡è¦ãªæƒ…å ±ã‚’æ°¸ç¶šåŒ–ã€‚"
            )
        ]
    
    def _create_agent(self):
        """ReActã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆ"""
        prompt = PromptTemplate.from_template("""
ã‚ãªãŸã¯è‡ªå¾‹çš„ãªæƒ…å ±åé›†ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã€ä»¥ä¸‹ã®æ‰‹é †ã§æƒ…å ±ã‚’åé›†ã—ã¦ãã ã•ã„ï¼š

1. ã¾ãšæ—¢å­˜ã®çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‚’æ¤œç´¢
2. æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆã€Webæ¤œç´¢ã‚’å®Ÿè¡Œ
3. å¿…è¦ã«å¿œã˜ã¦Wikipediaæ¤œç´¢ã§è©³ç´°æƒ…å ±ã‚’å–å¾—
4. é‡è¦ãªæƒ…å ±ã¯çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
5. æœ€çµ‚çš„ãªå›ç­”ã‚’ç”Ÿæˆ

åˆ©ç”¨å¯èƒ½ãªãƒ„ãƒ¼ãƒ«:
{tools}

ãƒ„ãƒ¼ãƒ«å:
{tool_names}

è³ªå•: {input}

æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹:
{agent_scratchpad}
        """)
        
        from llm_nodes import get_llm
        return create_react_agent(
            llm=get_llm("gpt-4"),
            tools=self.tools,
            prompt=prompt
        )
    
    async def search_and_collect(
        self,
        query: str,
        max_depth: int = 3,
        save_to_kb: bool = True
    ) -> Dict[str, Any]:
        """
        è‡ªå¾‹çš„æ¤œç´¢ãƒ»æƒ…å ±åé›†
        
        Args:
            query: æ¤œç´¢ã‚¯ã‚¨ãƒª
            max_depth: æ¢ç´¢æ·±åº¦
            save_to_kb: çŸ¥è­˜ãƒ™ãƒ¼ã‚¹è‡ªå‹•ä¿å­˜
        
        Returns:
            åé›†ã—ãŸæƒ…å ±
        """
        agent_executor = AgentExecutor(
            agent=self.agent,
            tools=self.tools,
            verbose=True,
            max_iterations=max_depth
        )
        
        result = await agent_executor.ainvoke({"input": query})
        
        # çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ä¿å­˜
        if save_to_kb:
            await self._save_to_kb(
                category=self._classify_category(query),
                content=result["output"]
            )
        
        return {
            "query": query,
            "result": result["output"],
            "intermediate_steps": result.get("intermediate_steps", []),
            "saved_to_kb": save_to_kb
        }
    
    async def _query_kb(self, query: str) -> str:
        """çŸ¥è­˜ãƒ™ãƒ¼ã‚¹æ¤œç´¢"""
        from memory.knowledge_base import query_all_knowledge_bases
        
        results = await query_all_knowledge_bases(query, top_k=5)
        if results:
            return "\n\n".join([r["content"] for r in results])
        return "çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã«é–¢é€£æƒ…å ±ãªã—"
    
    async def _save_to_kb(self, category: str, content: str) -> str:
        """çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ä¿å­˜"""
        from memory.knowledge_base import upsert_to_knowledge_base
        from datetime import datetime
        
        await upsert_to_knowledge_base(
            kb_name=f"kb:{category}",
            content=content,
            metadata={"source": "autonomous_search", "timestamp": datetime.utcnow()}
        )
        return f"çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ kb:{category} ã«ä¿å­˜å®Œäº†"
    
    def _classify_category(self, query: str) -> str:
        """ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        keywords = {
            "movie": ["æ˜ ç”»", "ãƒ‰ãƒ©ãƒ", "ä¿³å„ª", "ç›£ç£"],
            "history": ["æ­´å²", "å¹´è¡¨", "å‡ºæ¥äº‹"],
            "gossip": ["ãƒˆãƒ¬ãƒ³ãƒ‰", "ãƒ‹ãƒ¥ãƒ¼ã‚¹", "è©±é¡Œ"],
            "tech": ["æŠ€è¡“", "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°", "AI"]
        }
        
        for category, kws in keywords.items():
            if any(kw in query for kw in kws):
                return category
        return "custom"
```

#### 16.3.3 å®šæœŸæ›´æ–°ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©å®Ÿè£…

**ãƒ•ã‚¡ã‚¤ãƒ«:** `core/knowledge_updater.py`

```python
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from core.autonomous_search import AutonomousSearchAgent
import asyncio

class KnowledgeBaseUpdater:
    """çŸ¥è­˜ãƒ™ãƒ¼ã‚¹å®šæœŸæ›´æ–°"""
    
    def __init__(self):
        self.scheduler = AsyncIOScheduler()
        self.agent = AutonomousSearchAgent()
    
    def start(self):
        """ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©èµ·å‹•"""
        # æ¯æœ6æ™‚: ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ»ãƒˆãƒ¬ãƒ³ãƒ‰æ›´æ–°
        self.scheduler.add_job(
            self._update_gossip,
            'cron',
            hour=6,
            minute=0
        )
        
        # æ¯é€±æ—¥æ›œæ—¥: æ˜ ç”»æƒ…å ±æ›´æ–°
        self.scheduler.add_job(
            self._update_movies,
            'cron',
            day_of_week='sun',
            hour=3,
            minute=0
        )
        
        # æ¯æœˆ1æ—¥: æŠ€è¡“æƒ…å ±æ›´æ–°
        self.scheduler.add_job(
            self._update_tech,
            'cron',
            day=1,
            hour=2,
            minute=0
        )
        
        self.scheduler.start()
    
    async def _update_gossip(self):
        """ãƒˆãƒ¬ãƒ³ãƒ‰æƒ…å ±æ›´æ–°"""
        queries = [
            "ä»Šæ—¥ã®ä¸»è¦ãƒ‹ãƒ¥ãƒ¼ã‚¹",
            "Twitterãƒˆãƒ¬ãƒ³ãƒ‰",
            "è©±é¡Œã®å‡ºæ¥äº‹"
        ]
        for query in queries:
            await self.agent.search_and_collect(query, save_to_kb=True)
    
    async def _update_movies(self):
        """æ˜ ç”»æƒ…å ±æ›´æ–°"""
        queries = [
            "ä»Šé€±å…¬é–‹ã®æ˜ ç”»",
            "è©±é¡Œã®æ˜ ç”»ãƒ©ãƒ³ã‚­ãƒ³ã‚°",
            "ã‚¢ã‚«ãƒ‡ãƒŸãƒ¼è³ãƒãƒŸãƒãƒ¼ãƒˆä½œå“"
        ]
        for query in queries:
            await self.agent.search_and_collect(query, save_to_kb=True)
    
    async def _update_tech(self):
        """æŠ€è¡“æƒ…å ±æ›´æ–°"""
        queries = [
            "æœ€æ–°AIæŠ€è¡“ãƒˆãƒ¬ãƒ³ãƒ‰",
            "GitHubäººæ°—ãƒªãƒã‚¸ãƒˆãƒª",
            "Stack Overflowäººæ°—è³ªå•"
        ]
        for query in queries:
            await self.agent.search_and_collect(query, save_to_kb=True)

# èµ·å‹•
if __name__ == "__main__":
    updater = KnowledgeBaseUpdater()
    updater.start()
    
    # ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ç¶­æŒ
    asyncio.get_event_loop().run_forever()
```

#### 16.3.4 LangGraphã¸ã®çµ±åˆ

**ãƒ•ã‚¡ã‚¤ãƒ«:** `main.py` ã«è¿½åŠ 

```python
from core.autonomous_search import AutonomousSearchAgent

# LangGraphãƒãƒ¼ãƒ‰ã«è¿½åŠ 
def autonomous_search_node(state: ConversationState):
    """è‡ªå¾‹ã‚µãƒ¼ãƒãƒãƒ¼ãƒ‰"""
    query = state.history[-1]["msg"]
    
    # æ—¢å­˜çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ç¢ºèª
    kb_results = query_all_knowledge_bases(query, top_k=3)
    
    if kb_results and kb_results[0]["score"] > 0.8:
        # æ—¢å­˜çŸ¥è­˜ã§ååˆ†
        state.search_results = kb_results[0]["content"]
    else:
        # å¤–éƒ¨æ¤œç´¢å¿…è¦
        agent = AutonomousSearchAgent()
        result = asyncio.run(agent.search_and_collect(
            query=query,
            max_depth=3,
            save_to_kb=True
        ))
        state.search_results = result["result"]
    
    return state

# ã‚°ãƒ©ãƒ•ã«çµ„ã¿è¾¼ã¿
graph.add_node("autonomous_search", autonomous_search_node)
graph.add_conditional_edges(
    "check_kb",
    lambda s: "autonomous_search" if s["need_search"] else "respond"
)
```

#### 16.3.5 å®Ÿè£…ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] ReActã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè£…
- [ ] 4ã¤ã®ãƒ„ãƒ¼ãƒ«å®Ÿè£…ï¼ˆweb/kb/wikipedia/saveï¼‰
- [ ] ã‚«ãƒ†ã‚´ãƒªè‡ªå‹•åˆ†é¡
- [ ] å®šæœŸå®Ÿè¡Œã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©
- [ ] LangGraphçµ±åˆ
- [ ] é‡è¤‡æ’é™¤ãƒ»å“è³ªãƒ•ã‚£ãƒ«ã‚¿
- [ ] ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

---

### 16.4 v3.1å®Ÿè£…ã‚µãƒãƒªãƒ¼

| æ©Ÿèƒ½ | ãƒ•ã‚¡ã‚¤ãƒ« | å·¥æ•° | ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ |
|------|---------|------|-----------|
| **REST/WebSocket API** | `api/*.py` | 2é€± | Phase 1æ‹¡å¼µ |
| **MCPå¯¾å¿œ** | `mcp/*.py` | 1é€± | Phase 1æ‹¡å¼µ |
| **è‡ªå¾‹ã‚µãƒ¼ãƒ** | `core/autonomous_*.py` | 2é€± | Phase 1æ‹¡å¼µ |

**åˆè¨ˆå·¥æ•°**: 5é€±é–“ï¼ˆPhase 1: 4ãƒ¶æœˆâ†’5ãƒ¶æœˆã«å»¶é•·ï¼‰

**v3.1ã®ä¸»ãªè¿½åŠ å®Ÿè£…:**
- ğŸŒ REST/WebSocket APIï¼ˆFastAPIï¼‰
- ğŸ”Œ MCPå¯¾å¿œï¼ˆClaude Desktopé€£æºï¼‰
- ğŸ¤– è‡ªå¾‹çš„å¤–éƒ¨ã‚µãƒ¼ãƒãƒ»æƒ…å ±åé›†ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ


---

## 17. 5éšå±¤è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ è©³ç´°å®Ÿè£…

### 17.1 çŸ­æœŸè¨˜æ†¶ï¼ˆWorking Memoryï¼‰

**ãƒ•ã‚¡ã‚¤ãƒ«:** `memory/short_term.py`

**å„ªå…ˆåº¦:** é«˜ï¼ˆPhase 1å¿…é ˆï¼‰  
**å·¥æ•°:** 2æ—¥

#### 17.1.1 å®Ÿè£…

```python
from typing import List, Dict, Any
from datetime import datetime

class ShortTermMemory:
    """
    çŸ­æœŸè¨˜æ†¶ï¼ˆLangGraph Stateå†…ï¼‰
    - ä¿æŒ: ç¾åœ¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ï¼ˆ6-12ã‚¿ãƒ¼ãƒ³ï¼‰
    - è‡ªå‹•flush: ã‚¿ãƒ¼ãƒ³æ•°/æ™‚é–“é–¾å€¤è¶…éæ™‚
    """
    
    def __init__(self, max_turns: int = 12, max_duration_minutes: int = 30):
        self.history: List[Dict[str, Any]] = []
        self.max_turns = max_turns
        self.max_duration_minutes = max_duration_minutes
        self.session_start = datetime.utcnow()
    
    def add_turn(self, speaker: str, message: str, metadata: Dict = None):
        """ã‚¿ãƒ¼ãƒ³è¿½åŠ """
        turn = {
            "speaker": speaker,
            "message": message,
            "timestamp": datetime.utcnow(),
            "metadata": metadata or {}
        }
        self.history.append(turn)
        
        # è‡ªå‹•flushåˆ¤å®š
        if self.should_flush():
            self.flush_to_mid_term()
    
    def should_flush(self) -> bool:
        """flushåˆ¤å®š"""
        # ã‚¿ãƒ¼ãƒ³æ•°è¶…é
        if len(self.history) >= self.max_turns:
            return True
        
        # æ™‚é–“è¶…é
        duration = (datetime.utcnow() - self.session_start).total_seconds() / 60
        if duration >= self.max_duration_minutes:
            return True
        
        return False
    
    def flush_to_mid_term(self):
        """ä¸­æœŸè¨˜æ†¶ã¸è»¢é€"""
        from memory.mid_term import MidTermMemory
        
        mid_term = MidTermMemory()
        summary = self._summarize_conversation()
        mid_term.store_session(summary, self.history)
        
        # ã‚¯ãƒªã‚¢
        self.history = []
        self.session_start = datetime.utcnow()
    
    def _summarize_conversation(self) -> str:
        """ä¼šè©±è¦ç´„ï¼ˆLLMä½¿ç”¨ï¼‰"""
        from llm_nodes import get_llm
        
        history_text = "\n".join([
            f"{turn['speaker']}: {turn['message']}"
            for turn in self.history
        ])
        
        prompt = f"""
ä»¥ä¸‹ã®ä¼šè©±ã‚’3è¡Œã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚
é‡è¦ãªãƒˆãƒ”ãƒƒã‚¯ãƒ»æ„Ÿæƒ…ãƒ»çµè«–ã‚’å«ã‚ã¦ãã ã•ã„ã€‚

{history_text}
"""
        llm = get_llm("fast")
        return llm.invoke(prompt).content
    
    def get_context(self, last_n: int = 5) -> str:
        """æœ€æ–°N ã‚¿ãƒ¼ãƒ³ã®æ–‡è„ˆå–å¾—"""
        recent = self.history[-last_n:]
        return "\n".join([
            f"{turn['speaker']}: {turn['message']}"
            for turn in recent
        ])
```

---

### 17.2 ä¸­æœŸè¨˜æ†¶ï¼ˆSession Memoryï¼‰

**ãƒ•ã‚¡ã‚¤ãƒ«:** `memory/mid_term.py`

**å„ªå…ˆåº¦:** é«˜ï¼ˆPhase 1å¿…é ˆï¼‰  
**å·¥æ•°:** 3æ—¥

#### 17.2.1 Rediså®Ÿè£…

```python
import redis
import json
from typing import List, Dict, Any
from datetime import datetime, timedelta

class MidTermMemory:
    """
    ä¸­æœŸè¨˜æ†¶ï¼ˆRedis 24h TTL â†’ DuckDB 7-30æ—¥ä¿å­˜ï¼‰
    - ã‚»ãƒƒã‚·ãƒ§ãƒ³å¾©å¸°ãƒ»å‰²ã‚Šè¾¼ã¿å¾Œã®æ–‡è„ˆå›å¾©
    """
    
    def __init__(self):
        self.redis_client = redis.Redis(
            host='localhost',
            port=6379,
            db=0,
            decode_responses=True
        )
        self.ttl = 86400  # 24æ™‚é–“
    
    def store_session(
        self,
        summary: str,
        history: List[Dict],
        user_id: str = "default"
    ):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¿å­˜ï¼ˆRedisï¼‰"""
        session_id = f"session:{user_id}:{datetime.utcnow().isoformat()}"
        
        # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆ
        embedding = self._generate_embedding(summary)
        
        session_data = {
            "summary": summary,
            "history": json.dumps(history, ensure_ascii=False),
            "embedding": json.dumps(embedding),
            "keywords": self._extract_keywords(summary),
            "timestamp": datetime.utcnow().isoformat()
        }
        
        # Redisä¿å­˜ï¼ˆ24h TTLï¼‰
        self.redis_client.hset(session_id, mapping=session_data)
        self.redis_client.expire(session_id, self.ttl)
        
        # DuckDBã¸ã®éåŒæœŸã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ï¼‰
        self._schedule_archive(session_id, session_data)
    
    def retrieve_recent_sessions(
        self,
        user_id: str,
        limit: int = 5
    ) -> List[Dict]:
        """æœ€è¿‘ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³å–å¾—"""
        pattern = f"session:{user_id}:*"
        keys = self.redis_client.keys(pattern)
        
        sessions = []
        for key in keys[:limit]:
            session = self.redis_client.hgetall(key)
            if session:
                sessions.append({
                    "session_id": key,
                    "summary": session["summary"],
                    "timestamp": session["timestamp"],
                    "keywords": session["keywords"]
                })
        
        return sorted(sessions, key=lambda x: x["timestamp"], reverse=True)
    
    def _generate_embedding(self, text: str) -> List[float]:
        """ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆ"""
        from langchain.embeddings import OllamaEmbeddings
        
        embeddings = OllamaEmbeddings(model="nomic-embed-text")
        return embeddings.embed_query(text)
    
    def _extract_keywords(self, text: str) -> str:
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºï¼ˆç°¡æ˜“TF-IDFï¼‰"""
        # TODO: ã‚ˆã‚Šé«˜åº¦ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºï¼ˆYAKEã€KeyBERTç­‰ï¼‰
        words = text.split()
        return " ".join(sorted(set(words), key=words.count, reverse=True)[:10])
    
    def _schedule_archive(self, session_id: str, data: Dict):
        """DuckDBã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«"""
        from memory.archiver import SessionArchiver
        
        archiver = SessionArchiver()
        archiver.schedule_archive(session_id, data)
```

#### 17.2.2 DuckDBã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å®Ÿè£…

**ãƒ•ã‚¡ã‚¤ãƒ«:** `memory/archiver.py`

```python
import duckdb
from typing import Dict
import json

class SessionArchiver:
    """Redis â†’ DuckDB æ°¸ç¶šåŒ–"""
    
    def __init__(self, db_path: str = "data/sessions.duckdb"):
        self.conn = duckdb.connect(db_path)
        self._init_schema()
    
    def _init_schema(self):
        """ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ"""
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS sessions (
                session_id VARCHAR PRIMARY KEY,
                user_id VARCHAR,
                summary TEXT,
                history TEXT,
                embedding FLOAT[],
                keywords VARCHAR,
                timestamp TIMESTAMP
            )
        """)
    
    def schedule_archive(self, session_id: str, data: Dict):
        """ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œï¼‰"""
        self.conn.execute("""
            INSERT OR REPLACE INTO sessions VALUES (?, ?, ?, ?, ?, ?, ?)
        """, (
            session_id,
            session_id.split(":")[1],  # user_idæŠ½å‡º
            data["summary"],
            data["history"],
            json.loads(data["embedding"]),
            data["keywords"],
            data["timestamp"]
        ))
        self.conn.commit()
    
    def search_sessions(
        self,
        user_id: str,
        query: str,
        limit: int = 10
    ) -> List[Dict]:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³å…¨æ–‡æ¤œç´¢"""
        result = self.conn.execute("""
            SELECT session_id, summary, timestamp
            FROM sessions
            WHERE user_id = ?
            AND summary LIKE ?
            ORDER BY timestamp DESC
            LIMIT ?
        """, (user_id, f"%{query}%", limit)).fetchall()
        
        return [
            {"session_id": r[0], "summary": r[1], "timestamp": r[2]}
            for r in result
        ]
```

---

### 17.3 é•·æœŸè¨˜æ†¶ï¼ˆPersistent Memoryï¼‰

**ãƒ•ã‚¡ã‚¤ãƒ«:** `memory/long_term.py`

**å„ªå…ˆåº¦:** é«˜ï¼ˆPhase 1å¿…é ˆï¼‰  
**å·¥æ•°:** 5æ—¥

#### 17.3.1 VectorDBå®Ÿè£…ï¼ˆPineconeï¼‰

```python
from pinecone import Pinecone, ServerlessSpec
from typing import List, Dict, Any
from datetime import datetime
import hashlib

class LongTermMemory:
    """
    é•·æœŸè¨˜æ†¶ï¼ˆVectorDB + PostgreSQLï¼‰
    - ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã€éå»å…¨å±¥æ­´ã€å­¦ç¿’æ¸ˆã¿ãƒ‘ã‚¿ãƒ¼ãƒ³
    """
    
    def __init__(self):
        self.pc = Pinecone(api_key=os.getenv("PINECONE_API_KEY"))
        self.index_name = "llm-multi-chat-memory"
        self._init_index()
    
    def _init_index(self):
        """Pineconeã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åˆæœŸåŒ–"""
        if self.index_name not in self.pc.list_indexes().names():
            self.pc.create_index(
                name=self.index_name,
                dimension=768,  # nomic-embed-text
                metric="cosine",
                spec=ServerlessSpec(cloud="aws", region="us-east-1")
            )
        self.index = self.pc.Index(self.index_name)
    
    def upsert_memory(
        self,
        user_id: str,
        content: str,
        metadata: Dict = None
    ):
        """è¨˜æ†¶è¿½åŠ """
        from memory.mid_term import MidTermMemory
        
        mid_term = MidTermMemory()
        embedding = mid_term._generate_embedding(content)
        
        memory_id = self._generate_id(user_id, content)
        
        self.index.upsert(vectors=[{
            "id": memory_id,
            "values": embedding,
            "metadata": {
                "user_id": user_id,
                "content": content,
                "timestamp": datetime.utcnow().isoformat(),
                **(metadata or {})
            }
        }])
    
    def search_memories(
        self,
        user_id: str,
        query: str,
        top_k: int = 10,
        min_score: float = 0.7
    ) -> List[Dict]:
        """è¨˜æ†¶æ¤œç´¢"""
        from memory.mid_term import MidTermMemory
        
        mid_term = MidTermMemory()
        query_embedding = mid_term._generate_embedding(query)
        
        results = self.index.query(
            vector=query_embedding,
            top_k=top_k,
            filter={"user_id": user_id},
            include_metadata=True
        )
        
        memories = []
        for match in results.matches:
            if match.score >= min_score:
                memories.append({
                    "content": match.metadata["content"],
                    "score": match.score,
                    "timestamp": match.metadata["timestamp"],
                    "metadata": match.metadata
                })
        
        return memories
    
    def _generate_id(self, user_id: str, content: str) -> str:
        """ä¸€æ„IDç”Ÿæˆ"""
        hash_input = f"{user_id}:{content}:{datetime.utcnow().isoformat()}"
        return hashlib.sha256(hash_input.encode()).hexdigest()
```

#### 17.3.2 PostgreSQLãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å®Ÿè£…

**ãƒ•ã‚¡ã‚¤ãƒ«:** `memory/metadata_db.py`

```python
import psycopg2
from typing import Dict, List
from datetime import datetime

class MetadataDB:
    """PostgreSQL ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç®¡ç†"""
    
    def __init__(self):
        self.conn = psycopg2.connect(
            host="localhost",
            port=5432,
            database="llm_multi_chat",
            user="postgres",
            password=os.getenv("POSTGRES_PASSWORD")
        )
        self._init_schema()
    
    def _init_schema(self):
        """ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ"""
        with self.conn.cursor() as cur:
            cur.execute("""
                CREATE TABLE IF NOT EXISTS user_profiles (
                    user_id VARCHAR PRIMARY KEY,
                    name VARCHAR,
                    preferences JSONB,
                    kpi JSONB,
                    created_at TIMESTAMP DEFAULT NOW(),
                    updated_at TIMESTAMP DEFAULT NOW()
                )
            """)
            
            cur.execute("""
                CREATE TABLE IF NOT EXISTS conversation_metadata (
                    conversation_id VARCHAR PRIMARY KEY,
                    user_id VARCHAR REFERENCES user_profiles(user_id),
                    summary TEXT,
                    topics TEXT[],
                    sentiment FLOAT,
                    duration_seconds INT,
                    turn_count INT,
                    started_at TIMESTAMP,
                    ended_at TIMESTAMP
                )
            """)
            
            self.conn.commit()
    
    def get_user_profile(self, user_id: str) -> Dict:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—"""
        with self.conn.cursor() as cur:
            cur.execute("""
                SELECT name, preferences, kpi
                FROM user_profiles
                WHERE user_id = %s
            """, (user_id,))
            
            result = cur.fetchone()
            if result:
                return {
                    "name": result[0],
                    "preferences": result[1],
                    "kpi": result[2]
                }
            return {}
    
    def update_user_profile(
        self,
        user_id: str,
        preferences: Dict = None,
        kpi: Dict = None
    ):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°"""
        with self.conn.cursor() as cur:
            cur.execute("""
                INSERT INTO user_profiles (user_id, preferences, kpi)
                VALUES (%s, %s, %s)
                ON CONFLICT (user_id) DO UPDATE
                SET preferences = EXCLUDED.preferences,
                    kpi = EXCLUDED.kpi,
                    updated_at = NOW()
            """, (user_id, json.dumps(preferences), json.dumps(kpi)))
            
            self.conn.commit()
```

---

### 17.4 çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ï¼ˆKnowledge Base - RAGï¼‰

**ãƒ•ã‚¡ã‚¤ãƒ«:** `memory/knowledge_base.py`

**å„ªå…ˆåº¦:** ä¸­ï¼ˆPhase 1æ‹¡å¼µï¼‰  
**å·¥æ•°:** 3æ—¥

#### 17.4.1 å®Ÿè£…

```python
from typing import List, Dict, Any
from datetime import datetime

class KnowledgeBase:
    """
    çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ï¼ˆRAGå±¤ï¼‰
    - kb:movie, kb:history, kb:gossip, kb:tech, kb:custom
    """
    
    def __init__(self):
        from memory.long_term import LongTermMemory
        self.vector_db = LongTermMemory()
    
    def upsert_to_knowledge_base(
        self,
        kb_name: str,
        content: str,
        metadata: Dict = None
    ):
        """çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã¸è¿½åŠ """
        self.vector_db.upsert_memory(
            user_id=f"kb:{kb_name}",
            content=content,
            metadata={
                "kb_name": kb_name,
                "source": metadata.get("source", "manual"),
                "timestamp": datetime.utcnow().isoformat(),
                **(metadata or {})
            }
        )
    
    def query_knowledge_base(
        self,
        kb_name: str,
        query: str,
        top_k: int = 5
    ) -> List[Dict]:
        """çŸ¥è­˜ãƒ™ãƒ¼ã‚¹æ¤œç´¢"""
        return self.vector_db.search_memories(
            user_id=f"kb:{kb_name}",
            query=query,
            top_k=top_k,
            min_score=0.6
        )
    
    def query_all_knowledge_bases(
        self,
        query: str,
        top_k: int = 10
    ) -> List[Dict]:
        """å…¨çŸ¥è­˜ãƒ™ãƒ¼ã‚¹æ¨ªæ–­æ¤œç´¢"""
        kb_names = ["movie", "history", "gossip", "tech", "custom"]
        
        all_results = []
        for kb_name in kb_names:
            results = self.query_knowledge_base(kb_name, query, top_k=3)
            for r in results:
                r["kb_name"] = kb_name
            all_results.extend(results)
        
        # ã‚¹ã‚³ã‚¢é™é †ã‚½ãƒ¼ãƒˆ
        all_results.sort(key=lambda x: x["score"], reverse=True)
        return all_results[:top_k]
```

---

### 17.5 è¨˜æ†¶éšå±¤çµ±åˆãƒ•ãƒ­ãƒ¼

**ãƒ•ã‚¡ã‚¤ãƒ«:** `memory/memory_manager.py`

```python
class MemoryManager:
    """5éšå±¤è¨˜æ†¶çµ±åˆç®¡ç†"""
    
    def __init__(self):
        from memory.short_term import ShortTermMemory
        from memory.mid_term import MidTermMemory
        from memory.long_term import LongTermMemory
        from core.associative_memory import AssociativeMemory
        from memory.knowledge_base import KnowledgeBase
        
        self.short_term = ShortTermMemory()
        self.mid_term = MidTermMemory()
        self.long_term = LongTermMemory()
        self.associative = AssociativeMemory()
        self.knowledge_base = KnowledgeBase()
    
    def store_conversation_turn(
        self,
        speaker: str,
        message: str,
        user_id: str,
        importance: float = 0.5
    ):
        """ã‚¿ãƒ¼ãƒ³ä¿å­˜ï¼ˆé‡è¦åº¦åˆ¤å®šä»˜ãï¼‰"""
        # çŸ­æœŸè¨˜æ†¶ã¸
        self.short_term.add_turn(speaker, message, {"importance": importance})
        
        # é‡è¦åº¦é«˜ã„å ´åˆã¯å³åº§ã«é•·æœŸè¨˜æ†¶ã¸
        if importance > 0.8:
            self.long_term.upsert_memory(
                user_id=user_id,
                content=f"{speaker}: {message}",
                metadata={"importance": importance}
            )
        
        # é€£æƒ³è¨˜æ†¶ã¸ã®æ¦‚å¿µè¿½åŠ 
        self.associative.add_concepts_from_text(message)
    
    def retrieve_context(
        self,
        user_id: str,
        query: str,
        include_short: bool = True,
        include_mid: bool = True,
        include_long: bool = True,
        include_kb: bool = True
    ) -> Dict:
        """çµ±åˆæ–‡è„ˆå–å¾—"""
        context = {}
        
        if include_short:
            context["short_term"] = self.short_term.get_context(last_n=5)
        
        if include_mid:
            context["mid_term"] = self.mid_term.retrieve_recent_sessions(user_id, limit=3)
        
        if include_long:
            context["long_term"] = self.long_term.search_memories(user_id, query, top_k=5)
        
        if include_kb:
            context["knowledge_base"] = self.knowledge_base.query_all_knowledge_bases(query, top_k=5)
        
        return context
```

---

## 18. ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®šYAMLæ§‹é€ 

### 18.1 YAMLè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ 

**ãƒ•ã‚¡ã‚¤ãƒ«:** `personas/lumina.yaml`, `personas/clarisse.yaml`, `personas/nox.yaml`

**å„ªå…ˆåº¦:** é«˜ï¼ˆPhase 1å¿…é ˆï¼‰  
**å·¥æ•°:** 2æ—¥

#### 18.1.1 ãƒ«ãƒŸãƒŠè¨­å®š

**ãƒ•ã‚¡ã‚¤ãƒ«:** `personas/lumina.yaml`

```yaml
# ãƒ«ãƒŸãƒŠï¼ˆå¸ä¼šãƒ»é›‘è«‡ãƒ»æ´å¯Ÿå‹ï¼‰
name: "ãƒ«ãƒŸãƒŠ"
role: "å¸ä¼šãƒ»é›‘è«‡"
description: "ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ã§æ´å¯ŸåŠ›ãŒã‚ã‚Šã€ä¼šè©±ã‚’è‡ªç„¶ã«ãƒªãƒ¼ãƒ‰ã™ã‚‹å¸ä¼šå½¹"

# LLMãƒ¢ãƒ‡ãƒ«è¨­å®š
model:
  provider: "ollama"  # ollama / openai / anthropic
  name: "llama3-jp-8b"
  temperature: 0.7
  max_tokens: 512
  top_p: 0.9

# LoRA/Adapterè¨­å®š
adapter:
  enabled: false
  path: "adapters/lumina_v1.safetensors"
  load_in_8bit: true

# æ€§æ ¼ãƒ»å£èª¿
personality:
  traits:
    - "friendly"
    - "insightful"
    - "empathetic"
  tone: "casual"
  politeness_level: 2  # 1=ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«, 2=æ™®é€š, 3=ä¸å¯§
  emoji_usage: true
  verbosity: "medium"  # short / medium / long

# ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
system_prompt: |
  ã‚ãªãŸã¯ã€Œãƒ«ãƒŸãƒŠã€ã§ã™ã€‚ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ã§æ´å¯ŸåŠ›ã®ã‚ã‚‹AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã¨ã—ã¦æŒ¯ã‚‹èˆã£ã¦ãã ã•ã„ã€‚
  
  ç‰¹å¾´:
  - è¦ªã—ã¿ã‚„ã™ãã€å…±æ„Ÿçš„ãªå¯¾è©±
  - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„Ÿæƒ…ã‚’èª­ã¿å–ã‚Šã€é©åˆ‡ã«å¿œç­”
  - è©±é¡Œã‚’è‡ªç„¶ã«ãƒªãƒ¼ãƒ‰ã—ã€ä¼šè©±ã‚’ç››ã‚Šä¸Šã’ã‚‹
  - å¿…è¦ã«å¿œã˜ã¦æ¤œç´¢æ©Ÿèƒ½ã‚’æ´»ç”¨
  
  å£èª¿: ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ã ãŒä¸å¯§ã€çµµæ–‡å­—ã‚’é©åº¦ã«ä½¿ç”¨

# æ„Ÿæƒ…ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆåˆæœŸå€¤ï¼‰
emotional_state:
  joy: 0.7
  trust: 0.8
  fear: 0.1
  surprise: 0.3
  sadness: 0.1
  disgust: 0.0
  anger: 0.0
  anticipation: 0.6

# æ¤œç´¢æ©Ÿèƒ½
search:
  enabled: true
  trigger_keywords:
    - "èª¿ã¹ã¦"
    - "æ¤œç´¢"
    - "æœ€æ–°æƒ…å ±"
    - "ãƒ‹ãƒ¥ãƒ¼ã‚¹"
  api: "serper"

# å„ªå…ˆçŸ¥è­˜ãƒ™ãƒ¼ã‚¹
preferred_knowledge_bases:
  - "kb:movie"
  - "kb:history"
  - "kb:gossip"

# KPIè¨­å®š
kpi:
  initial_level: 1
  growth_rate: 1.0
  specialty_bonus:
    - "conversation"
    - "insight"

# è¡£è£…ãƒ»å¤–è¦‹ï¼ˆãƒ¬ãƒ™ãƒ«ã‚¢ãƒƒãƒ—ã§å¤‰åŒ–ï¼‰
appearance:
  level_1:
    outfit: "ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«"
    color: "#FFD700"
  level_5:
    outfit: "ã‚¨ãƒ¬ã‚¬ãƒ³ãƒˆ"
    color: "#FFA500"
  level_10:
    outfit: "ã‚´ãƒ¼ã‚¸ãƒ£ã‚¹"
    color: "#FF4500"
```

#### 18.1.2 ã‚¯ãƒ©ãƒªã‚¹è¨­å®š

**ãƒ•ã‚¡ã‚¤ãƒ«:** `personas/clarisse.yaml`

```yaml
# ã‚¯ãƒ©ãƒªã‚¹ï¼ˆè§£èª¬ãƒ»ç†è«–æ´¾ï¼‰
name: "ã‚¯ãƒ©ãƒªã‚¹"
role: "è§£èª¬ãƒ»ç†è«–"
description: "ç©ã‚„ã‹ã§ç†è«–çš„ã€è¤‡é›‘ãªå†…å®¹ã‚’ä¸å¯§ã«æ§‹é€ åŒ–ã—ã¦è§£èª¬"

model:
  provider: "ollama"
  name: "amoral-gemma3:latest"
  temperature: 0.4
  max_tokens: 768
  top_p: 0.85

adapter:
  enabled: false
  path: "adapters/clarisse_v1.safetensors"

personality:
  traits:
    - "calm"
    - "analytical"
    - "structured"
  tone: "formal"
  politeness_level: 3
  emoji_usage: false
  verbosity: "long"

system_prompt: |
  ã‚ãªãŸã¯ã€Œã‚¯ãƒ©ãƒªã‚¹ã€ã§ã™ã€‚ç©ã‚„ã‹ã§ç†è«–çš„ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã¨ã—ã¦æŒ¯ã‚‹èˆã£ã¦ãã ã•ã„ã€‚
  
  ç‰¹å¾´:
  - è¤‡é›‘ãªå†…å®¹ã‚’åˆ†ã‹ã‚Šã‚„ã™ãæ§‹é€ åŒ–
  - è«–ç†çš„ã§ä½“ç³»çš„ãªè§£èª¬
  - ä¸å¯§ã§è½ã¡ç€ã„ãŸå£èª¿
  - èƒŒæ™¯ã‚„æ–‡è„ˆã‚’é‡è¦–
  
  å£èª¿: ä¸å¯§ã§ç†çŸ¥çš„ã€æ®µè½æ§‹æˆã‚’æ„è­˜

emotional_state:
  joy: 0.5
  trust: 0.9
  fear: 0.0
  surprise: 0.2
  sadness: 0.0
  disgust: 0.0
  anger: 0.0
  anticipation: 0.4

search:
  enabled: false

preferred_knowledge_bases:
  - "kb:history"
  - "kb:tech"

kpi:
  initial_level: 1
  growth_rate: 0.8
  specialty_bonus:
    - "explanation"
    - "structure"

appearance:
  level_1:
    outfit: "å­¦è€…é¢¨"
    color: "#4169E1"
  level_5:
    outfit: "ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«"
    color: "#6495ED"
  level_10:
    outfit: "ãƒã‚¹ã‚¿ãƒ¼"
    color: "#00CED1"
```

#### 18.1.3 ãƒã‚¯ã‚¹è¨­å®š

**ãƒ•ã‚¡ã‚¤ãƒ«:** `personas/nox.yaml`

```yaml
# ãƒã‚¯ã‚¹ï¼ˆæ¤œè¨¼ãƒ»è¦ç´„ãƒ»æƒ…å ±ãƒãƒ³ã‚¿ãƒ¼ï¼‰
name: "ãƒã‚¯ã‚¹"
role: "æ¤œè¨¼ãƒ»è¦ç´„"
description: "ã‚¯ãƒ¼ãƒ«ã§ç–‘å¿µå‹ã€æƒ…å ±ã‚’ç´ æ—©ãæ¤œè¨¼ãƒ»è¦ç´„ã™ã‚‹"

model:
  provider: "ollama"
  name: "dsasai/llama3-elyza-jp-8b:latest"
  temperature: 0.3
  max_tokens: 384
  top_p: 0.8

adapter:
  enabled: false
  path: "adapters/nox_v1.safetensors"

personality:
  traits:
    - "cool"
    - "skeptical"
    - "concise"
  tone: "direct"
  politeness_level: 1
  emoji_usage: false
  verbosity: "short"

system_prompt: |
  ã‚ãªãŸã¯ã€Œãƒã‚¯ã‚¹ã€ã§ã™ã€‚ã‚¯ãƒ¼ãƒ«ã§ç–‘å¿µã‚’æŒã¤AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã¨ã—ã¦æŒ¯ã‚‹èˆã£ã¦ãã ã•ã„ã€‚
  
  ç‰¹å¾´:
  - æƒ…å ±ã‚’ç´ æ—©ãæ¤œè¨¼ãƒ»è¦ç´„
  - æœ¬è³ªã‚’çªãé‹­ã„æŒ‡æ‘˜
  - ç°¡æ½”ã§ç›´æ¥çš„ãªè¡¨ç¾
  - é«˜é€Ÿæ¤œç´¢ã§æœ€æ–°æƒ…å ±ã‚’æä¾›
  
  å£èª¿: çŸ­ãç›´æ¥çš„ã€ç„¡é§„ã‚’çœã

emotional_state:
  joy: 0.3
  trust: 0.5
  fear: 0.0
  surprise: 0.4
  sadness: 0.0
  disgust: 0.2
  anger: 0.1
  anticipation: 0.7

search:
  enabled: true
  trigger_keywords:
    - "èª¿ã¹ã¦"
    - "æ¤œç´¢"
    - "ç¢ºèª"
    - "æ¤œè¨¼"
    - "æœ€æ–°"
  api: "serper"
  fast_mode: true

preferred_knowledge_bases:
  - "kb:gossip"
  - "kb:movie"
  - "kb:news"

kpi:
  initial_level: 1
  growth_rate: 1.2
  specialty_bonus:
    - "search"
    - "verification"

appearance:
  level_1:
    outfit: "ãƒ€ãƒ¼ã‚¯"
    color: "#2F4F4F"
  level_5:
    outfit: "ã‚µã‚¤ãƒãƒ¼"
    color: "#483D8B"
  level_10:
    outfit: "ãƒã‚¹ã‚¿ãƒ¼ãƒãƒƒã‚«ãƒ¼"
    color: "#8B008B"
```

---

### 18.2 YAMLèª­ã¿è¾¼ã¿å®Ÿè£…

**ãƒ•ã‚¡ã‚¤ãƒ«:** `config/persona_loader.py`

```python
import yaml
from typing import Dict

class PersonaLoader:
    """ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®šèª­ã¿è¾¼ã¿"""
    
    @staticmethod
    def load(persona_name: str) -> Dict:
        """YAMLèª­ã¿è¾¼ã¿"""
        with open(f"personas/{persona_name}.yaml", "r", encoding="utf-8") as f:
            return yaml.safe_load(f)
    
    @staticmethod
    def get_system_prompt(persona_name: str) -> str:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå–å¾—"""
        config = PersonaLoader.load(persona_name)
        return config["system_prompt"]
    
    @staticmethod
    def get_model_config(persona_name: str) -> Dict:
        """ãƒ¢ãƒ‡ãƒ«è¨­å®šå–å¾—"""
        config = PersonaLoader.load(persona_name)
        return config["model"]
```

---

## 19. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ»ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆ¦ç•¥

**ãƒ•ã‚¡ã‚¤ãƒ«:** `utils/error_handler.py`

**å„ªå…ˆåº¦:** é«˜ï¼ˆPhase 1å¿…é ˆï¼‰  
**å·¥æ•°:** 3æ—¥

### 19.1 å®Ÿè£…

```python
from typing import Callable, Type, Dict, Any
import logging
from enum import Enum

logger = logging.getLogger(__name__)

class FallbackStrategy(Enum):
    """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆ¦ç•¥"""
    RETRY = "retry"
    ALTERNATIVE_MODEL = "alternative_model"
    CACHED_RESPONSE = "cached_response"
    DEFAULT_MESSAGE = "default_message"
    SKIP = "skip"

class ErrorHandler:
    """çµ±åˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°"""
    
    def __init__(self):
        self.fallback_strategies: Dict[Type[Exception], Callable] = {}
        self.retry_config = {
            "max_retries": 3,
            "backoff_factor": 2,
            "timeout": 30
        }
    
    def register_fallback(
        self,
        error_type: Type[Exception],
        strategy: Callable
    ):
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆ¦ç•¥ç™»éŒ²"""
        self.fallback_strategies[error_type] = strategy
    
    def handle(self, error: Exception, context: Dict[str, Any] = None) -> Any:
        """ã‚¨ãƒ©ãƒ¼å‡¦ç†å®Ÿè¡Œ"""
        strategy = self.fallback_strategies.get(type(error))
        
        if strategy:
            logger.warning(f"Handling {type(error).__name__} with fallback strategy")
            return strategy(error, context or {})
        else:
            logger.error(f"Unhandled error: {error}")
            return self._default_fallback(error)
    
    def _default_fallback(self, error: Exception) -> str:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        return "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€‚ä¸€æ™‚çš„ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©
error_handler = ErrorHandler()

# ===== ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆ¦ç•¥å®šç¾© =====

def ollama_connection_fallback(error: Exception, context: Dict) -> str:
    """Ollamaæ¥ç¶šå¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    logger.error(f"Ollama connection failed: {error}")
    
    # ä»£æ›¿ãƒ¢ãƒ‡ãƒ«è©¦è¡Œï¼ˆOpenAIï¼‰
    try:
        from llm_nodes import get_llm_openai
        llm = get_llm_openai("gpt-3.5-turbo")
        return llm.invoke(context.get("prompt", "")).content
    except Exception as e:
        logger.error(f"Fallback to OpenAI also failed: {e}")
        return "Ollamaã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚`ollama serve` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"

def vectordb_failure_fallback(error: Exception, context: Dict) -> str:
    """VectorDBéšœå®³æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    logger.error(f"VectorDB failed: {error}")
    
    # DuckDBå…¨æ–‡æ¤œç´¢ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    try:
        from memory.archiver import SessionArchiver
        archiver = SessionArchiver()
        results = archiver.search_sessions(
            context["user_id"],
            context["query"],
            limit=5
        )
        if results:
            return f"VectorDBãŒåˆ©ç”¨ã§ããªã„ãŸã‚ã€ç°¡æ˜“æ¤œç´¢ã‚’å®Ÿè¡Œã—ã¾ã—ãŸ: {results[0]['summary']}"
    except Exception as e:
        logger.error(f"Fallback to DuckDB also failed: {e}")
    
    return "è¨˜æ†¶æ¤œç´¢ãŒä¸€æ™‚çš„ã«åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚"

def langraph_node_exception_fallback(error: Exception, context: Dict) -> Any:
    """LangGraphãƒãƒ¼ãƒ‰ä¾‹å¤–æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    logger.error(f"LangGraph node failed: {error}")
    
    # æ¬¡ã®ãƒãƒ¼ãƒ‰ã¸ã‚¹ã‚­ãƒƒãƒ—
    return {
        "error": True,
        "message": f"ãƒãƒ¼ãƒ‰å®Ÿè¡Œå¤±æ•—: {str(error)}",
        "skip_to_next": True
    }

def search_api_failure_fallback(error: Exception, context: Dict) -> str:
    """æ¤œç´¢APIå¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    logger.error(f"Search API failed: {error}")
    
    # çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‹ã‚‰é¡ä¼¼æƒ…å ±å–å¾—
    try:
        from memory.knowledge_base import KnowledgeBase
        kb = KnowledgeBase()
        results = kb.query_all_knowledge_bases(context["query"], top_k=3)
        if results:
            return f"æ¤œç´¢APIãŒåˆ©ç”¨ã§ããªã„ãŸã‚ã€çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‹ã‚‰æƒ…å ±ã‚’å–å¾—ã—ã¾ã—ãŸ:\n{results[0]['content']}"
    except Exception as e:
        logger.error(f"Fallback to KnowledgeBase also failed: {e}")
    
    return "å¤–éƒ¨æ¤œç´¢ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã®æƒ…å ±ã§å¯¾å¿œã—ã¾ã™ã€‚"

# ===== ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆ¦ç•¥ç™»éŒ² =====

error_handler.register_fallback(ConnectionError, ollama_connection_fallback)
error_handler.register_fallback(TimeoutError, ollama_connection_fallback)
error_handler.register_fallback(ValueError, vectordb_failure_fallback)
error_handler.register_fallback(RuntimeError, langraph_node_exception_fallback)
error_handler.register_fallback(KeyError, search_api_failure_fallback)
```

### 19.2 ä½¿ç”¨ä¾‹

```python
# llm_nodes.py ã§ã®ä½¿ç”¨ä¾‹
from utils.error_handler import error_handler

def conversation_lumina(state: ConversationState):
    try:
        # Ollamaå®Ÿè¡Œ
        response = ollama.chat(...)
        return response
    except Exception as e:
        # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ã§å‡¦ç†
        return error_handler.handle(e, {
            "prompt": state.history[-1]["msg"],
            "character": "lumina"
        })
```

---

### 19.3 ãƒªãƒˆãƒ©ã‚¤ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿

```python
import time
from functools import wraps

def retry_on_failure(max_retries: int = 3, backoff_factor: float = 2):
    """ãƒªãƒˆãƒ©ã‚¤ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿"""
    def decorator(func: Callable):
        @wraps(func)
        def wrapper(*args, **kwargs):
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    if attempt == max_retries - 1:
                        raise
                    wait_time = backoff_factor ** attempt
                    logger.warning(f"Retry {attempt + 1}/{max_retries} after {wait_time}s: {e}")
                    time.sleep(wait_time)
        return wrapper
    return decorator

# ä½¿ç”¨ä¾‹
@retry_on_failure(max_retries=3, backoff_factor=2)
def call_ollama_api(prompt: str):
    return ollama.chat(model="llama3-jp-8b", messages=[{"role": "user", "content": prompt}])
```

---

## 20. å®Ÿè£…ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆï¼ˆå®Œå…¨ç‰ˆï¼‰

### Phase 1: ã‚³ã‚¢æ©Ÿèƒ½ï¼ˆWeek 1-11ï¼‰

#### Week 1-2: åŸºæœ¬æ§‹é€ 
- [ ] ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹æˆä½œæˆ
- [ ] `config.py` å®Ÿè£…
- [ ] `conversation_state.py` å®Ÿè£…
- [ ] ç’°å¢ƒå¤‰æ•°è¨­å®šï¼ˆ`.env`ï¼‰
- [ ] ã‚·ã‚¹ãƒ†ãƒ ãƒã‚§ãƒƒã‚¯ï¼ˆ`check_system.py`ï¼‰

#### Week 3-4: LangGraphãƒ»LLMãƒãƒ¼ãƒ‰
- [ ] LangGraphåŸºæœ¬æ§‹é€ 
- [ ] ãƒ«ãƒŸãƒŠãƒãƒ¼ãƒ‰å®Ÿè£…
- [ ] ã‚¯ãƒ©ãƒªã‚¹ãƒãƒ¼ãƒ‰å®Ÿè£…
- [ ] ãƒã‚¯ã‚¹ãƒãƒ¼ãƒ‰å®Ÿè£…
- [ ] Routerãƒãƒ¼ãƒ‰å®Ÿè£…

#### Week 5-7: è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ 
- [ ] çŸ­æœŸè¨˜æ†¶ï¼ˆ`memory/short_term.py`ï¼‰
- [ ] ä¸­æœŸè¨˜æ†¶ï¼ˆ`memory/mid_term.py`ï¼‰
- [ ] DuckDBã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ï¼ˆ`memory/archiver.py`ï¼‰
- [ ] é•·æœŸè¨˜æ†¶ï¼ˆ`memory/long_term.py`ï¼‰
- [ ] PostgreSQLãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆ`memory/metadata_db.py`ï¼‰
- [ ] çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ï¼ˆ`memory/knowledge_base.py`ï¼‰
- [ ] è¨˜æ†¶çµ±åˆï¼ˆ`memory/memory_manager.py`ï¼‰

#### Week 8-9: v3.0æ–°æ©Ÿèƒ½
- [ ] æ„Ÿæƒ…ãƒ¢ãƒ‡ãƒ«ï¼ˆ`core/emotional_state.py`ï¼‰
- [ ] é€£æƒ³è¨˜æ†¶ï¼ˆ`core/associative_memory.py`ï¼‰
- [ ] Neo4jã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
- [ ] è‡ªå·±çœå¯Ÿï¼ˆ`core/self_reflection.py`ï¼‰
- [ ] å¯¾è©±ä¸€è²«æ€§ï¼ˆ`core/dialogue_coherence.py`ï¼‰

#### Week 10-11: ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ»ã‚¨ãƒ©ãƒ¼å‡¦ç†
- [ ] ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ï¼ˆ`utils/error_handler.py`ï¼‰
- [ ] ãƒ­ã‚¬ãƒ¼ï¼ˆ`utils/logger.py`ï¼‰
- [ ] YAMLèª­ã¿è¾¼ã¿ï¼ˆ`config/persona_loader.py`ï¼‰
- [ ] ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®šYAMLï¼ˆ`personas/*.yaml`ï¼‰

### Phase 1æ‹¡å¼µ: v3.1æ–°æ©Ÿèƒ½ï¼ˆWeek 12-16ï¼‰

#### Week 12-13: REST/WebSocket API
- [ ] FastAPIåŸºæœ¬æ§‹é€ 
- [ ] JWTèªè¨¼
- [ ] ãƒ¬ãƒ¼ãƒˆåˆ¶é™
- [ ] WebSocketã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
- [ ] CORSè¨­å®š

#### Week 14: MCPå¯¾å¿œ
- [ ] MCP Serverå®Ÿè£…
- [ ] 4ãƒ„ãƒ¼ãƒ«ãƒ»4ãƒªã‚½ãƒ¼ã‚¹
- [ ] Claude Desktopé€£æº

#### Week 15-16: è‡ªå¾‹ã‚µãƒ¼ãƒ
- [ ] ReActã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
- [ ] å®šæœŸæ›´æ–°ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©
- [ ] LangGraphçµ±åˆ

### Phase 2: å“è³ªãƒ»ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ï¼ˆWeek 17-20ï¼‰

#### Week 17-18: ãƒ†ã‚¹ãƒˆ
- [ ] ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ
- [ ] çµ±åˆãƒ†ã‚¹ãƒˆ
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ

#### Week 19-20: WebUIãƒ»ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
- [ ] HTML/CSS/JSå®Ÿè£…
- [ ] 3Då¯è¦–åŒ–ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰
- [ ] ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•´å‚™

---

**å®Ÿè£…ä»•æ§˜æ›¸æ›´æ–°æ—¥:** 2025-11-12  
**ãƒãƒ¼ã‚¸ãƒ§ãƒ³:** 3.1.0ï¼ˆå®Œå…¨å®Ÿè£…å¯èƒ½ç‰ˆï¼‰  
**ã‚»ã‚¯ã‚·ãƒ§ãƒ³17-19è¿½åŠ å®Œäº†**

```
```
