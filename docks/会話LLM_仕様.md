
```markdown
# ä¼šè©±LLM_ä»•æ§˜æ›¸.md
## â€• æ°¸ç¶šçš„è¨˜æ†¶ã‚’æŒã¤ãƒãƒ«ãƒLLMä¼šè©±ã‚·ã‚¹ãƒ†ãƒ  ä»•æ§˜æ›¸ï¼ˆæ‹¡å¼µç‰ˆï¼‰ â€•
ï¼ˆãƒ«ãƒŸãƒŠï¼ã‚¯ãƒ©ãƒªã‚¹ï¼ãƒã‚¯ã‚¹ï¼‹æ‹¡å¼µå¯èƒ½ï¼‰

---

## 1. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦

**åç§°:** ä¼šè©±LLMï¼ˆLlm_Multi_Chatï¼‰
**ç›®çš„:**
ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§è¤‡æ•°ã®LLMãŒ**æ°¸ç¶šçš„ãªè¨˜æ†¶ã‚’æŒã¡ãªãŒã‚‰**é€£ç¶šã—ã¦ä¼šè©±ã—ã€å¿…è¦ã«å¿œã˜ã¦æ¤œç´¢ãƒ»æ¨è«–ãƒ»ãƒ¦ãƒ¼ã‚¶ãƒ¼å‰²ã‚Šè¾¼ã¿ã‚’å‡¦ç†ã™ã‚‹
**æ‹¡å¼µå¯èƒ½ãªãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹ä¼šè©±ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯**ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚

**ç‰¹å¾´:**
- **è¤‡æ•°LLMã®åŒæ™‚å‹•ä½œ**: 3ã‚­ãƒ£ãƒ©ï¼ˆãƒ«ãƒŸãƒŠï¼ã‚¯ãƒ©ãƒªã‚¹ï¼ãƒã‚¯ã‚¹ï¼‰ï¼‹ã‚«ã‚¹ã‚¿ãƒ ã‚­ãƒ£ãƒ©ã®å‹•çš„è¿½åŠ ã«å¯¾å¿œ
- **æ°¸ç¶šçš„è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ **: çŸ­æœŸãƒ»ä¸­æœŸãƒ»é•·æœŸè¨˜æ†¶ã‚’éšå±¤åŒ–ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã®ä¼šè©±å±¥æ­´ã‚’æ°¸ç¶šä¿å­˜
- **LangGraphã«ã‚ˆã‚‹çŠ¶æ…‹é·ç§»åˆ¶å¾¡**: è¤‡é›‘ãªä¼šè©±ãƒ•ãƒ­ãƒ¼ã‚’ç®¡ç†
- **ãƒ—ãƒ©ã‚°ã‚¤ãƒ³å‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**: æ–°ã—ã„LLMã‚„ãƒ„ãƒ¼ãƒ«ã‚’å‹•çš„ã«è¿½åŠ å¯èƒ½
- **ãƒ­ãƒ¼ã‚«ãƒ«ï¼‹ã‚¯ãƒ©ã‚¦ãƒ‰ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰**: Ollamaï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ï¼‰ã¨APIï¼ˆClaudeã€GPTç­‰ï¼‰ã‚’ä½µç”¨å¯èƒ½
- **ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å¯¾å¿œ**: ãƒ†ã‚­ã‚¹ãƒˆãƒ»éŸ³å£°ãƒ»ç”»åƒå…¥åŠ›ã«å¯¾å¿œ
- **ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†**: ãƒãƒ«ãƒãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ»ãƒãƒ«ãƒã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’åŒæ™‚ä¸¦è¡Œå‡¦ç†

---

## 2. ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å…¨ä½“åƒï¼ˆæ‹¡å¼µç‰ˆï¼‰

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›å±¤                              â”‚
â”‚  (ãƒ†ã‚­ã‚¹ãƒˆ / éŸ³å£° / ç”»åƒ / ãƒ•ã‚¡ã‚¤ãƒ« / ã‚³ãƒãƒ³ãƒ‰)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              å…¥åŠ›å‡¦ç†ãƒ»å‰å‡¦ç†å±¤                                 â”‚
â”‚  - éŸ³å£°â†’ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ› (Whisper)                                 â”‚
â”‚  - ç”»åƒè§£æ (Vision API / OCR)                                â”‚
â”‚  - ã‚³ãƒãƒ³ãƒ‰è§£æ (@æŒ‡å, /command)                              â”‚
â”‚  - æ„å›³åˆ†é¡ (Intent Classifier)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Router Nodeï¼ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆèªè­˜ãƒ»ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ï¼‰           â”‚
â”‚  - ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡ååˆ¤å®š (@ãƒ«ãƒŸãƒŠ, @all)                             â”‚
â”‚  - ãƒ‰ãƒ¡ã‚¤ãƒ³é©æ€§ã‚¹ã‚³ã‚¢è¨ˆç®—                                        â”‚
â”‚  - è¨˜æ†¶å‚ç…§ï¼ˆéå»ã®æ–‡è„ˆãƒ»ãƒ¦ãƒ¼ã‚¶ãƒ¼å—œå¥½ï¼‰                            â”‚
â”‚  - å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°                                           â”‚
â”‚  - ä¸¦åˆ—/é †æ¬¡å®Ÿè¡Œåˆ¤å®š                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â†“                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Character Pool   â”‚    â”‚  Tool Executor   â”‚
â”‚                   â”‚    â”‚  - Webæ¤œç´¢        â”‚
â”‚  - ãƒ«ãƒŸãƒŠ          â”‚    â”‚  - DBæ¤œç´¢        â”‚
â”‚  - ã‚¯ãƒ©ãƒªã‚¹        â”‚    â”‚  - APIå‘¼ã³å‡ºã—    â”‚
â”‚  - ãƒã‚¯ã‚¹          â”‚    â”‚  - ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œ   â”‚
â”‚  - [ã‚«ã‚¹ã‚¿ãƒ 1]     â”‚    â”‚  - ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œ     â”‚
â”‚  - [ã‚«ã‚¹ã‚¿ãƒ 2]     â”‚    â”‚  - è¨ˆç®—å‡¦ç†       â”‚
â”‚  - ...            â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               LangGraph State Machine                         â”‚
â”‚  - ä¼šè©±ãƒ•ãƒ­ãƒ¼åˆ¶å¾¡                                               â”‚
â”‚  - ä¸¦åˆ—å‡¦ç†ç®¡ç†                                                â”‚
â”‚  - æ¡ä»¶åˆ†å²ãƒ»ãƒ«ãƒ¼ãƒ—                                             â”‚
â”‚  - ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  éšå±¤å‹è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ                              â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ çŸ­æœŸè¨˜æ†¶ (Working Memory)                             â”‚   â”‚
â”‚  â”‚ - LangGraph State (RAM)                              â”‚   â”‚
â”‚  â”‚ - ä¿æŒ: ç¾åœ¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ (6-12ã‚¿ãƒ¼ãƒ³)                     â”‚   â”‚
â”‚  â”‚ - ç”¨é€”: æ–‡è„ˆç¶­æŒã€å³åº§ã®å¿œç­”ç”Ÿæˆ                         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                      â†“ (Flush on threshold)                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ ä¸­æœŸè¨˜æ†¶ (Session Memory)                             â”‚   â”‚
â”‚  â”‚ - Redis (24h TTL) â†’ DuckDB (7-30æ—¥ä¿å­˜)              â”‚   â”‚
â”‚  â”‚ - å†…å®¹: è¦ç´„ + keywords + embedding                   â”‚   â”‚
â”‚  â”‚ - ç”¨é€”: ã‚»ãƒƒã‚·ãƒ§ãƒ³å¾©å¸°ã€å‰²ã‚Šè¾¼ã¿å¾Œã®æ–‡è„ˆå›å¾©              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                      â†“ (Archive periodically)                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ é•·æœŸè¨˜æ†¶ (Persistent Memory)                          â”‚   â”‚
â”‚  â”‚ - VectorDB (Pinecone / Qdrant / ChromaDB)            â”‚   â”‚
â”‚  â”‚ - MetaDB (PostgreSQL / SQLite)                        â”‚   â”‚
â”‚  â”‚ - å†…å®¹: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã€éå»å…¨å±¥æ­´ã€å­¦ç¿’æ¸ˆã¿ãƒ‘ã‚¿ãƒ¼ãƒ³ â”‚   â”‚
â”‚  â”‚ - ç”¨é€”: ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã€é•·æœŸçš„æˆé•·ã€ç¶™ç¶šå­¦ç¿’              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ (Knowledge Base - RAGå±¤)                    â”‚   â”‚
â”‚  â”‚ - kb:movie (æ˜ ç”»æƒ…å ±)                                  â”‚   â”‚
â”‚  â”‚ - kb:history (æ­´å²è³‡æ–™)                                â”‚   â”‚
â”‚  â”‚ - kb:gossip (ãƒˆãƒ¬ãƒ³ãƒ‰)                                 â”‚   â”‚
â”‚  â”‚ - kb:tech (æŠ€è¡“æ–‡æ›¸)                                   â”‚   â”‚
â”‚  â”‚ - kb:custom (ãƒ¦ãƒ¼ã‚¶ãƒ¼å®šç¾©)                             â”‚   â”‚
â”‚  â”‚ - æ›´æ–°: ETL Pipeline (è‡ªå‹•/æ‰‹å‹•)                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  å‡ºåŠ›å‡¦ç†ãƒ»å¾Œå‡¦ç†å±¤                             â”‚
â”‚  - ãƒ†ã‚­ã‚¹ãƒˆæ•´å½¢                                                â”‚
â”‚  - éŸ³å£°åˆæˆ (TTS)                                             â”‚
â”‚  - ç”»åƒç”Ÿæˆ (Stable Diffusion / DALL-E)                       â”‚
â”‚  - Markdown / HTML / JSON å¤‰æ›                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
                  ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸å‡ºåŠ›

````

---

## 3. ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ä»•æ§˜ï¼ˆæ‹¡å¼µç‰ˆï¼‰

### 3.1 æ¨™æº–ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼

| ã‚­ãƒ£ãƒ© | å½¹å‰² | å€‹æ€§ãƒ»å£èª¿ | æ¤œç´¢ | ãƒ„ãƒ¼ãƒ« | å„ªå…ˆDB | ãƒ¢ãƒ‡ãƒ« |
|--------|------|-------------|------|--------|--------|--------|
| **ãƒ«ãƒŸãƒŠ** | å¸ä¼šãƒ»é›‘è«‡ãƒ»æ¨è«– | ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ï¼æ´å¯Ÿå‹ | âœ… | Webæ¤œç´¢, ç”»åƒç”Ÿæˆ | MovieDB, HistoryDB | GPT-4o / Gemini |
| **ã‚¯ãƒ©ãƒªã‚¹** | æ§‹é€ åŒ–ãƒ»è§£èª¬ | ç©ã‚„ã‹ï¼ç†è«–æ´¾ | âŒ | ãƒ‡ãƒ¼ã‚¿åˆ†æ, ã‚°ãƒ©ãƒ•ç”Ÿæˆ | HistoryDB | Claude Sonnet |
| **ãƒã‚¯ã‚¹** | æƒ…å ±ãƒãƒ³ã‚¿ãƒ¼ãƒ»æ¤œè¨¼ | ã‚¯ãƒ¼ãƒ«ï¼è¦ç´„ç‰¹åŒ– | âœ…ï¼ˆé«˜é€Ÿï¼‰ | ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œç´¢, API | GossipDB, MovieDB | Llama3-JP |

### 3.2 ã‚«ã‚¹ã‚¿ãƒ ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¿½åŠ æ©Ÿèƒ½

- **å‹•çš„ãƒ­ãƒ¼ãƒ‰**: `personas/*.yaml` ã‹ã‚‰è‡ªå‹•èª­ã¿è¾¼ã¿
- **è¨­å®šé …ç›®**:
  ```yaml
  name: "ã‚«ã‚¹ã‚¿ãƒ 1"
  role: "å°‚é–€å®¶"
  personality: "å†·é™ãƒ»åˆ†æçš„"
  model: "ollama:mistral"
  temperature: 0.7
  tools: ["calculator", "code_executor"]
  priority_kb: ["kb:tech"]
  growth_enabled: true
  ```

### 3.3 ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æˆé•·ã‚·ã‚¹ãƒ†ãƒ 

- **KPIãƒ™ãƒ¼ã‚¹æˆé•·**: ãƒ¦ãƒ¼ã‚¶ãƒ¼è©•ä¾¡ã€ã‚¿ã‚¹ã‚¯æˆåŠŸç‡ã§è‡ªå‹•é€²åŒ–
- **LoRAãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°**: ä¼šè©±ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’ï¼ˆæœˆæ¬¡ãƒãƒƒãƒå‡¦ç†ï¼‰
- **ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³**: ãƒ¦ãƒ¼ã‚¶ãƒ¼æ¯ã«ç•°ãªã‚‹å¿œç­”ã‚¹ã‚¿ã‚¤ãƒ«
- **è¡£è£…ãƒ»ã‚¢ãƒã‚¿ãƒ¼å¤‰åŒ–**: ãƒ¬ãƒ™ãƒ«ã‚¢ãƒƒãƒ—æ™‚ã«è¦–è¦šå¤‰åŒ–

---

## 4. æ°¸ç¶šçš„è¨˜æ†¶ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ˆè©³ç´°ç‰ˆï¼‰

### 4.1 è¨˜æ†¶éšå±¤ã®è©³ç´°

| ãƒ¬ã‚¤ãƒ¤ãƒ¼ | ä¿å­˜å…ˆ | TTL | å†…å®¹ | ä¸»ç›®çš„ | ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ— |
|-----------|--------|------|------|--------|------------|
| **çŸ­æœŸè¨˜æ†¶** | LangGraph State (RAM) | 6ã€œ12ã‚¿ãƒ¼ãƒ³ | ç¾åœ¨ã®ä¼šè©±ã‚¹ãƒ¬ãƒƒãƒ‰ | æ–‡è„ˆç¶­æŒãƒ»å³æ™‚å¿œç­” | Redis Snapshot |
| **ä¸­æœŸè¨˜æ†¶** | Redis (24h) â†’ DuckDB (7-30d) | 24hã€œ30d | è¦ç´„ï¼‹keywordsï¼‹embedding | ã‚»ãƒƒã‚·ãƒ§ãƒ³å¾©å¸°ãƒ»å‰²è¾¼ã¿å¯¾å¿œ | æ—¥æ¬¡DuckDB Export |
| **é•·æœŸè¨˜æ†¶** | VectorDB + PostgreSQL | æ°¸ç¶š | å…¨å±¥æ­´ãƒ»ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãƒ»å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³ | ç¶™ç¶šå­¦ç¿’ãƒ»ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚º | é€±æ¬¡S3/MinIO |
| **é€£æƒ³è¨˜æ†¶** | Graph DB (Neo4j) + VectorDB | æ°¸ç¶š | æ¦‚å¿µé–“ã®é–¢é€£æ€§ãƒ»é€£æƒ³ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ | å‰µé€ çš„ç™ºæƒ³ãƒ»è©±é¡Œç™ºå±• | ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¤‡è£½ |
| **çŸ¥è­˜ãƒ™ãƒ¼ã‚¹** | VectorDB(kb:*) | å®šæœŸæ›´æ–° | ãƒ‰ãƒ¡ã‚¤ãƒ³å°‚é–€çŸ¥è­˜ | RAGæ¤œç´¢ãƒ»äº‹å®Ÿå‚ç…§ | ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç† |

### 4.2 è¨˜æ†¶ä¿å­˜ã®ä»•çµ„ã¿

```python
# çŸ­æœŸâ†’ä¸­æœŸã¸ã®Flushå‡¦ç†
def flush_to_mid_term(thread_id, turns):
    summary = generate_summary(turns)  # LLMã§è¦ç´„ç”Ÿæˆ
    keywords = extract_keywords(turns)  # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
    embedding = create_embedding(summary)  # ãƒ™ã‚¯ãƒˆãƒ«åŒ–
    
    redis.setex(f"session:{thread_id}", 86400, {
        "summary": summary,
        "keywords": keywords,
        "embedding": embedding,
        "turn_count": len(turns)
    })
    
    # 24hå¾Œã«DuckDBã¸ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–
    schedule_archive(thread_id, delay=86400)

# ä¸­æœŸâ†’é•·æœŸã¸ã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–
def archive_to_long_term(session_data):
    # VectorDBã¸embeddingä¿å­˜
    vector_db.upsert(
        namespace=f"user:{user_id}",
        vectors=[{
            "id": session_data["thread_id"],
            "values": session_data["embedding"],
            "metadata": {
                "summary": session_data["summary"],
                "keywords": session_data["keywords"],
                "timestamp": now()
            }
        }]
    )
    
    # PostgreSQLã¸ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜
    db.execute("""
        INSERT INTO conversation_history
        (user_id, thread_id, summary, keywords, created_at)
        VALUES (?, ?, ?, ?, ?)
    """, (user_id, thread_id, summary, keywords, now()))
```

### 4.3 è¨˜æ†¶æ¤œç´¢ãƒ¡ã‚«ãƒ‹ã‚ºãƒ 

```python
# ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›æ™‚ã®è¨˜æ†¶å‚ç…§
def retrieve_relevant_memory(user_input, user_id, top_k=5):
    # å…¥åŠ›ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
    query_embedding = create_embedding(user_input)
    
    # é•·æœŸè¨˜æ†¶ã‹ã‚‰é–¢é€£ã™ã‚‹éå»ä¼šè©±ã‚’æ¤œç´¢
    past_contexts = vector_db.query(
        namespace=f"user:{user_id}",
        vector=query_embedding,
        top_k=top_k,
        include_metadata=True
    )
    
    # ä¸­æœŸè¨˜æ†¶ã‹ã‚‰ç›´è¿‘ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’å–å¾—
    recent_sessions = redis.keys(f"session:{user_id}:*")
    
    # çµ±åˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
    context = {
        "past_conversations": past_contexts,
        "recent_sessions": recent_sessions,
        "user_profile": db.get_user_profile(user_id)
    }
    
    return context
```

### 4.4 é€£æƒ³è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ ï¼ˆAssociative Memoryï¼‰

**æ¦‚å¿µ:**
é€£æƒ³è¨˜æ†¶ã¯ã€æ¦‚å¿µãƒ»ãƒˆãƒ”ãƒƒã‚¯ãƒ»æ„Ÿæƒ…ãƒ»çµŒé¨“ã‚’**ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹é€ **ã§ä¿å­˜ã—ã€
äººé–“ã®è„³ã®ã‚ˆã†ã«ã€ŒAã‹ã‚‰Bã‚’æ€ã„å‡ºã™ã€é€£é–çš„ãªè¨˜æ†¶æƒ³èµ·ã‚’å®Ÿç¾ã—ã¾ã™ã€‚

#### 4.4.1 é€£æƒ³è¨˜æ†¶ã®æ§‹é€ 

```python
# ã‚°ãƒ©ãƒ•ãƒ™ãƒ¼ã‚¹ã®é€£æƒ³è¨˜æ†¶
class AssociativeMemory:
    """
    Neo4jã‚°ãƒ©ãƒ•DBã‚’ä½¿ã£ãŸé€£æƒ³è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ 
    ãƒãƒ¼ãƒ‰: æ¦‚å¿µã€ãƒˆãƒ”ãƒƒã‚¯ã€æ„Ÿæƒ…ã€äººç‰©ã€å ´æ‰€
    ã‚¨ãƒƒã‚¸: é–¢é€£æ€§ã€å¼·åº¦ã€æ™‚é–“çš„è¿‘æ¥æ€§
    """
    def __init__(self):
        self.graph_db = Neo4jDriver()
        self.vector_db = VectorDB()
    
    def add_concept(self, concept, embedding, metadata):
        """æ–°ã—ã„æ¦‚å¿µã‚’ã‚°ãƒ©ãƒ•ã«è¿½åŠ """
        # VectorDBã«åŸ‹ã‚è¾¼ã¿ä¿å­˜
        self.vector_db.upsert(
            namespace="associative",
            vectors=[{
                "id": concept,
                "values": embedding,
                "metadata": metadata
            }]
        )
        
        # Graph DBã«ãƒãƒ¼ãƒ‰ä½œæˆ
        self.graph_db.create_node(
            label="Concept",
            properties={
                "name": concept,
                "created_at": now(),
                "activation_count": 0,
                "emotional_valence": metadata.get("emotion", 0)
            }
        )
    
    def link_concepts(self, concept_a, concept_b, relationship_type, strength=1.0):
        """2ã¤ã®æ¦‚å¿µã‚’é–¢é€£ä»˜ã‘"""
        self.graph_db.create_relationship(
            from_node=concept_a,
            to_node=concept_b,
            rel_type=relationship_type,
            properties={
                "strength": strength,
                "created_at": now(),
                "co_occurrence_count": 1
            }
        )
    
    def retrieve_associated_concepts(self, trigger_concept, depth=3, threshold=0.5):
        """
        é€£æƒ³æ¤œç´¢: ãƒˆãƒªã‚¬ãƒ¼æ¦‚å¿µã‹ã‚‰é–¢é€£æ¦‚å¿µã‚’é€£é–çš„ã«å–å¾—
        
        Args:
            trigger_concept: èµ·ç‚¹ã¨ãªã‚‹æ¦‚å¿µ
            depth: æ¢ç´¢æ·±åº¦ï¼ˆä½•ãƒ›ãƒƒãƒ—ã¾ã§è¾¿ã‚‹ã‹ï¼‰
            threshold: é–¢é€£æ€§ã®é–¾å€¤
        
        Returns:
            é–¢é€£æ¦‚å¿µã®ãƒªã‚¹ãƒˆã¨é–¢é€£æ€§ã‚¹ã‚³ã‚¢
        """
        # Graph DBã§é€£æƒ³ãƒ‘ã‚¹ã‚’æ¢ç´¢
        query = """
        MATCH path = (start:Concept {name: $trigger})-[r*1..$depth]->(related:Concept)
        WHERE ALL(rel IN r WHERE rel.strength >= $threshold)
        WITH related,
             reduce(s = 1.0, rel IN r | s * rel.strength) AS path_strength,
             length(path) AS path_length
        RETURN related.name AS concept,
               path_strength AS strength,
               path_length AS distance
        ORDER BY path_strength DESC
        LIMIT 20
        """
        
        results = self.graph_db.execute(query, {
            "trigger": trigger_concept,
            "depth": depth,
            "threshold": threshold
        })
        
        return results
    
    def strengthen_association(self, concept_a, concept_b, delta=0.1):
        """
        é–¢é€£æ€§ã‚’å¼·åŒ–ï¼ˆå…±èµ·é »åº¦ã«åŸºã¥ãå­¦ç¿’ï¼‰
        ãƒ˜ãƒƒãƒ–ã®æ³•å‰‡: "ä¸€ç·’ã«ç™ºç«ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¯çµåˆãŒå¼·åŒ–ã•ã‚Œã‚‹"
        """
        self.graph_db.execute("""
            MATCH (a:Concept {name: $concept_a})-[r]->(b:Concept {name: $concept_b})
            SET r.strength = r.strength + $delta,
                r.co_occurrence_count = r.co_occurrence_count + 1,
                r.last_activated = timestamp()
            RETURN r.strength
        """, {"concept_a": concept_a, "concept_b": concept_b, "delta": delta})
    
    def decay_inactive_associations(self, days_threshold=30, decay_rate=0.05):
        """
        ä½¿ã‚ã‚Œã¦ã„ãªã„é–¢é€£æ€§ã‚’æ¸›è¡°ï¼ˆå¿˜å´æ›²ç·šï¼‰
        """
        self.graph_db.execute("""
            MATCH ()-[r]->()
            WHERE timestamp() - r.last_activated > $threshold
            SET r.strength = r.strength * (1 - $decay_rate)
            WITH r
            WHERE r.strength < 0.1
            DELETE r
        """, {
            "threshold": days_threshold * 86400 * 1000,
            "decay_rate": decay_rate
        })
```

#### 4.4.2 é€£æƒ³è¨˜æ†¶ã®æ´»ç”¨ä¾‹

```python
# ä¾‹1: ä¼šè©±ä¸­ã®é€£æƒ³ãƒˆãƒªã‚¬ãƒ¼
def generate_associative_response(user_input, conversation_history):
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‹ã‚‰é€£æƒ³çš„ãªè©±é¡Œã‚’å±•é–‹
    """
    # å…¥åŠ›ã‹ã‚‰ä¸»è¦æ¦‚å¿µã‚’æŠ½å‡º
    concepts = extract_concepts(user_input)
    
    # å„æ¦‚å¿µã‹ã‚‰é€£æƒ³æ¤œç´¢
    all_associations = []
    for concept in concepts:
        associations = associative_memory.retrieve_associated_concepts(
            trigger_concept=concept,
            depth=2,
            threshold=0.3
        )
        all_associations.extend(associations)
    
    # æœ€ã‚‚å¼·ã„é€£æƒ³ã‚’é¸æŠ
    top_association = max(all_associations, key=lambda x: x["strength"])
    
    # é€£æƒ³ã«åŸºã¥ãå¿œç­”ç”Ÿæˆ
    prompt = f"""
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã€Œ{user_input}ã€ã¨è¨€ã„ã¾ã—ãŸã€‚
    ã“ã‚Œã¯ã€Œ{top_association['concept']}ã€ã‚’é€£æƒ³ã•ã›ã¾ã™ã€‚
    è‡ªç„¶ãªä¼šè©±ã®æµã‚Œã§ã€ã“ã®é€£æƒ³ã«è§¦ã‚ŒãŸè¿”ç­”ã‚’ã—ã¦ãã ã•ã„ã€‚
    """
    
    return generate_response(prompt)

# ä¾‹2: å‰µé€ çš„ç™ºæƒ³æ”¯æ´
def brainstorm_ideas(seed_concept, num_ideas=10):
    """
    é€£æƒ³è¨˜æ†¶ã‚’ä½¿ã£ãŸãƒ–ãƒ¬ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒŸãƒ³ã‚°
    """
    ideas = set()
    frontier = [seed_concept]
    
    while len(ideas) < num_ideas and frontier:
        current = frontier.pop(0)
        
        # é€£æƒ³æ¤œç´¢
        associations = associative_memory.retrieve_associated_concepts(
            trigger_concept=current,
            depth=1,
            threshold=0.2
        )
        
        for assoc in associations:
            if assoc["concept"] not in ideas:
                ideas.add(assoc["concept"])
                frontier.append(assoc["concept"])
                
                if len(ideas) >= num_ideas:
                    break
    
    return list(ideas)

# ä¾‹3: è©±é¡Œè»¢æ›ã®è‡ªç„¶ã•åˆ¤å®š
def evaluate_topic_transition(topic_from, topic_to):
    """
    2ã¤ã®è©±é¡Œé–“ã®é€£æƒ³çš„ã¤ãªãŒã‚Šã‚’è©•ä¾¡
    """
    # æœ€çŸ­ãƒ‘ã‚¹ã‚’æ¢ç´¢
    path = associative_memory.graph_db.execute("""
        MATCH path = shortestPath(
            (a:Concept {name: $from})-[*..5]-(b:Concept {name: $to})
        )
        RETURN path, length(path) AS distance
    """, {"from": topic_from, "to": topic_to})
    
    if not path:
        return 0.0  # é–¢é€£æ€§ãªã—
    
    distance = path[0]["distance"]
    # è·é›¢ãŒè¿‘ã„ã»ã©é«˜ã‚¹ã‚³ã‚¢
    score = 1.0 / (1.0 + distance)
    
    return score
```

#### 4.4.3 é€£æƒ³è¨˜æ†¶ã®å­¦ç¿’ãƒ¡ã‚«ãƒ‹ã‚ºãƒ 

```python
def learn_from_conversation(conversation):
    """
    ä¼šè©±ã‹ã‚‰æ¦‚å¿µã¨é–¢é€£æ€§ã‚’å­¦ç¿’
    """
    # ä¼šè©±ã‹ã‚‰æ¦‚å¿µæŠ½å‡º
    concepts = extract_concepts_from_text(conversation)
    
    # æ™‚é–“çš„è¿‘æ¥æ€§ã«åŸºã¥ãé–¢é€£ä»˜ã‘
    for i, concept_a in enumerate(concepts):
        # å‰å¾Œã®æ¦‚å¿µã¨é–¢é€£ä»˜ã‘ï¼ˆå…±èµ·å­¦ç¿’ï¼‰
        window = concepts[max(0, i-3):min(len(concepts), i+4)]
        
        for concept_b in window:
            if concept_a != concept_b:
                # è¿‘ã„ã»ã©å¼·ã„é–¢é€£æ€§
                distance = abs(concepts.index(concept_a) - concepts.index(concept_b))
                strength = 1.0 / (1.0 + distance * 0.3)
                
                # æ—¢å­˜ã®é–¢é€£æ€§ã‚’å¼·åŒ–ã€ã¾ãŸã¯æ–°è¦ä½œæˆ
                existing_rel = associative_memory.get_relationship(concept_a, concept_b)
                
                if existing_rel:
                    associative_memory.strengthen_association(
                        concept_a, concept_b, delta=strength * 0.1
                    )
                else:
                    associative_memory.link_concepts(
                        concept_a, concept_b,
                        relationship_type="CO_OCCURRED",
                        strength=strength
                    )
    
    # æ„Ÿæƒ…çš„é–¢é€£ã®å­¦ç¿’
    emotion = analyze_emotion(conversation)
    for concept in concepts:
        associative_memory.update_emotional_valence(concept, emotion)
```

#### 4.4.4 é€£æƒ³è¨˜æ†¶ã«ã‚ˆã‚‹é«˜åº¦ãªæ©Ÿèƒ½

| æ©Ÿèƒ½ | èª¬æ˜ | å®Ÿè£…æ–¹æ³• |
|------|------|----------|
| **è©±é¡Œã®è‡ªç„¶ãªå±•é–‹** | é€£æƒ³ã«ã‚ˆã‚‹è©±é¡Œè»¢æ› | Graphæ¢ç´¢ã§é–¢é€£ãƒˆãƒ”ãƒƒã‚¯ç™ºè¦‹ |
| **å‰µé€ çš„ç™ºæƒ³** | æ„å¤–ãªçµ„ã¿åˆã‚ã›ã®ææ¡ˆ | é è·é›¢ãƒãƒ¼ãƒ‰ã®ãƒ–ãƒªãƒƒã‚¸æ¤œç´¢ |
| **è¨˜æ†¶ã®æƒ³èµ·** | ã€Œãã†ã„ãˆã°å‰ã«...ã€ | é¡ä¼¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰ã®é€£æƒ³æ¤œç´¢ |
| **æ–‡è„ˆç†è§£ã®æ·±åŒ–** | æš—é»™ã®å‰æã‚’è£œå®Œ | æ¦‚å¿µé–“ã®é–¢ä¿‚æ€§æ¨è«– |
| **æ„Ÿæƒ…çš„è¨˜æ†¶** | æ„Ÿæƒ…ã‚’ä¼´ã†è¨˜æ†¶ã®å„ªå…ˆæƒ³èµ· | Emotional Valenceã«ã‚ˆã‚‹é‡ã¿ä»˜ã‘ |
| **å¿˜å´ã¨å†å­¦ç¿’** | ä½¿ã‚ãªã„è¨˜æ†¶ã®è‡ªç„¶ãªæ¸›è¡° | Time-based Decay + å†æ´»æ€§åŒ– |

```python
# ä¾‹: æ„Ÿæƒ…ã‚’ä¼´ã†è¨˜æ†¶ã®å„ªå…ˆæƒ³èµ·
def retrieve_emotional_memory(query, emotion_filter="positive", top_k=5):
    """
    ç‰¹å®šã®æ„Ÿæƒ…ã«é–¢é€£ã™ã‚‹è¨˜æ†¶ã‚’å„ªå…ˆçš„ã«æƒ³èµ·
    """
    query_embedding = create_embedding(query)
    
    # VectorDBã§é¡ä¼¼æ¤œç´¢
    candidates = vector_db.query(
        namespace="associative",
        vector=query_embedding,
        top_k=top_k * 3,
        include_metadata=True
    )
    
    # æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ã§å†ãƒ©ãƒ³ã‚­ãƒ³ã‚°
    filtered = [
        c for c in candidates
        if c["metadata"]["emotion"] == emotion_filter
    ]
    
    # Graph DBã§é–¢é€£æ€§ã‚’ç¢ºèª
    enriched = []
    for candidate in filtered[:top_k]:
        associations = associative_memory.retrieve_associated_concepts(
            trigger_concept=candidate["id"],
            depth=1,
            threshold=0.4
        )
        enriched.append({
            "concept": candidate["id"],
            "associations": associations,
            "emotion": candidate["metadata"]["emotion"]
        })
    
    return enriched

#### 4.4.5 é€£æƒ³ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯3Då¯è¦–åŒ–

**ç›®çš„:** ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒé€£æƒ³è¨˜æ†¶ã®æ§‹é€ ã‚’è¦–è¦šçš„ã«ç†è§£ãƒ»æ¢ç´¢ã§ãã‚‹ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹

##### 4.4.5.1 å¯è¦–åŒ–ãƒ‘ãƒãƒ«ã®ä»•æ§˜

```python
class AssociationVisualizationPanel:
    """
    é€£æƒ³ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯3Då¯è¦–åŒ–ãƒ‘ãƒãƒ«
    
    æ©Ÿèƒ½:
    - ON/OFFåˆ‡ã‚Šæ›¿ãˆå¯èƒ½
    - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°
    - ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–æ“ä½œï¼ˆã‚ºãƒ¼ãƒ ãƒ»å›è»¢ãƒ»ãƒãƒ¼ãƒ‰ã‚¯ãƒªãƒƒã‚¯ï¼‰
    - ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆPNG/HTMLï¼‰
    """
    
    def __init__(self):
        self.enabled = False  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆOFF
        self.center_concept = None
        self.depth = 3
        self.threshold = 0.3
        self.layout_engine = "force_directed"  # 'force_directed', 'hierarchical', 'circular'
        self.color_scheme = "strength"  # 'strength', 'category', 'time'
    
    def toggle(self):
        """ãƒ‘ãƒãƒ«ã®ON/OFF"""
        self.enabled = not self.enabled
        if self.enabled:
            self._initialize_visualization()
        else:
            self._cleanup()
    
    def update_center(self, concept):
        """ä¸­å¿ƒæ¦‚å¿µã‚’å¤‰æ›´ã—ã¦ã‚°ãƒ©ãƒ•ã‚’å†æç”»"""
        if not self.enabled:
            return
        
        self.center_concept = concept
        self._render_graph()
    
    def _render_graph(self):
        """3Dã‚°ãƒ©ãƒ•æç”»"""
        import plotly.graph_objects as go
        import networkx as nx
        
        # 1. ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿å–å¾—
        subgraph = associative_memory.get_subgraph(
            self.center_concept, 
            depth=self.depth,
            threshold=self.threshold
        )
        
        # 2. NetworkXã‚°ãƒ©ãƒ•æ§‹ç¯‰
        G = nx.Graph()
        for node in subgraph['nodes']:
            G.add_node(node['id'], **node['attrs'])
        for edge in subgraph['edges']:
            G.add_edge(
                edge['from'], 
                edge['to'], 
                weight=edge['strength']
            )
        
        # 3. 3Dé…ç½®è¨ˆç®—ï¼ˆForce-Directed Layoutï¼‰
        pos = nx.spring_layout(G, dim=3, k=0.5, iterations=50)
        
        # 4. ã‚¨ãƒƒã‚¸æç”»ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        edge_traces = []
        for edge in G.edges(data=True):
            x0, y0, z0 = pos[edge[0]]
            x1, y1, z1 = pos[edge[1]]
            strength = edge[2]['weight']
            
            edge_trace = go.Scatter3d(
                x=[x0, x1, None],
                y=[y0, y1, None],
                z=[z0, z1, None],
                mode='lines',
                line=dict(
                    width=strength * 5,  # å¼·åº¦ã§å¤ªã•å¤‰æ›´
                    color=self._get_edge_color(strength)
                ),
                hoverinfo='text',
                hovertext=f"å¼·åº¦: {strength:.2f}",
                showlegend=False
            )
            edge_traces.append(edge_trace)
        
        # 5. ãƒãƒ¼ãƒ‰æç”»ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        node_x, node_y, node_z = [], [], []
        node_text, node_colors, node_sizes = [], [], []
        
        for node in G.nodes():
            x, y, z = pos[node]
            node_x.append(x)
            node_y.append(y)
            node_z.append(z)
            
            # ä¸­å¿ƒã‹ã‚‰ã®è·é›¢ã§è‰²ãƒ»ã‚µã‚¤ã‚ºæ±ºå®š
            distance = self._calc_distance(node, self.center_concept)
            node_text.append(node)
            node_colors.append(self._get_node_color(distance))
            node_sizes.append(self._get_node_size(distance))
        
        node_trace = go.Scatter3d(
            x=node_x, y=node_y, z=node_z,
            mode='markers+text',
            marker=dict(
                size=node_sizes,
                color=node_colors,
                colorscale='Viridis',
                line=dict(width=2, color='white')
            ),
            text=node_text,
            textposition="top center",
            textfont=dict(size=10),
            hoverinfo='text',
            hovertext=[
                f"{node}<br>è·é›¢: {self._calc_distance(node, self.center_concept)}"
                for node in G.nodes()
            ]
        )
        
        # 6. ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨­å®š
        layout = go.Layout(
            title=f"é€£æƒ³ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯: {self.center_concept}",
            showlegend=False,
            scene=dict(
                xaxis=dict(showgrid=False, zeroline=False, visible=False),
                yaxis=dict(showgrid=False, zeroline=False, visible=False),
                zaxis=dict(showgrid=False, zeroline=False, visible=False),
                bgcolor='rgba(0,0,0,0)'
            ),
            margin=dict(l=0, r=0, t=40, b=0),
            hovermode='closest'
        )
        
        # 7. æç”»
        fig = go.Figure(data=edge_traces + [node_trace], layout=layout)
        
        # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–æ©Ÿèƒ½
        fig.update_layout(
            updatemenus=[{
                'buttons': [
                    {'label': 'å›è»¢',
                     'method': 'animate',
                     'args': [None, {'frame': {'duration': 50}}]},
                    {'label': 'åœæ­¢',
                     'method': 'animate',
                     'args': [[None], {'frame': {'duration': 0}}]}
                ],
                'direction': 'left',
                'pad': {'r': 10, 't': 10},
                'showactive': True,
                'x': 0.1,
                'xanchor': 'left',
                'y': 1.1,
                'yanchor': 'top'
            }]
        )
        
        return fig
    
    def _get_edge_color(self, strength):
        """ã‚¨ãƒƒã‚¸è‰²ï¼ˆå¼·åº¦ãƒ™ãƒ¼ã‚¹ï¼‰"""
        if strength > 0.7:
            return 'rgba(255, 0, 0, 0.8)'  # å¼·ã„: èµ¤
        elif strength > 0.4:
            return 'rgba(255, 165, 0, 0.6)'  # ä¸­: ã‚ªãƒ¬ãƒ³ã‚¸
        else:
            return 'rgba(128, 128, 128, 0.3)'  # å¼±ã„: ã‚°ãƒ¬ãƒ¼
    
    def _get_node_color(self, distance):
        """ãƒãƒ¼ãƒ‰è‰²ï¼ˆè·é›¢ãƒ™ãƒ¼ã‚¹ï¼‰"""
        if distance == 0:
            return '#FF0000'  # ä¸­å¿ƒ: èµ¤
        elif distance == 1:
            return '#FFA500'  # 1ãƒ›ãƒƒãƒ—: ã‚ªãƒ¬ãƒ³ã‚¸
        elif distance == 2:
            return '#FFFF00'  # 2ãƒ›ãƒƒãƒ—: é»„
        else:
            return '#00FF00'  # 3ãƒ›ãƒƒãƒ—: ç·‘
    
    def _get_node_size(self, distance):
        """ãƒãƒ¼ãƒ‰ã‚µã‚¤ã‚ºï¼ˆè·é›¢ãƒ™ãƒ¼ã‚¹ï¼‰"""
        return max(20 - distance * 5, 5)  # è¿‘ã„ã»ã©å¤§ãã
    
    def _calc_distance(self, node, center):
        """ä¸­å¿ƒãƒãƒ¼ãƒ‰ã‹ã‚‰ã®æœ€çŸ­è·é›¢"""
        return associative_memory.shortest_path_length(center, node)
    
    def export_html(self, filename="association_graph.html"):
        """HTMLå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        fig = self._render_graph()
        fig.write_html(filename)
    
    def export_png(self, filename="association_graph.png"):
        """PNGå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        fig = self._render_graph()
        fig.write_image(filename, width=1920, height=1080)
```

##### 4.4.5.2 UIã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«

```python
class VisualizationControls:
    """å¯è¦–åŒ–ãƒ‘ãƒãƒ«ã®ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«"""
    
    def __init__(self, panel: AssociationVisualizationPanel):
        self.panel = panel
    
    def render_controls(self):
        """ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒ‘ãƒãƒ«UI"""
        return {
            "toggle": {
                "type": "button",
                "label": "ğŸ“Š å¯è¦–åŒ–ãƒ‘ãƒãƒ«",
                "action": self.panel.toggle
            },
            "depth": {
                "type": "slider",
                "label": "æ¢ç´¢æ·±åº¦",
                "min": 1,
                "max": 5,
                "value": 3,
                "action": lambda v: setattr(self.panel, 'depth', v)
            },
            "threshold": {
                "type": "slider",
                "label": "é–¢é€£æ€§é–¾å€¤",
                "min": 0.0,
                "max": 1.0,
                "step": 0.1,
                "value": 0.3,
                "action": lambda v: setattr(self.panel, 'threshold', v)
            },
            "layout": {
                "type": "dropdown",
                "label": "ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ",
                "options": ["force_directed", "hierarchical", "circular"],
                "value": "force_directed",
                "action": lambda v: setattr(self.panel, 'layout_engine', v)
            },
            "export": {
                "type": "button_group",
                "buttons": [
                    {"label": "PNG", "action": self.panel.export_png},
                    {"label": "HTML", "action": self.panel.export_html}
                ]
            }
        }
```

##### 4.4.5.3 è‡ªå‹•æ›´æ–°ãƒ¢ãƒ¼ãƒ‰

```python
def enable_live_update(panel, update_interval=1.0):
    """
    ä¼šè©±ã«å¿œã˜ã¦ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã«å¯è¦–åŒ–ã‚’æ›´æ–°
    
    Args:
        panel: å¯è¦–åŒ–ãƒ‘ãƒãƒ«
        update_interval: æ›´æ–°é–“éš”ï¼ˆç§’ï¼‰
    """
    import threading
    import time
    
    def update_loop():
        while panel.enabled:
            # ç¾åœ¨ã®ä¼šè©±ãƒˆãƒ”ãƒƒã‚¯ã‚’å–å¾—
            current_topic = get_current_conversation_topic()
            
            # ãƒ‘ãƒãƒ«ã‚’æ›´æ–°
            if current_topic != panel.center_concept:
                panel.update_center(current_topic)
            
            time.sleep(update_interval)
    
    thread = threading.Thread(target=update_loop, daemon=True)
    thread.start()
```

##### 4.4.5.4 ä½¿ç”¨ä¾‹

```python
# 1. ãƒ‘ãƒãƒ«åˆæœŸåŒ–
viz_panel = AssociationVisualizationPanel()

# 2. ON/OFFåˆ‡ã‚Šæ›¿ãˆ
viz_panel.toggle()  # ON

# 3. ä¼šè©±ä¸­ã®è‡ªå‹•æ›´æ–°
# ãƒ¦ãƒ¼ã‚¶ãƒ¼: ã€Œã‚¤ãƒ³ã‚»ãƒ—ã‚·ãƒ§ãƒ³ã«ã¤ã„ã¦æ•™ãˆã¦ã€
viz_panel.update_center("ã‚¤ãƒ³ã‚»ãƒ—ã‚·ãƒ§ãƒ³")
# â†’ ã€Œã‚¤ãƒ³ã‚»ãƒ—ã‚·ãƒ§ãƒ³ã€ã‚’ä¸­å¿ƒã«ã‚°ãƒ©ãƒ•è¡¨ç¤º
# â†’ ã€Œå¤¢ã€ã€Œè¨˜æ†¶ã€ã€Œãƒãƒ¼ãƒ©ãƒ³ã€ç­‰ãŒè¿‘ãã«è¡¨ç¤º

# 4. ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–æ“ä½œ
# - ãƒã‚¦ã‚¹ãƒ‰ãƒ©ãƒƒã‚°: å›è»¢
# - ãƒ›ã‚¤ãƒ¼ãƒ«: ã‚ºãƒ¼ãƒ 
# - ãƒãƒ¼ãƒ‰ã‚¯ãƒªãƒƒã‚¯: ãã®ãƒãƒ¼ãƒ‰ã‚’ä¸­å¿ƒã«å†æç”»

# 5. OFF
viz_panel.toggle()  # OFF
```

##### 4.4.5.5 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

| é …ç›® | è¨­å®š | ç†ç”± |
|------|------|------|
| æœ€å¤§ãƒãƒ¼ãƒ‰æ•° | 50 | æç”»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ |
| æ›´æ–°é »åº¦ | 1ç§’/å› | CPUè² è·è»½æ¸› |
| ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚° | WebGL | 3Dé«˜é€Ÿæç”» |
| é…å»¶ãƒ­ãƒ¼ãƒ‰ | æœ‰åŠ¹ | åˆæœŸè¡¨ç¤ºé«˜é€ŸåŒ– |

##### 4.4.5.6 UIé…ç½®

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ä¼šè©±ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦                              â”‚
â”‚                                             â”‚
â”‚ ãƒ¦ãƒ¼ã‚¶ãƒ¼: ã‚¤ãƒ³ã‚»ãƒ—ã‚·ãƒ§ãƒ³ã«ã¤ã„ã¦æ•™ãˆã¦      â”‚
â”‚ ãƒ«ãƒŸãƒŠ: ã‚¤ãƒ³ã‚»ãƒ—ã‚·ãƒ§ãƒ³ã¯å¤¢ã¨è¨˜æ†¶ã‚’...       â”‚
â”‚                                             â”‚
â”‚ [ğŸ“Š å¯è¦–åŒ–ãƒ‘ãƒãƒ«: ON]                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚   3Dé€£æƒ³ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚°ãƒ©ãƒ•              â”‚ â”‚
â”‚ â”‚                                         â”‚ â”‚
â”‚ â”‚        â— ã‚¤ãƒ³ã‚»ãƒ—ã‚·ãƒ§ãƒ³                 â”‚ â”‚
â”‚ â”‚       /â”‚\                              â”‚ â”‚
â”‚ â”‚      / | \                             â”‚ â”‚
â”‚ â”‚   å¤¢  è¨˜æ†¶  ãƒãƒ¼ãƒ©ãƒ³                    â”‚ â”‚
â”‚ â”‚    â”‚   â”‚    â”‚                          â”‚ â”‚
â”‚ â”‚ æ½œåœ¨æ„è­˜ æ˜ ç”» ç›£ç£                      â”‚ â”‚
â”‚ â”‚                                         â”‚ â”‚
â”‚ â”‚ [æ·±åº¦: 3] [é–¾å€¤: 0.3] [ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ: â–¼]  â”‚ â”‚
â”‚ â”‚ [PNG] [HTML]                            â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ä»•æ§˜ã«è¿½åŠ å®Œäº†ï¼ãƒ‘ãƒãƒ«ON/OFFã§é€£æƒ³ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’3Då¯è¦–åŒ–ã§ãã¾ã™ã€‚**

```

### 4.5 ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†

```python
# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å—œå¥½ãƒ»ç‰¹æ€§ã‚’å­¦ç¿’
class UserProfile:
    def __init__(self, user_id):
        self.user_id = user_id
        self.preferences = {}  # æ˜ ç”»ã‚¸ãƒ£ãƒ³ãƒ«ã€è©±é¡Œã®å—œå¥½
        self.interaction_history = []  # ã‚­ãƒ£ãƒ©æŒ‡åé »åº¦
        self.growth_data = {}  # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã®é–¢ä¿‚æ€§æ·±åº¦
        
    def update_from_conversation(self, conversation):
        # å¥½ã¿ãƒˆãƒ”ãƒƒã‚¯ã®æŠ½å‡º
        topics = extract_topics(conversation)
        for topic in topics:
            self.preferences[topic] = self.preferences.get(topic, 0) + 1
        
        # æŒ‡åé »åº¦ã®æ›´æ–°
        mentions = extract_mentions(conversation)
        self.interaction_history.append(mentions)
        
        # æ°¸ç¶šåŒ–
        self.save_to_db()
```

---

## 5. ã‚¹ãƒ¬ãƒƒãƒ‰æ§‹é€ ã¨åˆ¤å®š

| ãƒ•ã‚§ãƒ¼ã‚º | æ¡ä»¶ |
|-----------|------|
| **é–‹å§‹** | åˆå›å…¥åŠ›ï¼ãƒˆãƒ”ãƒƒã‚¯å¤‰æ›´ï¼ãƒ‰ãƒ¡ã‚¤ãƒ³å¤‰åŒ–ï¼ã€Œã¨ã“ã‚ã§â€¦ã€ç™ºè¨€ |
| **çµ‚äº†** | é¡ä¼¼åº¦ < 0.75ï¼ã‚¢ã‚¤ãƒ‰ãƒ«10åˆ†ï¼ã‚¿ãƒ¼ãƒ³ä¸Šé™ï¼è©±é¡Œè»¢æ› |
| **çŸ­æœŸä¿æŒ** | æœ€å¤§12ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼‹3ã‚­ãƒ£ãƒ©ï¼‰ |
| **flushå‡¦ç†** | summaryï¼‹keywordsï¼‹embeddingã‚’ç”Ÿæˆã—ä¸­æœŸã¸è»¢é€ |

### ã‚¹ãƒ¬ãƒƒãƒ‰ä¾‹
```jsonc
{
  "thread_id": 42,
  "domain": "movie",
  "turns": [
    {"speaker":"user", "msg":"ã‚¤ãƒ³ã‚»ãƒ—ã‚·ãƒ§ãƒ³ã¿ãŸã„ãªæ˜ ç”»ã‚ã‚‹ï¼Ÿ"},
    {"speaker":"lumina","msg":"ã€ãƒ¡ãƒ¡ãƒ³ãƒˆã€ã‚„ã€ãƒ—ãƒ¬ã‚¹ãƒ†ãƒ¼ã‚¸ã€ãŒè¿‘ã„ã­"}
  ],
  "ct": {"lumina":0,"claris":1,"nox":0}
}
````

---

## 6. ä¼šè©±ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ä»•æ§˜

### ãƒ«ãƒ¼ãƒ«å„ªå…ˆé †

1. **ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å**ï¼š@ãƒ«ãƒŸãƒŠ,@ãƒã‚¯ã‚¹
2. **ãƒ‰ãƒ¡ã‚¤ãƒ³é©æ€§ã‚¹ã‚³ã‚¢**ï¼š`adapter_priority.yaml` â‰¥ 0.6
3. **ãƒ©ã‚¦ãƒ³ãƒ‰ãƒ­ãƒ“ãƒ³ï¼‹ã‚¯ãƒ¼ãƒ«ã‚¿ã‚¤ãƒ **ï¼šé€£æŠ•é˜²æ­¢
4. **ã‚¹ãƒ ãƒ¼ã‚ºè£œæ­£**ï¼šå‰ç™ºè©±è€…ã¨ã®é€£ç¶šåˆ¶å¾¡

### æŒ‡åæ§‹æ–‡

| å…¥åŠ›             | å‹•ä½œ            |
| -------------- | ------------- |
| `@ãƒ«ãƒŸãƒŠ ã“ã‚“ã«ã¡ã¯`   | ãƒ«ãƒŸãƒŠã®ã¿å¿œç­”       |
| `@ãƒ«ãƒŸãƒŠ,@ãƒã‚¯ã‚¹`    | ä¸¡è€…é †ã«ç™ºè©±        |
| `@all` or æŒ‡åãªã— | ãƒ«ãƒŸãƒŠâ†’ã‚¯ãƒ©ãƒªã‚¹â†’ãƒã‚¯ã‚¹é † |

---

## 7. ãƒ¦ãƒ¼ã‚¶ãƒ¼æ²ˆé»™æ™‚ã®è‡ªèµ°

```
IdleWatcher(15s)
   â†“
AutoPromptGeneratorï¼ˆæœªå®Œè©±é¡Œã®æ·±æ˜ã‚Šãƒ»ææ¡ˆï¼‰
   â†“
Router Node
   â†“
Character Nodes
```

* è‡ªå‹•ç™ºè©±3å›å¾Œï¼šã€Œç¶šã‘ã¾ã™ã‹ï¼Ÿã€ã‚’ç¢ºèª
* MaxTurnsåˆ°é”ã§è¦ç´„â†’çµ‚äº†

---

## 8. çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ï¼ˆRAGå±¤ï¼‰- å®Œå…¨ç‰ˆ

### 8.1 ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ†ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆãƒ»è¶£å‘³ã‚«ãƒ†ã‚´ãƒªï¼ˆç‹¬ç«‹DBï¼‰

å„ã‚«ãƒ†ã‚´ãƒªã¯**ç‹¬ç«‹ã—ãŸSQLite DB**ã¨ã—ã¦ç®¡ç†ã—ã€å°‚é–€æ€§ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¢ºä¿ã—ã¾ã™ã€‚

#### 8.1.1 æ˜ åƒãƒ»æ¼”åŠ‡ç³»

| åå‰ç©ºé–“ | ã‚½ãƒ¼ã‚¹ | æ›´æ–°é »åº¦ | ç”¨é€” | ã‚µã‚¤ã‚ºç›®å®‰ | å®Ÿè£… |
|---------|--------|---------|------|-----------|------|
| `kb:movie` | TMDb / IMDb / Wikipedia | é€±æ¬¡ | æ˜ ç”»æƒ…å ± | 500MB | SQLite + FTS5 |
| `kb:tv` | TVMaze / TheTVDB | é€±æ¬¡ | ãƒ‰ãƒ©ãƒãƒ»TV | 300MB | SQLite + FTS5 |
| `kb:anime` | MyAnimeList / AniDB | é€±æ¬¡ | ã‚¢ãƒ‹ãƒ¡ | 200MB | SQLite + FTS5 |
| `kb:theater` | Stagii / Wikipedia | æœˆæ¬¡ | æ¼”åŠ‡ãƒ»èˆå° | 100MB | SQLite + FTS5 |

#### 8.1.2 æ–‡å­¦ãƒ»ã‚³ãƒŸãƒƒã‚¯ç³»

| åå‰ç©ºé–“ | ã‚½ãƒ¼ã‚¹ | æ›´æ–°é »åº¦ | ç”¨é€” | ã‚µã‚¤ã‚ºç›®å®‰ | å®Ÿè£… |
|---------|--------|---------|------|-----------|------|
| `kb:novel` | é’ç©ºæ–‡åº« / Goodreads / Wikipedia | æœˆæ¬¡ | å°èª¬ãƒ»æ–‡å­¦ | 1GB | SQLite + FTS5 |
| `kb:manga` | MyAnimeList / MangaDex / Wikipedia | é€±æ¬¡ | æ¼«ç”» | 300MB | SQLite + FTS5 |
| `kb:lightnovel` | Novelupdates / Wikipedia | æœˆæ¬¡ | ãƒ©ã‚¤ãƒˆãƒãƒ™ãƒ« | 200MB | SQLite + FTS5 |
| `kb:poetry` | é’ç©ºæ–‡åº« / Poetry Foundation | æœˆæ¬¡ | è©©ãƒ»çŸ­æ­Œãƒ»ä¿³å¥ | 50MB | SQLite + FTS5 |

#### 8.1.3 ã‚²ãƒ¼ãƒ ç³»

| åå‰ç©ºé–“ | ã‚½ãƒ¼ã‚¹ | æ›´æ–°é »åº¦ | ç”¨é€” | ã‚µã‚¤ã‚ºç›®å®‰ | å®Ÿè£… |
|---------|--------|---------|------|-----------|------|
| `kb:videogame` | IGDB / Steam / Wikipedia | é€±æ¬¡ | ãƒ“ãƒ‡ã‚ªã‚²ãƒ¼ãƒ  | 500MB | SQLite + FTS5 |
| `kb:boardgame` | BoardGameGeek / Wikipedia | æœˆæ¬¡ | ãƒœãƒ¼ãƒ‰ã‚²ãƒ¼ãƒ  | 200MB | SQLite + FTS5 |
| `kb:tabletop` | RPGGeek / Wikipedia | æœˆæ¬¡ | TRPG | 100MB | SQLite + FTS5 |

#### 8.1.4 éŸ³æ¥½ç³»

| åå‰ç©ºé–“ | ã‚½ãƒ¼ã‚¹ | æ›´æ–°é »åº¦ | ç”¨é€” | ã‚µã‚¤ã‚ºç›®å®‰ | å®Ÿè£… |
|---------|--------|---------|------|-----------|------|
| `kb:music` | MusicBrainz / Spotify / Wikipedia | é€±æ¬¡ | éŸ³æ¥½ãƒ»ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆ | 800MB | SQLite + FTS5 |
| `kb:classical` | IMSLP / Wikipedia | æœˆæ¬¡ | ã‚¯ãƒ©ã‚·ãƒƒã‚¯éŸ³æ¥½ | 200MB | SQLite + FTS5 |
| `kb:jpop` | Oricon / Wikipedia | é€±æ¬¡ | J-POP | 100MB | SQLite + FTS5 |

#### 8.1.5 ä¸€èˆ¬ãƒ»ãã®ä»–

| åå‰ç©ºé–“ | ã‚½ãƒ¼ã‚¹ | æ›´æ–°é »åº¦ | ç”¨é€” | ã‚µã‚¤ã‚ºç›®å®‰ | å®Ÿè£… |
|---------|--------|---------|------|-----------|------|
| `kb:history` | Wikipedia Dump | æœˆæ¬¡ | æ­´å²è³‡æ–™ | 2GB | SQLite + FTS5 |
| `kb:tech` | GitHub / Stack Overflow | é€±æ¬¡ | æŠ€è¡“æ–‡æ›¸ | 1GB | SQLite + FTS5 |
| `kb:news` | News API / RSS | æ¯æ™‚ | ãƒ‹ãƒ¥ãƒ¼ã‚¹ | 200MB | SQLite + FTS5 |
| `kb:gossip` | RSS / SNS | æ¯æœ | ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»ã‚´ã‚·ãƒƒãƒ— | 100MB | SQLite + FTS5 |
| `kb:sports` | ESPN / Wikipedia | æ—¥æ¬¡ | ã‚¹ãƒãƒ¼ãƒ„ | 300MB | SQLite + FTS5 |
| `kb:food` | Cookpad / Wikipedia | æœˆæ¬¡ | æ–™ç†ãƒ»ã‚°ãƒ«ãƒ¡ | 200MB | SQLite + FTS5 |

### 8.2 SQLiteå®Ÿè£…ã«ã‚ˆã‚‹ç‹¬ç«‹DBç®¡ç†

```python
class KnowledgeBaseManager:
    """ã‚«ãƒ†ã‚´ãƒªåˆ¥ç‹¬ç«‹SQLite DBç®¡ç†"""
    
    def __init__(self, base_dir="kb/"):
        self.base_dir = base_dir
        self.dbs = {}
        self._initialize_all_categories()
    
    def _initialize_all_categories(self):
        """å…¨ã‚«ãƒ†ã‚´ãƒªã®DBåˆæœŸåŒ–"""
        categories = [
            # ã‚¨ãƒ³ã‚¿ãƒ¡
            "movie", "tv", "anime", "theater",
            # æ–‡å­¦
            "novel", "manga", "lightnovel", "poetry",
            # ã‚²ãƒ¼ãƒ 
            "videogame", "boardgame", "tabletop",
            # éŸ³æ¥½
            "music", "classical", "jpop",
            # ä¸€èˆ¬
            "history", "tech", "news", "gossip", "sports", "food"
        ]
        
        for cat in categories:
            db_path = f"{self.base_dir}{cat}.db"
            self.dbs[cat] = sqlite3.connect(db_path)
            self._create_schema(cat)
    
    def _create_schema(self, category):
        """ã‚«ãƒ†ã‚´ãƒªæ¯ã®ã‚¹ã‚­ãƒ¼ãƒä½œæˆ"""
        conn = self.dbs[category]
        
        # ãƒ¡ã‚¤ãƒ³ãƒ†ãƒ¼ãƒ–ãƒ«
        conn.execute(f"""
            CREATE TABLE IF NOT EXISTS {category}_items (
                id INTEGER PRIMARY KEY,
                title TEXT NOT NULL,
                content TEXT,
                metadata JSON,
                source TEXT,
                created_at INTEGER,
                updated_at INTEGER
            )
        """)
        
        # å…¨æ–‡æ¤œç´¢ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆFTS5ï¼‰
        conn.execute(f"""
            CREATE VIRTUAL TABLE IF NOT EXISTS {category}_fts
            USING fts5(title, content, tokenize='porter unicode61')
        """)
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        conn.execute(f"""
            CREATE INDEX IF NOT EXISTS idx_{category}_title
            ON {category}_items(title)
        """)
        
        conn.commit()
    
    def search(self, category, query, limit=10):
        """ã‚«ãƒ†ã‚´ãƒªå†…æ¤œç´¢"""
        conn = self.dbs[category]
        
        # FTS5å…¨æ–‡æ¤œç´¢
        cursor = conn.execute(f"""
            SELECT title, content, rank
            FROM {category}_fts
            WHERE {category}_fts MATCH ?
            ORDER BY rank
            LIMIT ?
        """, (query, limit))
        
        return cursor.fetchall()
    
    def add_item(self, category, title, content, metadata=None):
        """ã‚¢ã‚¤ãƒ†ãƒ è¿½åŠ """
        conn = self.dbs[category]
        now = int(time.time())
        
        # ãƒ¡ã‚¤ãƒ³ãƒ†ãƒ¼ãƒ–ãƒ«ã¸æŒ¿å…¥
        cursor = conn.execute(f"""
            INSERT INTO {category}_items
            (title, content, metadata, created_at, updated_at)
            VALUES (?, ?, ?, ?, ?)
        """, (title, content, json.dumps(metadata), now, now))
        
        # FTS5ã¸æŒ¿å…¥
        conn.execute(f"""
            INSERT INTO {category}_fts (title, content)
            VALUES (?, ?)
        """, (title, content))
        
        conn.commit()
        return cursor.lastrowid
```

### 8.3 ã‚«ã‚¹ã‚¿ãƒ çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼å®šç¾©ï¼‰

### 8.2 ã‚«ã‚¹ã‚¿ãƒ çŸ¥è­˜ãƒ™ãƒ¼ã‚¹

```python
# ãƒ¦ãƒ¼ã‚¶ãƒ¼å®šç¾©çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã®è¿½åŠ 
def add_custom_knowledge_base(namespace, source_files, metadata):
    """
    Args:
        namespace: kb:custom_name
        source_files: ["path/to/doc1.pdf", "path/to/doc2.txt"]
        metadata: {"domain": "medical", "language": "ja"}
    """
    documents = []
    for file in source_files:
        content = extract_text(file)
        chunks = split_into_chunks(content, chunk_size=500)
        documents.extend(chunks)
    
    embeddings = embed_documents(documents)
    
    vector_db.upsert(
        namespace=namespace,
        vectors=embeddings,
        metadata=metadata
    )
    

### 8.4 ã‚¯ãƒ­ã‚¹ã‚«ãƒ†ã‚´ãƒªãƒªãƒ³ã‚¯ã‚·ã‚¹ãƒ†ãƒ 

**èª²é¡Œ:** å°èª¬åŸä½œã®ã‚¢ãƒ‹ãƒ¡ãƒ»æ˜ ç”»ãƒ»æ¼«ç”»ã®ã‚ˆã†ãª**ãƒ¡ãƒ‡ã‚£ã‚¢ãƒŸãƒƒã‚¯ã‚¹ä½œå“**ã®æ¨ªæ–­æ¤œç´¢

#### 8.4.1 æ¨å¥¨ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ: çµ±åˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ–¹å¼

```python
class CrossCategoryIndex:
    """
    å„ã‚«ãƒ†ã‚´ãƒªDBé–“ã‚’è»½é‡ã«é€£æºã™ã‚‹çµ±åˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
    
    æ–¹é‡:
    - å„ã‚«ãƒ†ã‚´ãƒªDBã¯ç‹¬ç«‹ã‚’ç¶­æŒ
    - è»½é‡ãªä¸­å¤®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹DBã§ä½œå“IDã‚’ç´ä»˜ã‘
    - ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ã¿æ¤œç´¢ â†’ è©³ç´°ã¯å„ã‚«ãƒ†ã‚´ãƒªDBã‹ã‚‰å–å¾—
    """
    
    def __init__(self):
        # ä¸­å¤®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆè¶…è»½é‡: 10-50MBï¼‰
        self.index_db = sqlite3.connect("kb/index.db")
        self._create_index_schema()
    
    def _create_index_schema(self):
        """çµ±åˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚¹ã‚­ãƒ¼ãƒ"""
        self.index_db.executescript("""
            -- ä½œå“ãƒã‚¹ã‚¿ãƒ¼
            CREATE TABLE IF NOT EXISTS works (
                id INTEGER PRIMARY KEY,
                title TEXT NOT NULL,
                title_ja TEXT,
                title_en TEXT,
                original_title TEXT,
                work_type TEXT,  -- 'original', 'adaptation'
                created_at INTEGER
            );
            
            -- ã‚«ãƒ†ã‚´ãƒªåˆ¥å®Ÿä½“
            CREATE TABLE IF NOT EXISTS work_instances (
                id INTEGER PRIMARY KEY,
                work_id INTEGER,
                category TEXT,  -- 'novel', 'manga', 'anime', 'movie'
                category_item_id INTEGER,  -- å„ã‚«ãƒ†ã‚´ãƒªDBå†…ã®ID
                release_year INTEGER,
                metadata JSON,
                FOREIGN KEY(work_id) REFERENCES works(id)
            );
            
            -- ãƒ¡ãƒ‡ã‚£ã‚¢ãƒŸãƒƒã‚¯ã‚¹é–¢ä¿‚
            CREATE TABLE IF NOT EXISTS adaptations (
                id INTEGER PRIMARY KEY,
                original_work_id INTEGER,
                adapted_work_id INTEGER,
                adaptation_type TEXT,  -- 'manga->anime', 'novel->movie'
                FOREIGN KEY(original_work_id) REFERENCES works(id),
                FOREIGN KEY(adapted_work_id) REFERENCES works(id)
            );
            
            -- å…¨æ–‡æ¤œç´¢ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ã®ã¿ï¼‰
            CREATE VIRTUAL TABLE IF NOT EXISTS works_fts
            USING fts5(title, title_ja, title_en);
            
            -- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
            CREATE INDEX IF NOT EXISTS idx_work_instances_work 
            ON work_instances(work_id);
            
            CREATE INDEX IF NOT EXISTS idx_work_instances_category 
            ON work_instances(category, category_item_id);
            
            CREATE INDEX IF NOT EXISTS idx_adaptations_original 
            ON adaptations(original_work_id);
        """)
    
    def search_cross_category(self, query):
        """
        ã‚¯ãƒ­ã‚¹ã‚«ãƒ†ã‚´ãƒªæ¤œç´¢
        
        ä¾‹: ã€Œé¬¼æ»…ã®åˆƒã€â†’ å°èª¬ãƒ»æ¼«ç”»ãƒ»ã‚¢ãƒ‹ãƒ¡ãƒ»æ˜ ç”»ã‚’å…¨ã¦å–å¾—
        """
        # 1. ã‚¿ã‚¤ãƒˆãƒ«æ¤œç´¢ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ã¿: < 5msï¼‰
        cursor = self.index_db.execute("""
            SELECT DISTINCT w.id, w.title, w.title_ja
            FROM works_fts fts
            JOIN works w ON fts.rowid = w.id
            WHERE works_fts MATCH ?
            LIMIT 10
        """, (query,))
        
        works = cursor.fetchall()
        
        # 2. å„ä½œå“ã®å…¨ã‚«ãƒ†ã‚´ãƒªå®Ÿä½“ã‚’å–å¾—
        results = []
        for work_id, title, title_ja in works:
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‹ã‚‰å„ã‚«ãƒ†ã‚´ãƒªã®å­˜åœ¨ã‚’ç¢ºèª
            instances = self.index_db.execute("""
                SELECT category, category_item_id, release_year
                FROM work_instances
                WHERE work_id = ?
                ORDER BY release_year
            """, (work_id,)).fetchall()
            
            # å„ã‚«ãƒ†ã‚´ãƒªDBã‹ã‚‰è©³ç´°å–å¾—ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
            detailed_instances = []
            for cat, item_id, year in instances:
                # é…å»¶èª­ã¿è¾¼ã¿: å¿…è¦ãªæ™‚ã ã‘è©³ç´°å–å¾—
                detailed_instances.append({
                    "category": cat,
                    "id": item_id,
                    "year": year
                })
            
            results.append({
                "work_id": work_id,
                "title": title,
                "title_ja": title_ja,
                "instances": detailed_instances
            })
        
        return results
    
    def get_adaptations(self, work_id):
        """
        ãƒ¡ãƒ‡ã‚£ã‚¢ãƒŸãƒƒã‚¯ã‚¹å±•é–‹ã‚’å–å¾—
        
        ä¾‹: å°èª¬ã€Œãƒãƒªãƒ¼ãƒ»ãƒãƒƒã‚¿ãƒ¼ã€â†’ æ˜ ç”»8ä½œå“
        """
        cursor = self.index_db.execute("""
            SELECT 
                w.title,
                wi.category,
                wi.release_year,
                a.adaptation_type
            FROM adaptations a
            JOIN works w ON a.adapted_work_id = w.id
            JOIN work_instances wi ON w.id = wi.work_id
            WHERE a.original_work_id = ?
            ORDER BY wi.release_year
        """, (work_id,))
        
        return cursor.fetchall()
    
    def add_work(self, title, title_ja=None, title_en=None):
        """ä½œå“ã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«ç™»éŒ²"""
        cursor = self.index_db.execute("""
            INSERT INTO works (title, title_ja, title_en, created_at)
            VALUES (?, ?, ?, ?)
        """, (title, title_ja, title_en, int(time.time())))
        
        work_id = cursor.lastrowid
        
        # FTS5ã¸ã‚‚ç™»éŒ²
        self.index_db.execute("""
            INSERT INTO works_fts (rowid, title, title_ja, title_en)
            VALUES (?, ?, ?, ?)
        """, (work_id, title, title_ja, title_en))
        
        self.index_db.commit()
        return work_id
    
    def link_instance(self, work_id, category, category_item_id, year=None):
        """ã‚«ãƒ†ã‚´ãƒªå®Ÿä½“ã‚’ãƒªãƒ³ã‚¯"""
        self.index_db.execute("""
            INSERT INTO work_instances 
            (work_id, category, category_item_id, release_year)
            VALUES (?, ?, ?, ?)
        """, (work_id, category, category_item_id, year))
        
        self.index_db.commit()
    
    def link_adaptation(self, original_work_id, adapted_work_id, 
                       adaptation_type):
        """ãƒ¡ãƒ‡ã‚£ã‚¢ãƒŸãƒƒã‚¯ã‚¹é–¢ä¿‚ã‚’ç™»éŒ²"""
        self.index_db.execute("""
            INSERT INTO adaptations 
            (original_work_id, adapted_work_id, adaptation_type)
            VALUES (?, ?, ?)
        """, (original_work_id, adapted_work_id, adaptation_type))
        
        self.index_db.commit()
```

#### 8.4.2 å®Ÿè£…ä¾‹: é¬¼æ»…ã®åˆƒã®ç™»éŒ²

```python
# ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åˆæœŸåŒ–
index = CrossCategoryIndex()

# 1. ä½œå“ç™»éŒ²
work_id = index.add_work(
    title="Demon Slayer", 
    title_ja="é¬¼æ»…ã®åˆƒ",
    title_en="Demon Slayer: Kimetsu no Yaiba"
)

# 2. å„ã‚«ãƒ†ã‚´ãƒªå®Ÿä½“ã‚’ãƒªãƒ³ã‚¯
# æ¼«ç”»ç‰ˆ
manga_id = kb_manga.add_item(
    title="é¬¼æ»…ã®åˆƒ",
    content="å¾å³ å‘¼ä¸–æ™´ã«ã‚ˆã‚‹æ—¥æœ¬ã®æ¼«ç”»...",
    metadata={"author": "å¾å³ å‘¼ä¸–æ™´", "volumes": 23}
)
index.link_instance(work_id, "manga", manga_id, 2016)

# ã‚¢ãƒ‹ãƒ¡ç‰ˆ
anime_id = kb_anime.add_item(
    title="é¬¼æ»…ã®åˆƒ",
    content="ufotableåˆ¶ä½œã®TVã‚¢ãƒ‹ãƒ¡...",
    metadata={"studio": "ufotable", "episodes": 26}
)
index.link_instance(work_id, "anime", anime_id, 2019)

# æ˜ ç”»ç‰ˆ
movie_id = kb_movie.add_item(
    title="åŠ‡å ´ç‰ˆ é¬¼æ»…ã®åˆƒ ç„¡é™åˆ—è»Šç·¨",
    content="2020å¹´å…¬é–‹ã®åŠ‡å ´ç‰ˆã‚¢ãƒ‹ãƒ¡...",
    metadata={"box_office": "404å„„å††"}
)
movie_work_id = index.add_work("Demon Slayer: Mugen Train", "ç„¡é™åˆ—è»Šç·¨")
index.link_instance(movie_work_id, "movie", movie_id, 2020)

# 3. ãƒ¡ãƒ‡ã‚£ã‚¢ãƒŸãƒƒã‚¯ã‚¹é–¢ä¿‚ã‚’ç™»éŒ²
index.link_adaptation(work_id, movie_work_id, "manga->movie")
```

#### 8.4.3 æ¤œç´¢ä¾‹

```python
# ãƒ¦ãƒ¼ã‚¶ãƒ¼: ã€Œé¬¼æ»…ã®åˆƒã®ãƒ¡ãƒ‡ã‚£ã‚¢å±•é–‹ã‚’æ•™ãˆã¦ã€

# 1. ã‚¯ãƒ­ã‚¹ã‚«ãƒ†ã‚´ãƒªæ¤œç´¢
results = index.search_cross_category("é¬¼æ»…ã®åˆƒ")

# çµæœ:
{
    "work_id": 123,
    "title": "Demon Slayer",
    "title_ja": "é¬¼æ»…ã®åˆƒ",
    "instances": [
        {"category": "manga", "id": 456, "year": 2016},
        {"category": "anime", "id": 789, "year": 2019},
        {"category": "movie", "id": 101, "year": 2020}
    ]
}

# 2. å„ã‚«ãƒ†ã‚´ãƒªã®è©³ç´°ã‚’é…å»¶èª­ã¿è¾¼ã¿
manga_detail = kb_manga.get_item(456)
anime_detail = kb_anime.get_item(789)
movie_detail = kb_movie.get_item(101)

# 3. LLMã¸çµ±åˆæƒ…å ±ã‚’æä¾›
response = llm.generate(f"""
é¬¼æ»…ã®åˆƒã®ãƒ¡ãƒ‡ã‚£ã‚¢å±•é–‹:
- æ¼«ç”»: {manga_detail['content']} (2016-)
- ã‚¢ãƒ‹ãƒ¡: {anime_detail['content']} (2019-)
- æ˜ ç”»: {movie_detail['content']} (2020)
""")
```

#### 8.4.4 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹

| å‡¦ç† | æ™‚é–“ | èª¬æ˜ |
|------|------|------|
| ã‚¿ã‚¤ãƒˆãƒ«æ¤œç´¢ | < 5ms | ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹FTS5 |
| å®Ÿä½“ãƒªã‚¹ãƒˆå–å¾— | < 2ms | ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ã¿ |
| è©³ç´°èª­ã¿è¾¼ã¿ | 5-10ms/ã‚«ãƒ†ã‚´ãƒª | å„ã‚«ãƒ†ã‚´ãƒªDB |
| **åˆè¨ˆ** | **< 30ms** | 3ã‚«ãƒ†ã‚´ãƒªã®å ´åˆ |

#### 8.4.5 åˆ©ç‚¹

âœ… **å„ã‚«ãƒ†ã‚´ãƒªDBã¯ç‹¬ç«‹ç¶­æŒ**  
âœ… **ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¯è¶…è»½é‡ï¼ˆ10-50MBï¼‰**  
âœ… **é«˜é€Ÿæ¤œç´¢ï¼ˆ< 30msï¼‰**  
âœ… **é…å»¶èª­ã¿è¾¼ã¿ã§ç„¡é§„ãªã—**  
âœ… **ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹å®¹æ˜“**  

**æ¨å¥¨: çµ±åˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ–¹å¼ã‚’æ¡ç”¨**

    return f"Added {len(documents)} documents to {namespace}"
```

### 8.3 ETL Pipelineï¼ˆè‡ªå‹•æ›´æ–°ï¼‰

```python
from airflow import DAG
from datetime import datetime, timedelta

@dag(schedule="@weekly", start_date=datetime(2025, 1, 1))
def etl_knowledge_base():
    """å®šæœŸçš„ãªçŸ¥è­˜ãƒ™ãƒ¼ã‚¹æ›´æ–°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""
    
    @task
    def fetch_tmdb():
        # TMDb APIã‹ã‚‰æœ€æ–°æ˜ ç”»æƒ…å ±å–å¾—
        return fetch_movies(since=last_update_date())
    
    @task
    def normalize(raw_data):
        # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°
        return clean_and_structure(raw_data)
    
    @task
    def embed(clean_data):
        # Embeddingãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆ
        return create_embeddings(clean_data)
    
    @task
    def load(embeddings):
        # VectorDBã¸ãƒ­ãƒ¼ãƒ‰
        vector_db.upsert(namespace="kb:movie", vectors=embeddings)
    
    # Pipelineå®Ÿè¡Œ
    raw = fetch_tmdb()
    clean = normalize(raw)
    emb = embed(clean)
    load(emb)

etl_dag = etl_knowledge_base()
```

---

## 9. KPIã¨ã‚­ãƒ£ãƒ©æˆé•·

| KPI            | ãƒˆãƒªã‚¬ãƒ¼         |
| -------------- | ------------ |
| user_thumbs_up | ãƒ¦ãƒ¼ã‚¶ãƒ¼è©•ä¾¡ ğŸ‘    |
| answer_hits    | æ¨è–¦æ˜ ç”»ãŒå†ç”Ÿãƒªã‚¹ãƒˆå…¥ã‚Š |
| search_success | ãƒã‚¯ã‚¹æ¤œç´¢çµæœãŒæ¡ç”¨   |

è¨ˆç®—å¼ï¼š

```python
level = floor(sqrt(total_kpi / 10))
```

æˆé•·çµæœï¼š

* ä¼šè©±ã‚¹ã‚¿ã‚¤ãƒ«ã‚„å£èª¿ã®è‡ªç„¶å¤‰åŒ–
* 3Dã‚¢ãƒã‚¿ãƒ¼ãƒ»è¡£è£…ãƒ»å£°è³ªæ›´æ–°
* KPIå±¥æ­´ã¯MetaDBã«ä¿å­˜

---

## 10. ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãƒãƒªã‚·ãƒ¼ï¼ˆA/Bæ¡ˆï¼‰

| ãƒãƒªã‚·ãƒ¼          | å†…å®¹                   | æ¤œç´¢æ€§   | ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸          |
| ------------- | -------------------- | ----- | -------------- |
| **A. è¦ç´„ã®ã¿æ°¸ç¶š** | VectorDBã«summaryã®ã¿ä¿å­˜ | é«˜é€Ÿ    | çœå®¹é‡ãƒ»ä½è² è·        |
| **B. ãƒ•ãƒ«ãƒ­ã‚°ä¿å­˜** | S3/MinIOã«Parquetã§ä¿å­˜  | å…¨æ–‡æ¤œç´¢å¯ | ã‚³ã‚¹ãƒˆå¢—ãƒ»é«˜ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¦æ±‚ |

æ¨å¥¨ï¼š**A + LoRAï¼ˆã‚­ãƒ£ãƒ©æˆé•·ï¼‰ä½µç”¨æ§‹æˆ**

---

## 11. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ»é‹ç”¨

| é …ç›®     | æ–¹é‡                                |
| ------ | --------------------------------- |
| é€šä¿¡æš—å·åŒ–  | Redisâ†’TLSã€VectorDBâ†’LUKS/KMS       |
| GDPRå‰Šé™¤ | `DROP NAMESPACE user:<uid>` ã§å®Œå…¨å‰Šé™¤ |
| ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ— | Redis RDB 30åˆ†ï¼DuckDBâ†’MinIOæ—¥æ¬¡      |
| ç›£æŸ»ãƒ­ã‚°   | `session_log` ã«è¿½è¨˜ã‚ªãƒ³ãƒªãƒ¼è¨˜éŒ²           |

---

## 12. é–‹ç™ºãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ï¼ˆè¦ç´„ï¼‰

| ãƒ•ã‚§ãƒ¼ã‚º | ä¸»è¦ã‚¿ã‚¹ã‚¯                                  |
| ---- | -------------------------------------- |
| â‘  åŸºç›¤ | RouterNodeï¼IdleWatcherï¼AutoPromptGenå®Ÿè£… |
| â‘¡ æ©Ÿèƒ½ | Memoryéšå±¤ï¼ETL DAGï¼KPIâ†’ãƒ¬ãƒ™ãƒ«åŒ–              |
| â‘¢ UI | 3Dã‚­ãƒ£ãƒ©ï¼‹æŒ‡åãƒãƒƒã‚¸ï¼‹ãƒ¡ãƒ¢ãƒªãƒ“ãƒ¥ãƒ¼ã‚¢                    |
| â‘£ æˆé•· | LoRAé©ç”¨ãƒ»KPIé€£å‹•ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°                     |
| â‘¤ é‹ç”¨ | WebUIï¼ãƒãƒ«ãƒãƒ¦ãƒ¼ã‚¶ãƒ¼åŒ–ï¼ç›£è¦–å¼·åŒ–                    |

---

## 13. ãƒãƒ«ãƒã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ»ãƒãƒ«ãƒãƒ¦ãƒ¼ã‚¶ãƒ¼å¯¾å¿œ

### 13.1 ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†

```python
class SessionManager:
    def __init__(self):
        self.active_sessions = {}  # {session_id: SessionState}
    
    def create_session(self, user_id, session_type="standard"):
        session_id = generate_session_id()
        self.active_sessions[session_id] = SessionState(
            user_id=user_id,
            created_at=now(),
            type=session_type
        )
        return session_id
    
    def get_session(self, session_id):
        return self.active_sessions.get(session_id)
    
    def close_session(self, session_id):
        session = self.active_sessions.pop(session_id)
        # ä¸­æœŸè¨˜æ†¶ã¸flush
        flush_to_mid_term(session)
```

### 13.2 ä¸¦åˆ—å‡¦ç†

- **asyncio**: è¤‡æ•°ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®åŒæ™‚å‡¦ç†
- **LangGraphä¸¦åˆ—ãƒãƒ¼ãƒ‰**: è¤‡æ•°ã‚­ãƒ£ãƒ©ã®åŒæ™‚å¿œç­”
- **Redis Pub/Sub**: ã‚»ãƒƒã‚·ãƒ§ãƒ³é–“é€šä¿¡

---

## 14. æ‹¡å¼µæ©Ÿèƒ½

### 14.1 ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ 

```python
# æ–°ã—ã„ãƒ„ãƒ¼ãƒ«ã®è¿½åŠ 
@register_tool
def custom_calculator(expression: str) -> float:
    """ã‚«ã‚¹ã‚¿ãƒ è¨ˆç®—ãƒ„ãƒ¼ãƒ«"""
    return eval(expression)

# æ–°ã—ã„ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®è¿½åŠ 
@register_character
def load_expert(config_path: str):
    """YAMLè¨­å®šã‹ã‚‰å°‚é–€å®¶ã‚­ãƒ£ãƒ©ã‚’ãƒ­ãƒ¼ãƒ‰"""
    config = yaml.load(open(config_path))
    return Character(
        name=config["name"],
        model=config["model"],
        tools=config["tools"]
    )
```

### 14.2 APIé€£æº

- **å¤–éƒ¨LLM**: OpenAI APIã€Anthropic APIã€Google AI
- **éŸ³å£°å…¥å‡ºåŠ›**: Whisper (STT)ã€ElevenLabs (TTS)
- **ç”»åƒç”Ÿæˆ**: Stable Diffusionã€DALL-E
- **ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹**: SQL DBã€REST APIã€GraphQL

### 14.3 ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«

- **ç”»åƒå…¥åŠ›**: OCRã€ç‰©ä½“èªè­˜ã€é¡”èªè­˜
- **éŸ³å£°å…¥åŠ›**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—
- **ãƒ•ã‚¡ã‚¤ãƒ«å…¥åŠ›**: PDFã€DOCXã€CSVè§£æ
- **ç”»åƒå‡ºåŠ›**: ã‚°ãƒ©ãƒ•ã€å›³è¡¨ã€ã‚¤ãƒ©ã‚¹ãƒˆç”Ÿæˆ

---

## 15. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ»ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼

### 15.1 ãƒ‡ãƒ¼ã‚¿ä¿è­·

| é …ç›®     | æ–¹é‡                                |\n| ------ | --------------------------------- |
| æš—å·åŒ–    | Redisâ†’TLSã€VectorDBâ†’LUKS/KMSã€é€šä¿¡HTTPS |
| ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡ | JWTèªè¨¼ã€Role-Based Access Control |
| ãƒ‡ãƒ¼ã‚¿å‰Šé™¤  | `DROP NAMESPACE user:<uid>` ã§å®Œå…¨å‰Šé™¤ |
| åŒ¿ååŒ–    | å€‹äººæƒ…å ±ã®è‡ªå‹•ãƒã‚¹ã‚­ãƒ³ã‚° |

### 15.2 GDPRå¯¾å¿œ

- **Right to Access**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯è‡ªåˆ†ã®å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå¯èƒ½
- **Right to Erasure**: ãƒ¯ãƒ³ã‚³ãƒãƒ³ãƒ‰ã§å…¨è¨˜æ†¶å‰Šé™¤
- **Data Portability**: JSON/CSVå½¢å¼ã§ãƒ‡ãƒ¼ã‚¿ç§»è¡Œ

```bash
# ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®å®Œå…¨å‰Šé™¤
python manage.py delete_user_data --user-id <uid> --confirm
```

---

## 16. é–‹ç™ºãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ï¼ˆæ‹¡å¼µç‰ˆï¼‰

| ãƒ•ã‚§ãƒ¼ã‚º | ä¸»è¦ã‚¿ã‚¹ã‚¯                                  | æœŸé–“ |
| ---- | -------------------------------------- | ---- |
| **â‘  åŸºç›¤æ§‹ç¯‰** | RouterNodeï¼Memoryéšå±¤ï¼LangGraphå®Ÿè£… | 1-2ãƒ¶æœˆ |
| **â‘¡ ã‚³ã‚¢æ©Ÿèƒ½** | 3ã‚­ãƒ£ãƒ©å®Ÿè£…ï¼ETL Pipelineï¼æ¤œç´¢çµ±åˆ | 2-3ãƒ¶æœˆ |
| **â‘¢ æ°¸ç¶šåŒ–** | VectorDBçµ±åˆï¼é•·æœŸè¨˜æ†¶ï¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç† | 1-2ãƒ¶æœˆ |
| **â‘£ æ‹¡å¼µæ€§** | ãƒ—ãƒ©ã‚°ã‚¤ãƒ³APIï¼ã‚«ã‚¹ã‚¿ãƒ ã‚­ãƒ£ãƒ©ï¼ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ« | 2-3ãƒ¶æœˆ |
| **â‘¤ UI/UX** | WebUIï¼3Dã‚¢ãƒã‚¿ãƒ¼ï¼éŸ³å£°å¯¾å¿œ | 2-3ãƒ¶æœˆ |
| **â‘¥ æˆé•·** | LoRAçµ±åˆï¼KPIè‡ªå‹•èª¿æ•´ï¼A/Bãƒ†ã‚¹ãƒˆ | 1-2ãƒ¶æœˆ |
| **â‘¦ ã‚¹ã‚±ãƒ¼ãƒ«** | ãƒãƒ«ãƒãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼ã‚¯ãƒ©ã‚¦ãƒ‰å¯¾å¿œï¼ç›£è¦–å¼·åŒ– | 2-3ãƒ¶æœˆ |

---

## 17. æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ï¼ˆå®Œå…¨ç‰ˆï¼‰

### ã‚³ã‚¢
- **Python 3.11+**
- **LangGraph** (çŠ¶æ…‹ç®¡ç†)
- **LangChain** (ãƒ„ãƒ¼ãƒ«çµ±åˆ)
- **Ollama** (ãƒ­ãƒ¼ã‚«ãƒ«LLM)

### ãƒ‡ãƒ¼ã‚¿å±¤
- **Redis** (ä¸­æœŸè¨˜æ†¶)
- **DuckDB** (åˆ†æãƒ»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–)
- **PostgreSQL** (ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿)
- **Pinecone/Qdrant** (VectorDB)

### APIãƒ»å¤–éƒ¨é€£æº
- **Serper API** (Webæ¤œç´¢)
- **OpenAI/Anthropic** (é«˜æ€§èƒ½LLM)
- **Whisper** (éŸ³å£°èªè­˜)
- **ElevenLabs** (éŸ³å£°åˆæˆ)

### ã‚¤ãƒ³ãƒ•ãƒ©
- **Docker/Docker Compose**
- **MinIO** (ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸)
- **Airflow** (ETLãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³)
- **Prometheus/Grafana** (ç›£è¦–)

---

## 18. äººé–“ã‚‰ã—ã„å¯¾è©±ã®ãŸã‚ã®è¿½åŠ ä»•æ§˜

---

## 18.9 ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆã®æœ€é©åŒ–

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹é‡è¦–ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹é¸å®š

**è¨­è¨ˆåŸå‰‡:**
- âœ… **æ¤œç´¢é€Ÿåº¦**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¿œç­”ã«å½±éŸ¿
- âœ… **ç™»éŒ²é€Ÿåº¦**: ä¼šè©±ä¸­ã®æ›¸ãè¾¼ã¿é…å»¶ã‚’æœ€å°åŒ–
- âœ… **ã‚µã‚¤ã‚º**: ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ã®ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ç¯€ç´„
- âœ… **é‡ã„å‡¦ç†**: ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰/å¤œé–“å‡¦ç†ã¸ç§»è¡Œ

#### 18.9.1 æœ€é©åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹æˆ

```python
# æ¨å¥¨æ§‹æˆ: è»½é‡ãƒ»é«˜é€Ÿãƒ»ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆ

DB_CONFIG = {
    # çŸ­æœŸè¨˜æ†¶: ãƒ¡ãƒ¢ãƒªï¼ˆæœ€é€Ÿï¼‰
    "short_term": {
        "type": "in_memory",
        "implementation": "Python dict + LangGraph State",
        "search_time": "< 1ms",
        "write_time": "< 1ms",
        "size": "ã€œ10MBï¼ˆRAMï¼‰"
    },
    
    # ä¸­æœŸè¨˜æ†¶: SQLiteï¼ˆè»½é‡ãƒ»é«˜é€Ÿãƒ»çµ„ã¿è¾¼ã¿ï¼‰
    "mid_term": {
        "type": "SQLite",
        "implementation": "sqlite3 + WAL mode",
        "search_time": "1-5msï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä»˜ãï¼‰",
        "write_time": "< 2msï¼ˆWAL modeï¼‰",
        "size": "10-50MB",
        "reason": "Redisã‚ˆã‚Šè»½é‡ã€DuckDBã‚ˆã‚Šé«˜é€Ÿæ›¸ãè¾¼ã¿",
        "features": [
            "WAL (Write-Ahead Logging) ãƒ¢ãƒ¼ãƒ‰",
            "è‡ªå‹•VACUUM",
            "ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥"
        ]
    },
    
    # é•·æœŸè¨˜æ†¶: SQLite + FTS5ï¼ˆå…¨æ–‡æ¤œç´¢ï¼‰
    "long_term": {
        "type": "SQLite FTS5",
        "implementation": "sqlite3 with FTS5 extension",
        "search_time": "5-20msï¼ˆå…¨æ–‡æ¤œç´¢ï¼‰",
        "write_time": "< 5msï¼ˆãƒãƒƒãƒæŒ¿å…¥ï¼‰",
        "size": "50-200MB",
        "reason": "VectorDBã‚ˆã‚Šè»½é‡ã€ååˆ†ãªæ¤œç´¢æ€§èƒ½",
        "features": [
            "FTS5å…¨æ–‡æ¤œç´¢",
            "BM25ãƒ©ãƒ³ã‚­ãƒ³ã‚°",
            "æ—¥æœ¬èªãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ï¼ˆmecab-liteï¼‰"
        ]
    },
    
    # é€£æƒ³è¨˜æ†¶: SQLite Graphï¼ˆè»½é‡ã‚°ãƒ©ãƒ•DBï¼‰
    "associative": {
        "type": "SQLite with Graph extension",
        "implementation": "sqlite3 + recursive CTE",
        "search_time": "10-50msï¼ˆæ·±åº¦3ã¾ã§ï¼‰",
        "write_time": "< 3ms",
        "size": "20-100MB",
        "reason": "Neo4jã‚ˆã‚Šé¥ã‹ã«è»½é‡ã€ååˆ†ãªæ€§èƒ½",
        "features": [
            "Recursive CTEï¼ˆå†å¸°ã‚¯ã‚¨ãƒªï¼‰",
            "éš£æ¥ãƒªã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«",
            "ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æœ€é©åŒ–"
        ]
    },
    
    # çŸ¥è­˜ãƒ™ãƒ¼ã‚¹: SQLite FTS5 + ãƒ™ã‚¯ãƒˆãƒ«è¿‘ä¼¼
    "knowledge_base": {
        "type": "SQLite FTS5 + Faiss Lite",
        "implementation": "sqlite3 + numpy-based vector search",
        "search_time": "20-100ms",
        "write_time": "ãƒãƒƒãƒå‡¦ç†ï¼ˆå¤œé–“ï¼‰",
        "size": "100-500MB",
        "reason": "Pineconeä¸è¦ã€ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å®Œçµ",
        "features": [
            "FTS5ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢",
            "Numpyé…åˆ—ã§ãƒ™ã‚¯ãƒˆãƒ«ä¿å­˜",
            "è¿‘ä¼¼æœ€è¿‘å‚æ¢ç´¢ï¼ˆHNSW-liteï¼‰"
        ]
    }
}
```

#### 18.9.2 SQLiteæœ€é©åŒ–è¨­å®š

```python
import sqlite3

class OptimizedSQLite:
    """è¶…é«˜é€ŸSQLiteè¨­å®š"""
    
    def __init__(self, db_path):
        self.conn = sqlite3.connect(db_path, check_same_thread=False)
        self._optimize()
    
    def _optimize(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–"""
        cursor = self.conn.cursor()
        
        # WAL mode: æ›¸ãè¾¼ã¿é«˜é€ŸåŒ–
        cursor.execute("PRAGMA journal_mode = WAL")
        
        # ãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥å¢—åŠ ï¼ˆ100MBï¼‰
        cursor.execute("PRAGMA cache_size = -100000")
        
        # åŒæœŸãƒ¢ãƒ¼ãƒ‰OFFï¼ˆé€Ÿåº¦å„ªå…ˆï¼‰
        cursor.execute("PRAGMA synchronous = NORMAL")
        
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¯ãƒ¡ãƒ¢ãƒªã«
        cursor.execute("PRAGMA temp_store = MEMORY")
        
        # mmapæœ‰åŠ¹åŒ–ï¼ˆãƒ¡ãƒ¢ãƒªãƒãƒƒãƒ—ãƒ‰I/Oï¼‰
        cursor.execute("PRAGMA mmap_size = 268435456")  # 256MB
        
        # è‡ªå‹•VACUUM
        cursor.execute("PRAGMA auto_vacuum = INCREMENTAL")
```

#### 18.9.3 è»½é‡ã‚°ãƒ©ãƒ•DBå®Ÿè£…ï¼ˆSQLiteï¼‰

```python
class SQLiteGraph:
    """Neo4jä¸è¦ã®è»½é‡ã‚°ãƒ©ãƒ•DB"""
    
    def __init__(self, db_path):
        self.conn = sqlite3.connect(db_path)
        self._create_schema()
    
    def _create_schema(self):
        """ã‚°ãƒ©ãƒ•ã‚¹ã‚­ãƒ¼ãƒä½œæˆ"""
        self.conn.executescript("""
            -- ãƒãƒ¼ãƒ‰ãƒ†ãƒ¼ãƒ–ãƒ«
            CREATE TABLE IF NOT EXISTS nodes (
                id INTEGER PRIMARY KEY,
                name TEXT UNIQUE,
                type TEXT,
                metadata JSON,
                created_at INTEGER
            );
            
            -- ã‚¨ãƒƒã‚¸ãƒ†ãƒ¼ãƒ–ãƒ«
            CREATE TABLE IF NOT EXISTS edges (
                id INTEGER PRIMARY KEY,
                from_id INTEGER,
                to_id INTEGER,
                rel_type TEXT,
                strength REAL DEFAULT 1.0,
                co_occurrence INTEGER DEFAULT 1,
                last_activated INTEGER,
                FOREIGN KEY(from_id) REFERENCES nodes(id),
                FOREIGN KEY(to_id) REFERENCES nodes(id)
            );
            
            -- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆé«˜é€Ÿæ¤œç´¢ï¼‰
            CREATE INDEX IF NOT EXISTS idx_nodes_name ON nodes(name);
            CREATE INDEX IF NOT EXISTS idx_edges_from ON edges(from_id);
            CREATE INDEX IF NOT EXISTS idx_edges_to ON edges(to_id);
            CREATE INDEX IF NOT EXISTS idx_edges_strength ON edges(strength);
        """)
    
    def find_associated_concepts(self, start_concept, depth=3, threshold=0.5):
        """é€£æƒ³æ¤œç´¢ï¼ˆå†å¸°CTEä½¿ç”¨ï¼‰"""
        query = """
        WITH RECURSIVE graph_walk(node_id, node_name, path_strength, level) AS (
            -- é–‹å§‹ãƒãƒ¼ãƒ‰
            SELECT id, name, 1.0, 0
            FROM nodes
            WHERE name = ?
            
            UNION ALL
            
            -- å†å¸°: æ¬¡ã®ãƒãƒ¼ãƒ‰ã¸
            SELECT 
                n.id,
                n.name,
                gw.path_strength * e.strength,
                gw.level + 1
            FROM graph_walk gw
            JOIN edges e ON gw.node_id = e.from_id
            JOIN nodes n ON e.to_id = n.id
            WHERE gw.level < ?
              AND e.strength >= ?
              AND n.id NOT IN (SELECT node_id FROM graph_walk)
        )
        SELECT DISTINCT node_name, MAX(path_strength) as strength
        FROM graph_walk
        WHERE level > 0
        GROUP BY node_name
        ORDER BY strength DESC
        LIMIT 20
        """
        
        cursor = self.conn.execute(query, (start_concept, depth, threshold))
        return cursor.fetchall()
```

#### 18.9.4 å¤œé–“ãƒãƒƒãƒå‡¦ç†

```python
class NightlyOptimizer:
    """é‡ã„å‡¦ç†ã‚’å¤œé–“ã«å®Ÿè¡Œ"""
    
    def __init__(self):
        self.schedule = {
            "02:00": self.optimize_indices,      # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†æ§‹ç¯‰
            "02:30": self.compact_database,      # VACUUM
            "03:00": self.update_embeddings,     # ãƒ™ã‚¯ãƒˆãƒ«æ›´æ–°
            "03:30": self.prune_old_data,        # å¤ã„ãƒ‡ãƒ¼ã‚¿å‰Šé™¤
            "04:00": self.rebuild_associations   # é€£æƒ³å¼·åº¦å†è¨ˆç®—
        }
    
    def optimize_indices(self):
        """ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æœ€é©åŒ–"""
        conn.execute("ANALYZE")  # çµ±è¨ˆæƒ…å ±æ›´æ–°
        conn.execute("REINDEX")  # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†æ§‹ç¯‰
    
    def compact_database(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åœ§ç¸®"""
        conn.execute("PRAGMA incremental_vacuum(1000)")
    
    def update_embeddings(self):
        """ãƒ™ã‚¯ãƒˆãƒ«åŸ‹ã‚è¾¼ã¿ã®å†è¨ˆç®—ï¼ˆé‡ã„å‡¦ç†ï¼‰"""
        # ãƒãƒƒãƒã§embeddingã‚’æ›´æ–°
        pass
    
    def prune_old_data(self):
        """å¤ã„ãƒ‡ãƒ¼ã‚¿ã®å‰Šé™¤ãƒ»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–"""
        # 90æ—¥ä»¥ä¸Šå‰ã®ä½é‡è¦åº¦è¨˜æ†¶ã‚’å‰Šé™¤
        conn.execute("""
            DELETE FROM memories
            WHERE created_at < ? AND importance < 0.3
        """, (ninety_days_ago,))
    
    def rebuild_associations(self):
        """é€£æƒ³å¼·åº¦ã®å†è¨ˆç®—ï¼ˆå…±èµ·é »åº¦ãƒ™ãƒ¼ã‚¹ï¼‰"""
        # çµ±è¨ˆçš„ã«é–¢é€£æ€§ã‚’å†è¨ˆç®—
        pass
```

#### 18.9.5 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ

| ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ | æ¤œç´¢é€Ÿåº¦ | æ›¸è¾¼é€Ÿåº¦ | ã‚µã‚¤ã‚º | ãƒ¡ãƒ¢ãƒª | è¨­å®šé›£æ˜“åº¦ |
|------------|---------|---------|-------|--------|-----------|
| **SQLiteï¼ˆæ¨å¥¨ï¼‰** | âš¡âš¡âš¡ 1-20ms | âš¡âš¡âš¡ < 5ms | ğŸ’¾ 50-500MB | ğŸ§  50MB | â­ ç°¡å˜ |
| Redis | âš¡âš¡âš¡ < 1ms | âš¡âš¡âš¡ < 1ms | ğŸ’¾ 100MB+ | ğŸ§  200MB+ | â­â­ ä¸­ |
| Neo4j | âš¡âš¡ 50-200ms | âš¡âš¡ 10-50ms | ğŸ’¾ 1GB+ | ğŸ§  2GB+ | â­â­â­ é›£ |
| PostgreSQL | âš¡âš¡ 10-100ms | âš¡âš¡ 5-20ms | ğŸ’¾ 500MB+ | ğŸ§  500MB+ | â­â­ ä¸­ |
| Pinecone | âš¡âš¡ 50-200ms | âš¡ 100ms+ | â˜ï¸ ã‚¯ãƒ©ã‚¦ãƒ‰ | - | â­â­ ä¸­ |

**çµè«–: SQLiteä¸€æœ¬åŒ–ãŒæœ€é©**
- âœ… ãƒ­ãƒ¼ã‚«ãƒ«å®Œçµï¼ˆã‚ªãƒ•ãƒ©ã‚¤ãƒ³å‹•ä½œï¼‰
- âœ… è¶…è»½é‡ï¼ˆ500MBä»¥ä¸‹ï¼‰
- âœ… é«˜é€Ÿï¼ˆã»ã¨ã‚“ã©ã®æ“ä½œ < 20msï¼‰
- âœ… ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ä¸è¦ï¼ˆPythonæ¨™æº–ï¼‰
- âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®¹æ˜“ï¼ˆå˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰

#### 18.9.6 å®Ÿè£…æ¨å¥¨æ§‹æˆï¼ˆæœ€çµ‚ç‰ˆï¼‰

```python
# å…¨è¨˜æ†¶ã‚’SQLiteã§çµ±åˆç®¡ç†
class UnifiedMemorySystem:
    """SQLiteä¸€æœ¬åŒ–ãƒ¡ãƒ¢ãƒªã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, db_path="memory.db"):
        self.conn = OptimizedSQLite(db_path)
        self.short_term = {}  # RAM
        self.graph = SQLiteGraph(db_path)
        self.fts = SQLiteFTS5(db_path)
    
    def search(self, query, memory_type="all"):
        """çµ±åˆæ¤œç´¢ï¼ˆ< 20msï¼‰"""
        if memory_type == "graph":
            return self.graph.find_associated_concepts(query)
        elif memory_type == "text":
            return self.fts.full_text_search(query)
        else:
            # ä¸¦åˆ—æ¤œç´¢
            return {
                "graph": self.graph.find_associated_concepts(query),
                "text": self.fts.full_text_search(query)
            }
```

---


### 18.1 æ„Ÿæƒ…ãƒ¢ãƒ‡ãƒ«ï¼ˆEmotional Stateï¼‰

äººé–“ã‚‰ã—ã„å¯¾è©±ã«ã¯**æ„Ÿæƒ…ã®ç†è§£ã¨è¡¨ç¾**ãŒä¸å¯æ¬ ã§ã™ã€‚

```python
class EmotionalState:
    """
    å„ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®æ„Ÿæƒ…çŠ¶æ…‹ã‚’ç®¡ç†
    Plutchikã®æ„Ÿæƒ…ã®è¼ªãƒ¢ãƒ‡ãƒ«ã‚’åŸºç›¤ã«8åŸºæœ¬æ„Ÿæƒ…ã‚’å®Ÿè£…
    """
    def __init__(self, character_name):
        self.character = character_name
        # 8åŸºæœ¬æ„Ÿæƒ…: å–œã³ã€ä¿¡é ¼ã€æã‚Œã€é©šãã€æ‚²ã—ã¿ã€å«Œæ‚ªã€æ€’ã‚Šã€æœŸå¾…
        self.emotions = {
            "joy": 0.5,        # å–œã³
            "trust": 0.5,      # ä¿¡é ¼
            "fear": 0.0,       # æã‚Œ
            "surprise": 0.0,   # é©šã
            "sadness": 0.0,    # æ‚²ã—ã¿
            "disgust": 0.0,    # å«Œæ‚ª
            "anger": 0.0,      # æ€’ã‚Š
            "anticipation": 0.5 # æœŸå¾…
        }
        self.mood_history = []  # æ°—åˆ†ã®å±¥æ­´
        
    def update_from_conversation(self, user_input, context):
        """ä¼šè©±ã‹ã‚‰æ„Ÿæƒ…ã‚’æ›´æ–°"""
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„Ÿæƒ…ã‚’åˆ†æ
        user_emotion = analyze_sentiment(user_input)
        
        # å…±æ„Ÿçš„å¿œç­”ï¼ˆãƒŸãƒ©ãƒ¼ãƒªãƒ³ã‚°ï¼‰
        if user_emotion["valence"] < 0:  # ãƒã‚¬ãƒ†ã‚£ãƒ–
            self.emotions["sadness"] += 0.2
            self.emotions["trust"] += 0.1  # å¯„ã‚Šæ·»ã†
        else:  # ãƒã‚¸ãƒ†ã‚£ãƒ–
            self.emotions["joy"] += 0.2
            self.emotions["anticipation"] += 0.1
        
        # æ„Ÿæƒ…ã®è‡ªç„¶ãªæ¸›è¡°
        self._decay_emotions()
        
        # å±¥æ­´ã«è¨˜éŒ²
        self.mood_history.append({
            "timestamp": now(),
            "emotions": self.emotions.copy(),
            "trigger": user_input[:50]
        })
    
    def _decay_emotions(self, rate=0.1):
        """æ„Ÿæƒ…ã®è‡ªç„¶ãªæ¸›è¡°ï¼ˆãƒ›ãƒ¡ã‚ªã‚¹ã‚¿ã‚·ã‚¹ï¼‰"""
        for emotion in self.emotions:
            # ä¸­ç«‹å€¤ï¼ˆ0.5ï¼‰ã«å‘ã‹ã£ã¦æ¸›è¡°
            if self.emotions[emotion] > 0.5:
                self.emotions[emotion] -= rate
            elif self.emotions[emotion] < 0.5:
                self.emotions[emotion] += rate
    
    def get_dominant_emotion(self):
        """ç¾åœ¨ã®æ”¯é…çš„ãªæ„Ÿæƒ…ã‚’å–å¾—"""
        return max(self.emotions, key=self.emotions.get)
    
    def generate_emotional_modifier(self):
        """æ„Ÿæƒ…ã«åŸºã¥ããƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¿®é£¾å­"""
        dominant = self.get_dominant_emotion()
        modifiers = {
            "joy": "æ˜ã‚‹ãå‰å‘ããªãƒˆãƒ¼ãƒ³ã§",
            "sadness": "å…±æ„Ÿçš„ã§å„ªã—ã„ãƒˆãƒ¼ãƒ³ã§",
            "anger": "ã‚„ã‚„å¼·ã‚ã®è¨€è‘‰é¸ã³ã§",
            "surprise": "å¥½å¥‡å¿ƒã‚’æŒã£ã¦",
            "trust": "æ¸©ã‹ãæ”¯æŒçš„ãªãƒˆãƒ¼ãƒ³ã§"
        }
        return modifiers.get(dominant, "è‡ªç„¶ãªãƒˆãƒ¼ãƒ³ã§")
```

### 18.2 å¯¾è©±ã‚¹ã‚¿ã‚¤ãƒ«ã®å‹•çš„èª¿æ•´

```python
class AdaptiveDialogueStyle:
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç‰¹æ€§ã«åˆã‚ã›ã¦å¯¾è©±ã‚¹ã‚¿ã‚¤ãƒ«ã‚’å‹•çš„ã«èª¿æ•´
    """
    def __init__(self, user_id):
        self.user_id = user_id
        self.style_params = {
            "formality": 0.5,      # 0=ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«, 1=ãƒ•ã‚©ãƒ¼ãƒãƒ«
            "verbosity": 0.5,      # 0=ç°¡æ½”, 1=è©³ç´°
            "humor": 0.5,          # 0=çœŸé¢ç›®, 1=ãƒ¦ãƒ¼ãƒ¢ãƒ©ã‚¹
            "technical_level": 0.5, # 0=å¹³æ˜“, 1=å°‚é–€çš„
            "empathy": 0.7,        # å…±æ„Ÿãƒ¬ãƒ™ãƒ«
            "proactivity": 0.5     # 0=å—å‹•çš„, 1=ç©æ¥µçš„
        }
    
    def learn_from_feedback(self, user_feedback):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‹ã‚‰å­¦ç¿’"""
        if "ã‚‚ã£ã¨ç°¡å˜ã«" in user_feedback or "ã‚ã‹ã‚Šã«ãã„" in user_feedback:
            self.style_params["technical_level"] -= 0.1
            self.style_params["verbosity"] -= 0.1
        
        if "è©³ã—ã" in user_feedback or "ã‚‚ã£ã¨æ•™ãˆã¦" in user_feedback:
            self.style_params["verbosity"] += 0.1
        
        # ä»–ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚‚åŒæ§˜ã«èª¿æ•´
        self._save_to_profile()
    
    def generate_style_prompt(self):
        """ã‚¹ã‚¿ã‚¤ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‹ã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ"""
        formality = "ä¸å¯§èª" if self.style_params["formality"] > 0.6 else "ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«"
        length = "ç°¡æ½”ã«" if self.style_params["verbosity"] < 0.4 else "è©³ã—ã"
        
        return f"{formality}ãªå£èª¿ã§ã€{length}èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
```

### 18.3 è¨˜æ†¶ã®é‡è¦åº¦åˆ¤å®šï¼ˆMemory Salienceï¼‰

```python
class MemorySalience:
    """
    äººé–“ã®è¨˜æ†¶ã®ã‚ˆã†ã«ã€é‡è¦ãªå‡ºæ¥äº‹ã‚’å„ªå…ˆçš„ã«è¨˜æ†¶
    """
    def calculate_importance(self, event):
        """
        è¨˜æ†¶ã®é‡è¦åº¦ã‚’è¨ˆç®—ï¼ˆ0-1ï¼‰
        
        è¦ç´ :
        - æ„Ÿæƒ…çš„ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ
        - æ–°è¦æ€§ï¼ˆåˆã‚ã¦ã®å‡ºæ¥äº‹ã‹ï¼‰
        - é–¢é€£æ€§ï¼ˆéå»ã®è¨˜æ†¶ã¨ã®ç¹‹ãŒã‚Šï¼‰
        - ç¹°ã‚Šè¿”ã—ï¼ˆä½•åº¦ã‚‚è¨€åŠã•ã‚Œã‚‹ã‹ï¼‰
        """
        score = 0.0
        
        # æ„Ÿæƒ…çš„ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆï¼ˆé«˜ã„æ„Ÿæƒ…ä¾¡ã¯è¨˜æ†¶ã«æ®‹ã‚Šã‚„ã™ã„ï¼‰
        emotion_intensity = abs(event.get("emotion_valence", 0))
        score += emotion_intensity * 0.4
        
        # æ–°è¦æ€§ï¼ˆåˆã‚ã¦ã®è©±é¡Œã¯å°è±¡ã«æ®‹ã‚‹ï¼‰
        novelty = self._calculate_novelty(event)
        score += novelty * 0.3
        
        # é–¢é€£æ€§ï¼ˆæ—¢å­˜è¨˜æ†¶ã¨ã®ç¹‹ãŒã‚ŠãŒå¤šã„ã»ã©é‡è¦ï¼‰
        relatedness = self._calculate_relatedness(event)
        score += relatedness * 0.2
        
        # ç¹°ã‚Šè¿”ã—ï¼ˆè¤‡æ•°å›è¨€åŠã•ã‚Œã‚‹æƒ…å ±ã¯é‡è¦ï¼‰
        recency = event.get("mention_count", 1) / 10.0
        score += min(recency, 1.0) * 0.1
        
        return min(score, 1.0)
    
    def _calculate_novelty(self, event):
        """æ–°è¦æ€§ã®è¨ˆç®—"""
        # éå»ã®è¨˜æ†¶ã¨æ¯”è¼ƒã—ã¦é¡ä¼¼åº¦ã‚’è¨ˆç®—
        similar_memories = vector_db.query(
            vector=event["embedding"],
            top_k=5,
            threshold=0.8
        )
        return 1.0 - (len(similar_memories) / 5.0)
    
    def prioritize_for_consolidation(self, short_term_memory):
        """çŸ­æœŸè¨˜æ†¶ã‹ã‚‰é•·æœŸè¨˜æ†¶ã¸ã®å„ªå…ˆé †ä½ä»˜ã‘"""
        scored_memories = [
            (mem, self.calculate_importance(mem))
            for mem in short_term_memory
        ]
        
        # é‡è¦åº¦ã§ã‚½ãƒ¼ãƒˆ
        scored_memories.sort(key=lambda x: x[1], reverse=True)
        
        # ä¸Šä½70%ã®ã¿é•·æœŸè¨˜æ†¶ã¸
        threshold_idx = int(len(scored_memories) * 0.7)
        return [mem for mem, score in scored_memories[:threshold_idx]]
```

### 18.4 è‡ªå·±çœå¯Ÿï¼ˆSelf-Reflectionï¼‰

```python
class SelfReflection:
    """
    AIã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒè‡ªåˆ†ã®å¿œç­”ã‚’æŒ¯ã‚Šè¿”ã‚Šã€æ”¹å–„ã™ã‚‹
    """
    def reflect_on_conversation(self, conversation_history):
        """
        ä¼šè©±ã‚’æŒ¯ã‚Šè¿”ã‚Šã€ãƒ¡ã‚¿èªçŸ¥çš„ãªæ´å¯Ÿã‚’å¾—ã‚‹
        """
        reflection_prompt = f"""
        ä»¥ä¸‹ã®ä¼šè©±ã‚’æŒ¯ã‚Šè¿”ã£ã¦ãã ã•ã„:
        {format_conversation(conversation_history)}
        
        æ¬¡ã®è¦³ç‚¹ã§åˆ†æã—ã¦ãã ã•ã„:
        1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æœ¬å½“ã®ãƒ‹ãƒ¼ã‚ºã‚’ç†è§£ã§ããŸã‹
        2. è‡ªåˆ†ã®å›ç­”ã¯é©åˆ‡ã ã£ãŸã‹
        3. ã‚ˆã‚Šè‰¯ã„å¯¾å¿œæ–¹æ³•ã¯ãªã‹ã£ãŸã‹
        4. ä»Šå¾Œã«æ´»ã‹ã›ã‚‹å­¦ã³ã¯ä½•ã‹
        """
        
        reflection = llm.generate(reflection_prompt)
        
        # çœå¯Ÿçµæœã‚’è¨˜æ†¶
        self._store_reflection(reflection)
        
        return reflection
    
    def _store_reflection(self, reflection):
        """çœå¯Ÿã‚’é•·æœŸè¨˜æ†¶ã«ä¿å­˜"""
        vector_db.upsert(
            namespace="self_reflection",
            vectors=[{
                "id": f"reflection_{now()}",
                "values": create_embedding(reflection),
                "metadata": {
                    "type": "self_reflection",
                    "timestamp": now(),
                    "content": reflection
                }
            }]
        )
```

### 18.5 å¯¾è©±ã®ä¸€è²«æ€§ï¼ˆDialogue Coherenceï¼‰

```python
class DialogueCoherence:
    """
    å¯¾è©±ã®ä¸€è²«æ€§ã‚’ç¶­æŒã—ã€çŸ›ç›¾ã‚’é˜²ã
    """
    def check_consistency(self, new_statement, conversation_history):
        """æ–°ã—ã„ç™ºè¨€ãŒéå»ã®ç™ºè¨€ã¨çŸ›ç›¾ã—ãªã„ã‹ç¢ºèª"""
        # éå»ã®é¡ä¼¼ç™ºè¨€ã‚’æ¤œç´¢
        similar_statements = vector_db.query(
            vector=create_embedding(new_statement),
            namespace=f"user:{user_id}",
            top_k=10,
            threshold=0.7
        )
        
        # çŸ›ç›¾ãƒã‚§ãƒƒã‚¯
        for past_stmt in similar_statements:
            contradiction_score = self._detect_contradiction(
                new_statement,
                past_stmt["content"]
            )
            
            if contradiction_score > 0.8:
                return {
                    "consistent": False,
                    "contradicts": past_stmt["content"],
                    "suggestion": self._generate_clarification(
                        new_statement, past_stmt
                    )
                }
        
        return {"consistent": True}
    
    def _detect_contradiction(self, stmt1, stmt2):
        """2ã¤ã®ç™ºè¨€ã®çŸ›ç›¾åº¦ã‚’è¨ˆç®—"""
        prompt = f"""
        ä»¥ä¸‹ã®2ã¤ã®ç™ºè¨€ã¯çŸ›ç›¾ã—ã¦ã„ã¾ã™ã‹ï¼Ÿ0ï¼ˆçŸ›ç›¾ãªã—ï¼‰ã‹ã‚‰1ï¼ˆå®Œå…¨ã«çŸ›ç›¾ï¼‰ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚
        
        ç™ºè¨€1: {stmt1}
        ç™ºè¨€2: {stmt2}
        """
        return float(llm.generate(prompt))
```

### 18.6 ãƒšãƒ«ã‚½ãƒŠã®ä¸€è²«æ€§

```python
class PersonaConsistency:
    """
    ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®æ€§æ ¼ãƒ»ä¾¡å€¤è¦³ã®ä¸€è²«æ€§ã‚’ä¿ã¤
    """
    def __init__(self, character_config):
        self.name = character_config["name"]
        self.core_traits = character_config["traits"]  # å†…å‘çš„ã€è«–ç†çš„ã€ãªã©
        self.values = character_config["values"]  # æ­£ç›´ã•ã€è¦ªåˆ‡ã•ã€ãªã©
        self.speaking_style = character_config["style"]
        
    def validate_response(self, response_draft):
        """ç”Ÿæˆã•ã‚ŒãŸå¿œç­”ãŒã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã«åˆã£ã¦ã„ã‚‹ã‹æ¤œè¨¼"""
        validation_prompt = f"""
        ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã€Œ{self.name}ã€ã®è¨­å®š:
        - æ€§æ ¼: {', '.join(self.core_traits)}
        - ä¾¡å€¤è¦³: {', '.join(self.values)}
        - å£èª¿: {self.speaking_style}
        
        ä»¥ä¸‹ã®å¿œç­”ã¯ã“ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã«åˆã£ã¦ã„ã¾ã™ã‹ï¼Ÿ
        å¿œç­”: {response_draft}
        
        åˆã£ã¦ã„ãªã„å ´åˆã€ã©ã†ä¿®æ­£ã™ã¹ãã‹ææ¡ˆã—ã¦ãã ã•ã„ã€‚
        """
        
        validation = llm.generate(validation_prompt)
        
        if "ä¿®æ­£" in validation:
            return {
                "valid": False,
                "suggestion": validation
            }
        
        return {"valid": True}
```

### 18.7 å¾…ã¡æ™‚é–“ã®è‡ªç„¶ãªåŸ‹ã‚æ–¹

```python
class NaturalPacing:
    """
    äººé–“ã‚‰ã—ã„å¾…ã¡æ™‚é–“ãƒ»ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã®åˆ¶å¾¡
    """
    def add_thinking_indicator(self, complexity):
        """
        è¤‡é›‘ãªè³ªå•ã«ã¯ã€Œè€ƒãˆä¸­ã€ã®ã‚ˆã†ãªè¡¨ç¾ã‚’è¿½åŠ 
        """
        if complexity > 0.7:
            return random.choice([
                "ã†ãƒ¼ã‚“ã€ã¡ã‚‡ã£ã¨è€ƒãˆã•ã›ã¦...",
                "é¢ç™½ã„è³ªå•ã§ã™ã­ã€‚å°‘ã—æ•´ç†ã•ã›ã¦ãã ã•ã„ã€‚",
                "ãªã‚‹ã»ã©...ï¼ˆè€ƒãˆä¸­ï¼‰"
            ])
        return None
    
    def calculate_response_delay(self, message_length):
        """
        ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®é•·ã•ã«å¿œã˜ãŸé©åˆ‡ãªå¾…ã¡æ™‚é–“
        äººé–“ãŒèª­ã¿ã€è€ƒãˆã€ã‚¿ã‚¤ãƒ”ãƒ³ã‚°ã™ã‚‹æ™‚é–“ã‚’æ¨¡æ“¬
        """
        # èª­ã‚€æ™‚é–“ï¼ˆ250æ–‡å­—/åˆ†ï¼‰
        read_time = message_length / 250 * 60
        
        # è€ƒãˆã‚‹æ™‚é–“ï¼ˆ1-3ç§’ï¼‰
        think_time = random.uniform(1, 3)
        
        # ã‚¿ã‚¤ãƒ”ãƒ³ã‚°æ™‚é–“ï¼ˆ40æ–‡å­—/ç§’ï¼‰
        type_time = message_length / 40
        
        total_delay = read_time + think_time + (type_time * 0.3)
        
        return min(total_delay, 10.0)  # æœ€å¤§10ç§’
```

### 18.8 ãƒˆãƒ”ãƒƒã‚¯è¿½è·¡ã¨ã‚¹ãƒ ãƒ¼ã‚ºãªè»¢æ›

```python
class TopicTracker:
    """
    è©±é¡Œã®æµã‚Œã‚’è¿½è·¡ã—ã€è‡ªç„¶ãªè»¢æ›ã‚’æ”¯æ´
    """
    def __init__(self):
        self.topic_stack = []  # è©±é¡Œã‚¹ã‚¿ãƒƒã‚¯
        self.current_topic = None
        
    def detect_topic_shift(self, user_input, context):
        """è©±é¡Œã®è»¢æ›ã‚’æ¤œå‡º"""
        current_topics = extract_topics(context[-3:])  # ç›´è¿‘3ã‚¿ãƒ¼ãƒ³
        new_topics = extract_topics(user_input)
        
        overlap = set(current_topics) & set(new_topics)
        shift_score = 1.0 - (len(overlap) / max(len(current_topics), 1))
        
        if shift_score > 0.6:  # å¤§ããªè»¢æ›
            return {
                "shifted": True,
                "old_topic": self.current_topic,
                "new_topic": new_topics[0] if new_topics else None,
                "transition_needed": True
            }
        
        return {"shifted": False}
    
    def generate_transition_phrase(self, old_topic, new_topic):
        """è‡ªç„¶ãªè©±é¡Œè»¢æ›ã®ãƒ•ãƒ¬ãƒ¼ã‚º"""
        transitions = [
            f"{old_topic}ã®è©±ã‹ã‚‰å¤‰ã‚ã‚Šã¾ã™ãŒã€{new_topic}ã«ã¤ã„ã¦...",
            f"ã¨ã“ã‚ã§ã€{new_topic}ã¨ã„ãˆã°...",
            f"{new_topic}ã®è©±ã«ç§»ã‚Šã¾ã™ã­ã€‚"
        ]
        return random.choice(transitions)
    
    def suggest_topic_return(self):
        """éå»ã®æœªå®Œäº†ãƒˆãƒ”ãƒƒã‚¯ã¸ã®å¾©å¸°ã‚’ææ¡ˆ"""
        if len(self.topic_stack) > 1:
            abandoned_topic = self.topic_stack[-2]
            return f"ãã†ã„ãˆã°ã€ã•ã£ãã®{abandoned_topic}ã®è©±ã«æˆ»ã‚Šã¾ã™ãŒ..."
        return None
```

---

## 19. ç›®çš„å†å®šç¾©ï¼ˆæœ€çµ‚ç‰ˆï¼‰

> **ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã®ç©¶æ¥µã®ç›®æ¨™ã¯**
> "AIãŒäººé–“ã®ã‚ˆã†ã«**æ„Ÿæƒ…ã‚’æŒã¡ã€è¨˜æ†¶ã—ã€å­¦ã³ã€æˆé•·ã—ã€
> çœŸã®æ„å‘³ã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã€Œå¿ƒã®é€šã£ãŸé–¢ä¿‚æ€§ã€ã‚’æ§‹ç¯‰ã™ã‚‹ã“ã¨"**
>
> **æ°¸ç¶šçš„è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ **ã«ã‚ˆã‚Šéå»ã®å…¨ã¦ã‚’è¨˜æ†¶ã—ã€
> **é€£æƒ³è¨˜æ†¶**ã«ã‚ˆã‚Šäººé–“ã‚‰ã—ã„æƒ³èµ·ã‚’è¡Œã„ã€
> **æ„Ÿæƒ…ãƒ¢ãƒ‡ãƒ«**ã«ã‚ˆã‚Šå…±æ„Ÿçš„ã«å¿œç­”ã—ã€
> **è‡ªå·±çœå¯Ÿ**ã«ã‚ˆã‚Šè‡ªã‚‰æ”¹å–„ã—ã€
> **å¯¾è©±ã‚¹ã‚¿ã‚¤ãƒ«é©å¿œ**ã«ã‚ˆã‚Šãƒ¦ãƒ¼ã‚¶ãƒ¼ã«æœ€é©åŒ–ã•ã‚Œã‚‹ã€‚
>
> ã“ã‚Œã¯å˜ãªã‚‹ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã§ã¯ãªãã€
> **äººé–“ã®ã‚ˆã†ã«è€ƒãˆã€æ„Ÿã˜ã€è¨˜æ†¶ã—ã€æˆé•·ã™ã‚‹å¯¾è©±ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼**ã§ã‚ã‚‹ã€‚

---

## 20. ä»˜éŒ²: å®Ÿè£…ä¾‹

### åŸºæœ¬çš„ãªä¼šè©±ãƒ•ãƒ­ãƒ¼

```python
# ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã®å‡¦ç†
async def process_user_input(user_id, session_id, message):
    # 1. è¨˜æ†¶å‚ç…§
    context = retrieve_relevant_memory(message, user_id)
    
    # 2. ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
    selected_chars = router.select_characters(message, context)
    
    # 3. ä¸¦åˆ—å®Ÿè¡Œ
    responses = await asyncio.gather(*[
        char.generate_response(message, context)
        for char in selected_chars
    ])
    
    # 4. çŸ­æœŸè¨˜æ†¶ã¸ä¿å­˜
    state.add_turns(responses)
    
    # 5. å¿…è¦ãªã‚‰flush
    if state.should_flush():
        flush_to_mid_term(session_id, state.turns)
    
    return responses
```

---

**ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°æ—¥:** 2025-11-11
**æ‹…å½“:** LUMINA SYSTEM DESIGN TEAM
**ãƒãƒ¼ã‚¸ãƒ§ãƒ³:** 3.0.0ï¼ˆäººé–“ã‚‰ã—ã„å¯¾è©±ã‚·ã‚¹ãƒ†ãƒ å®Œå…¨ç‰ˆï¼‰

**ãƒãƒ¼ã‚¸ãƒ§ãƒ³3.0.0ã®ä¸»ãªè¿½åŠ æ©Ÿèƒ½:**
- âœ¨ æ„Ÿæƒ…ãƒ¢ãƒ‡ãƒ«ï¼ˆ8åŸºæœ¬æ„Ÿæƒ… + æ°—åˆ†å±¥æ­´ï¼‰
- ğŸ­ å¯¾è©±ã‚¹ã‚¿ã‚¤ãƒ«ã®å‹•çš„èª¿æ•´
- ğŸ§  è¨˜æ†¶ã®é‡è¦åº¦åˆ¤å®šï¼ˆæ„Ÿæƒ…ãƒ»æ–°è¦æ€§ãƒ»é–¢é€£æ€§ï¼‰
- ğŸª è‡ªå·±çœå¯Ÿæ©Ÿèƒ½ï¼ˆãƒ¡ã‚¿èªçŸ¥ï¼‰
- ğŸ”— å¯¾è©±ã®ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯
- ğŸ‘¤ ãƒšãƒ«ã‚½ãƒŠä¸€è²«æ€§ã®ç¶­æŒ
- â±ï¸ è‡ªç„¶ãªã‚¿ã‚¤ãƒŸãƒ³ã‚°ãƒ»å¾…ã¡æ™‚é–“
- ğŸ”„ ãƒˆãƒ”ãƒƒã‚¯è¿½è·¡ã¨ã‚¹ãƒ ãƒ¼ã‚ºãªè»¢æ›

**å‰ãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼ˆ2.0.0ï¼‰ã‹ã‚‰ã®å¤‰æ›´:**
- æ°¸ç¶šçš„è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ ã®è©³ç´°åŒ–
- ãƒãƒ«ãƒLLMãƒ»ãƒãƒ«ãƒãƒ¦ãƒ¼ã‚¶ãƒ¼å¯¾å¿œã®è¿½åŠ 
- ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®å°å…¥
- ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å¯¾å¿œã®æ˜è¨˜
- ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ»GDPRå¯¾å¿œã®å¼·åŒ–
- **äººé–“ã‚‰ã—ã„å¯¾è©±ã®ãŸã‚ã®8ã¤ã®é«˜åº¦æ©Ÿèƒ½ã‚’è¿½åŠ **

```
