# ä¼šè©±LLM é€£æƒ³è¨˜æ†¶ä»•æ§˜æ›¸

**ãƒãƒ¼ã‚¸ãƒ§ãƒ³:** 3.1.0  
**æœ€çµ‚æ›´æ–°:** 2025-11-19  
**è¦ªæ–‡æ›¸:** [ä¼šè©±LLM_ä»•æ§˜.md](./01_ä¼šè©±LLM_ä»•æ§˜.md)

---

## ç›®æ¬¡

1. [æ¦‚è¦](#1-æ¦‚è¦)
2. [é€£æƒ³è¨˜æ†¶ã®æ§‹é€ ](#2-é€£æƒ³è¨˜æ†¶ã®æ§‹é€ )
3. [é€£æƒ³è¨˜æ†¶ã®æ´»ç”¨ä¾‹](#3-é€£æƒ³è¨˜æ†¶ã®æ´»ç”¨ä¾‹)
4. [é€£æƒ³è¨˜æ†¶ã®å­¦ç¿’ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ](#4-é€£æƒ³è¨˜æ†¶ã®å­¦ç¿’ãƒ¡ã‚«ãƒ‹ã‚ºãƒ )
5. [é«˜åº¦ãªæ©Ÿèƒ½](#5-é«˜åº¦ãªæ©Ÿèƒ½)
6. [SQLite Graphå®Ÿè£…](#6-sqlite-graphå®Ÿè£…)
7. [ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–](#7-ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–)

---

## 1. æ¦‚è¦

é€£æƒ³è¨˜æ†¶ã¯ã€æ¦‚å¿µãƒ»ãƒˆãƒ”ãƒƒã‚¯ãƒ»æ„Ÿæƒ…ãƒ»çµŒé¨“ã‚’**ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹é€ **ã§ä¿å­˜ã—ã€äººé–“ã®è„³ã®ã‚ˆã†ã«ã€ŒAã‹ã‚‰Bã‚’æ€ã„å‡ºã™ã€é€£é–çš„ãªè¨˜æ†¶æƒ³èµ·ã‚’å®Ÿç¾ã—ã¾ã™ã€‚

### 1.1 è¨­è¨ˆæ€æƒ³

- **ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹é€ **: ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ã‚ˆã‚‹æ¦‚å¿µã®çµã³ã¤ã
- **é€£é–çš„æƒ³èµ·**: ä¸€ã¤ã®æ¦‚å¿µã‹ã‚‰é–¢é€£æ¦‚å¿µã‚’é€£æƒ³
- **å¼·åº¦å­¦ç¿’**: å…±èµ·é »åº¦ã«åŸºã¥ãé–¢é€£æ€§ã®å¼·åŒ–
- **è‡ªç„¶ãªå¿˜å´**: ä½¿ã‚ãªã„è¨˜æ†¶ã®æ¸›è¡°

### 1.2 ãƒ‡ãƒ¼ã‚¿æ§‹é€ 

```
æ¦‚å¿µãƒãƒ¼ãƒ‰
  â”œâ”€â”€ åå‰
  â”œâ”€â”€ ã‚«ãƒ†ã‚´ãƒª
  â”œâ”€â”€ åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«
  â””â”€â”€ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿

ã‚¨ãƒƒã‚¸(é–¢é€£æ€§)
  â”œâ”€â”€ å¼·åº¦ (0.0-1.0)
  â”œâ”€â”€ å…±èµ·å›æ•°
  â”œâ”€â”€ æœ€çµ‚æ´»æ€§åŒ–æ™‚åˆ»
  â””â”€â”€ é–¢ä¿‚ã‚¿ã‚¤ãƒ—
```

---

## 2. é€£æƒ³è¨˜æ†¶ã®æ§‹é€ 

### 2.1 åŸºæœ¬å®Ÿè£…ï¼ˆSQLite Graphï¼‰

```python
class AssociativeMemory:
    """
    SQLiteã‚°ãƒ©ãƒ•DBã‚’ä½¿ã£ãŸé€£æƒ³è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ 
    ãƒãƒ¼ãƒ‰: æ¦‚å¿µã€ãƒˆãƒ”ãƒƒã‚¯ã€æ„Ÿæƒ…ã€äººç‰©ã€å ´æ‰€
    ã‚¨ãƒƒã‚¸: é–¢é€£æ€§ã€å¼·åº¦ã€æ™‚é–“çš„è¿‘æ¥æ€§
    """
    def __init__(self):
        self.graph_db = SQLiteGraph("memory/associative.db")
        self.vector_db = SQLiteVectorDB("memory/embeddings.db")
    
    def add_concept(self, concept, embedding, metadata):
        """æ–°ã—ã„æ¦‚å¿µã‚’ã‚°ãƒ©ãƒ•ã«è¿½åŠ """
        # VectorDBã«åŸ‹ã‚è¾¼ã¿ä¿å­˜
        self.vector_db.upsert(
            namespace="associative",
            vectors=[{
                "id": concept,
                "values": embedding,
                "metadata": metadata
            }]
        )
        
        # Graph DBã«ãƒãƒ¼ãƒ‰ä½œæˆ
        self.graph_db.create_node(
            label="Concept",
            properties={
                "name": concept,
                "created_at": now(),
                "activation_count": 0,
                "emotional_valence": metadata.get("emotion", 0)
            }
        )
    
    def link_concepts(self, concept_a, concept_b, relationship_type, strength=1.0):
        """2ã¤ã®æ¦‚å¿µã‚’é–¢é€£ä»˜ã‘"""
        self.graph_db.create_relationship(
            from_node=concept_a,
            to_node=concept_b,
            rel_type=relationship_type,
            properties={
                "strength": strength,
                "created_at": now(),
                "co_occurrence_count": 1
            }
        )
    
    def retrieve_associated_concepts(self, trigger_concept, depth=3, threshold=0.5):
        """
        é€£æƒ³æ¤œç´¢: ãƒˆãƒªã‚¬ãƒ¼æ¦‚å¿µã‹ã‚‰é–¢é€£æ¦‚å¿µã‚’é€£é–çš„ã«å–å¾—
        
        Args:
            trigger_concept: èµ·ç‚¹ã¨ãªã‚‹æ¦‚å¿µ
            depth: æ¢ç´¢æ·±åº¦ï¼ˆä½•ãƒ›ãƒƒãƒ—ã¾ã§è¾¿ã‚‹ã‹ï¼‰
            threshold: é–¢é€£æ€§ã®é–¾å€¤
        
        Returns:
            é–¢é€£æ¦‚å¿µã®ãƒªã‚¹ãƒˆã¨é–¢é€£æ€§ã‚¹ã‚³ã‚¢
        """
        # Graph DBã§é€£æƒ³ãƒ‘ã‚¹ã‚’æ¢ç´¢
        query = """
        WITH RECURSIVE graph_walk(node_id, node_name, path_strength, level) AS (
            -- é–‹å§‹ãƒãƒ¼ãƒ‰
            SELECT id, name, 1.0, 0
            FROM nodes
            WHERE name = ?
            
            UNION ALL
            
            -- å†å¸°: æ¬¡ã®ãƒãƒ¼ãƒ‰ã¸
            SELECT 
                n.id,
                n.name,
                gw.path_strength * e.strength,
                gw.level + 1
            FROM graph_walk gw
            JOIN edges e ON gw.node_id = e.from_id
            JOIN nodes n ON e.to_id = n.id
            WHERE gw.level < ?
              AND e.strength >= ?
              AND n.id NOT IN (SELECT node_id FROM graph_walk)
        )
        SELECT DISTINCT node_name, MAX(path_strength) as strength
        FROM graph_walk
        WHERE level > 0
        GROUP BY node_name
        ORDER BY strength DESC
        LIMIT 20
        """
        
        results = self.graph_db.execute(query, (
            trigger_concept, depth, threshold
        ))
        
        return results
    
    def strengthen_association(self, concept_a, concept_b, delta=0.1):
        """
        é–¢é€£æ€§ã‚’å¼·åŒ–ï¼ˆå…±èµ·é »åº¦ã«åŸºã¥ãå­¦ç¿’ï¼‰
        ãƒ˜ãƒƒãƒ–ã®æ³•å‰‡: "ä¸€ç·’ã«ç™ºç«ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¯çµåˆãŒå¼·åŒ–ã•ã‚Œã‚‹"
        """
        self.graph_db.execute("""
            UPDATE edges
            SET strength = MIN(strength + ?, 1.0),
                co_occurrence_count = co_occurrence_count + 1,
                last_activated = ?
            WHERE (from_node = ? AND to_node = ?)
               OR (from_node = ? AND to_node = ?)
        """, (delta, now(), concept_a, concept_b, concept_b, concept_a))
    
    def decay_inactive_associations(self, days_threshold=30, decay_rate=0.05):
        """
        ä½¿ã‚ã‚Œã¦ã„ãªã„é–¢é€£æ€§ã‚’æ¸›è¡°ï¼ˆå¿˜å´æ›²ç·šï¼‰
        """
        cutoff_time = now() - (days_threshold * 86400)
        
        self.graph_db.execute("""
            UPDATE edges
            SET strength = MAX(strength * (1 - ?), 0.0)
            WHERE last_activated < ?
        """, (decay_rate, cutoff_time))
        
        # å¼±ã™ãã‚‹é–¢é€£æ€§ã‚’å‰Šé™¤
        self.graph_db.execute("""
            DELETE FROM edges
            WHERE strength < 0.1
        """)
```

### 2.2 ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒ

```sql
-- ãƒãƒ¼ãƒ‰ãƒ†ãƒ¼ãƒ–ãƒ«
CREATE TABLE IF NOT EXISTS nodes (
    id INTEGER PRIMARY KEY,
    name TEXT UNIQUE,
    type TEXT,
    metadata JSON,
    created_at INTEGER
);

-- ã‚¨ãƒƒã‚¸ãƒ†ãƒ¼ãƒ–ãƒ«
CREATE TABLE IF NOT EXISTS edges (
    id INTEGER PRIMARY KEY,
    from_id INTEGER,
    to_id INTEGER,
    rel_type TEXT,
    strength REAL DEFAULT 1.0,
    co_occurrence INTEGER DEFAULT 1,
    last_activated INTEGER,
    FOREIGN KEY(from_id) REFERENCES nodes(id),
    FOREIGN KEY(to_id) REFERENCES nodes(id)
);

-- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆé«˜é€Ÿæ¤œç´¢ï¼‰
CREATE INDEX IF NOT EXISTS idx_nodes_name ON nodes(name);
CREATE INDEX IF NOT EXISTS idx_edges_from ON edges(from_id);
CREATE INDEX IF NOT EXISTS idx_edges_to ON edges(to_id);
CREATE INDEX IF NOT EXISTS idx_edges_strength ON edges(strength);
```

---

## 3. é€£æƒ³è¨˜æ†¶ã®æ´»ç”¨ä¾‹

### 3.1 ä¼šè©±ä¸­ã®é€£æƒ³ãƒˆãƒªã‚¬ãƒ¼

```python
def generate_associative_response(user_input, conversation_history):
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‹ã‚‰é€£æƒ³çš„ãªè©±é¡Œã‚’å±•é–‹
    """
    # å…¥åŠ›ã‹ã‚‰ä¸»è¦æ¦‚å¿µã‚’æŠ½å‡º
    concepts = extract_concepts(user_input)
    
    # å„æ¦‚å¿µã‹ã‚‰é€£æƒ³æ¤œç´¢
    all_associations = []
    for concept in concepts:
        associations = associative_memory.retrieve_associated_concepts(
            trigger_concept=concept,
            depth=2,
            threshold=0.3
        )
        all_associations.extend(associations)
    
    # æœ€ã‚‚å¼·ã„é€£æƒ³ã‚’é¸æŠ
    top_association = max(all_associations, key=lambda x: x["strength"])
    
    # é€£æƒ³ã«åŸºã¥ãå¿œç­”ç”Ÿæˆ
    prompt = f"""
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã€Œ{user_input}ã€ã¨è¨€ã„ã¾ã—ãŸã€‚
    ã“ã‚Œã¯ã€Œ{top_association['concept']}ã€ã‚’é€£æƒ³ã•ã›ã¾ã™ã€‚
    è‡ªç„¶ãªä¼šè©±ã®æµã‚Œã§ã€ã“ã®é€£æƒ³ã«è§¦ã‚ŒãŸè¿”ç­”ã‚’ã—ã¦ãã ã•ã„ã€‚
    """
    
    return generate_response(prompt)
```

### 3.2 å‰µé€ çš„ç™ºæƒ³æ”¯æ´

```python
def brainstorm_ideas(seed_concept, num_ideas=10):
    """
    é€£æƒ³è¨˜æ†¶ã‚’ä½¿ã£ãŸãƒ–ãƒ¬ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒŸãƒ³ã‚°
    """
    ideas = set()
    frontier = [seed_concept]
    
    while len(ideas) < num_ideas and frontier:
        current = frontier.pop(0)
        
        # é€£æƒ³æ¤œç´¢
        associations = associative_memory.retrieve_associated_concepts(
            trigger_concept=current,
            depth=1,
            threshold=0.2
        )
        
        for assoc in associations:
            if assoc["concept"] not in ideas:
                ideas.add(assoc["concept"])
                frontier.append(assoc["concept"])
                
                if len(ideas) >= num_ideas:
                    break
    
    return list(ideas)
```

### 3.3 è©±é¡Œè»¢æ›ã®è‡ªç„¶ã•åˆ¤å®š

```python
def evaluate_topic_transition(topic_from, topic_to):
    """
    2ã¤ã®è©±é¡Œé–“ã®é€£æƒ³çš„ã¤ãªãŒã‚Šã‚’è©•ä¾¡
    """
    # æœ€çŸ­ãƒ‘ã‚¹ã‚’æ¢ç´¢
    path = associative_memory.graph_db.execute("""
        WITH RECURSIVE path_search(node, path, distance) AS (
            SELECT id, name, 0
            FROM nodes
            WHERE name = ?
            
            UNION ALL
            
            SELECT n.id, n.name, ps.distance + 1
            FROM path_search ps
            JOIN edges e ON ps.node = e.from_id
            JOIN nodes n ON e.to_id = n.id
            WHERE ps.distance < 5
              AND n.name = ?
        )
        SELECT MIN(distance) as shortest
        FROM path_search
        WHERE path = ?
    """, (topic_from, topic_to, topic_to))
    
    if not path or path[0]["shortest"] is None:
        return 0.0  # é–¢é€£æ€§ãªã—
    
    distance = path[0]["shortest"]
    # è·é›¢ãŒè¿‘ã„ã»ã©é«˜ã‚¹ã‚³ã‚¢
    score = 1.0 / (1.0 + distance)
    
    return score
```

---

## 4. é€£æƒ³è¨˜æ†¶ã®å­¦ç¿’ãƒ¡ã‚«ãƒ‹ã‚ºãƒ 

### 4.1 ä¼šè©±ã‹ã‚‰ã®å­¦ç¿’

```python
def learn_from_conversation(conversation):
    """
    ä¼šè©±ã‹ã‚‰æ¦‚å¿µã¨é–¢é€£æ€§ã‚’å­¦ç¿’
    """
    # ä¼šè©±ã‹ã‚‰æ¦‚å¿µæŠ½å‡º
    concepts = extract_concepts_from_text(conversation)
    
    # æ™‚é–“çš„è¿‘æ¥æ€§ã«åŸºã¥ãé–¢é€£ä»˜ã‘
    for i, concept_a in enumerate(concepts):
        # å‰å¾Œã®æ¦‚å¿µã¨é–¢é€£ä»˜ã‘ï¼ˆå…±èµ·å­¦ç¿’ï¼‰
        window = concepts[max(0, i-3):min(len(concepts), i+4)]
        
        for concept_b in window:
            if concept_a != concept_b:
                # è¿‘ã„ã»ã©å¼·ã„é–¢é€£æ€§
                distance = abs(concepts.index(concept_a) - concepts.index(concept_b))
                strength = 1.0 / (1.0 + distance * 0.3)
                
                # æ—¢å­˜ã®é–¢é€£æ€§ã‚’å¼·åŒ–ã€ã¾ãŸã¯æ–°è¦ä½œæˆ
                existing_rel = associative_memory.get_relationship(concept_a, concept_b)
                
                if existing_rel:
                    associative_memory.strengthen_association(
                        concept_a, concept_b, delta=strength * 0.1
                    )
                else:
                    associative_memory.link_concepts(
                        concept_a, concept_b,
                        relationship_type="CO_OCCURRED",
                        strength=strength
                    )
    
    # æ„Ÿæƒ…çš„é–¢é€£ã®å­¦ç¿’
    emotion = analyze_emotion(conversation)
    for concept in concepts:
        associative_memory.update_emotional_valence(concept, emotion)
```

### 4.2 ãƒ˜ãƒƒãƒ–ã®æ³•å‰‡

> **"ä¸€ç·’ã«ç™ºç«ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¯çµåˆãŒå¼·åŒ–ã•ã‚Œã‚‹"**

```python
def hebbian_learning(concept_a, concept_b, activation_strength):
    """
    ãƒ˜ãƒƒãƒ–å­¦ç¿’å‰‡ã®å®Ÿè£…
    """
    # ä¸¡æ¦‚å¿µãŒåŒæ™‚ã«æ´»æ€§åŒ–ã—ãŸã‚‰å¼·åŒ–
    delta = activation_strength * 0.1
    
    associative_memory.strengthen_association(
        concept_a, concept_b, delta=delta
    )
```

---

## 5. é«˜åº¦ãªæ©Ÿèƒ½

### 5.1 æ„Ÿæƒ…ã‚’ä¼´ã†è¨˜æ†¶ã®å„ªå…ˆæƒ³èµ·

```python
def retrieve_emotional_memory(query, emotion_filter="positive", top_k=5):
    """
    ç‰¹å®šã®æ„Ÿæƒ…ã«é–¢é€£ã™ã‚‹è¨˜æ†¶ã‚’å„ªå…ˆçš„ã«æƒ³èµ·
    """
    query_embedding = create_embedding(query)
    
    # VectorDBã§é¡ä¼¼æ¤œç´¢
    candidates = vector_db.query(
        namespace="associative",
        vector=query_embedding,
        top_k=top_k * 3,
        include_metadata=True
    )
    
    # æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ã§å†ãƒ©ãƒ³ã‚­ãƒ³ã‚°
    filtered = [
        c for c in candidates
        if c["metadata"]["emotion"] == emotion_filter
    ]
    
    # Graph DBã§é–¢é€£æ€§ã‚’ç¢ºèª
    enriched = []
    for candidate in filtered[:top_k]:
        associations = associative_memory.retrieve_associated_concepts(
            trigger_concept=candidate["id"],
            depth=1,
            threshold=0.4
        )
        enriched.append({
            "concept": candidate["id"],
            "associations": associations,
            "emotion": candidate["metadata"]["emotion"]
        })
    
    return enriched
```

### 5.2 è¨˜æ†¶ã®æƒ³èµ·ãƒˆãƒªã‚¬ãƒ¼

| æ©Ÿèƒ½ | èª¬æ˜ | å®Ÿè£…æ–¹æ³• |
|------|------|----------|
| **è©±é¡Œã®è‡ªç„¶ãªå±•é–‹** | é€£æƒ³ã«ã‚ˆã‚‹è©±é¡Œè»¢æ› | Graphæ¢ç´¢ã§é–¢é€£ãƒˆãƒ”ãƒƒã‚¯ç™ºè¦‹ |
| **å‰µé€ çš„ç™ºæƒ³** | æ„å¤–ãªçµ„ã¿åˆã‚ã›ã®ææ¡ˆ | é è·é›¢ãƒãƒ¼ãƒ‰ã®ãƒ–ãƒªãƒƒã‚¸æ¤œç´¢ |
| **è¨˜æ†¶ã®æƒ³èµ·** | ã€Œãã†ã„ãˆã°å‰ã«...ã€ | é¡ä¼¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰ã®é€£æƒ³æ¤œç´¢ |
| **æ–‡è„ˆç†è§£ã®æ·±åŒ–** | æš—é»™ã®å‰æã‚’è£œå®Œ | æ¦‚å¿µé–“ã®é–¢ä¿‚æ€§æ¨è«– |
| **æ„Ÿæƒ…çš„è¨˜æ†¶** | æ„Ÿæƒ…ã‚’ä¼´ã†è¨˜æ†¶ã®å„ªå…ˆæƒ³èµ· | Emotional Valenceã«ã‚ˆã‚‹é‡ã¿ä»˜ã‘ |
| **å¿˜å´ã¨å†å­¦ç¿’** | ä½¿ã‚ãªã„è¨˜æ†¶ã®è‡ªç„¶ãªæ¸›è¡° | Time-based Decay + å†æ´»æ€§åŒ– |

---

## 6. SQLite Graphå®Ÿè£…

### 6.1 è»½é‡ã‚°ãƒ©ãƒ•DB

```python
class SQLiteGraph:
    """Neo4jä¸è¦ã®è»½é‡ã‚°ãƒ©ãƒ•DB"""
    
    def __init__(self, db_path):
        self.conn = sqlite3.connect(db_path)
        self._create_schema()
    
    def _create_schema(self):
        """ã‚°ãƒ©ãƒ•ã‚¹ã‚­ãƒ¼ãƒä½œæˆ"""
        self.conn.executescript("""
            -- ãƒãƒ¼ãƒ‰ãƒ†ãƒ¼ãƒ–ãƒ«
            CREATE TABLE IF NOT EXISTS nodes (
                id INTEGER PRIMARY KEY,
                name TEXT UNIQUE,
                type TEXT,
                metadata JSON,
                created_at INTEGER
            );
            
            -- ã‚¨ãƒƒã‚¸ãƒ†ãƒ¼ãƒ–ãƒ«
            CREATE TABLE IF NOT EXISTS edges (
                id INTEGER PRIMARY KEY,
                from_id INTEGER,
                to_id INTEGER,
                rel_type TEXT,
                strength REAL DEFAULT 1.0,
                co_occurrence INTEGER DEFAULT 1,
                last_activated INTEGER,
                FOREIGN KEY(from_id) REFERENCES nodes(id),
                FOREIGN KEY(to_id) REFERENCES nodes(id)
            );
            
            -- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆé«˜é€Ÿæ¤œç´¢ï¼‰
            CREATE INDEX IF NOT EXISTS idx_nodes_name ON nodes(name);
            CREATE INDEX IF NOT EXISTS idx_edges_from ON edges(from_id);
            CREATE INDEX IF NOT EXISTS idx_edges_to ON edges(to_id);
            CREATE INDEX IF NOT EXISTS idx_edges_strength ON edges(strength);
        """)
    
    def find_associated_concepts(self, start_concept, depth=3, threshold=0.5):
        """é€£æƒ³æ¤œç´¢ï¼ˆå†å¸°CTEä½¿ç”¨ï¼‰"""
        query = """
        WITH RECURSIVE graph_walk(node_id, node_name, path_strength, level) AS (
            -- é–‹å§‹ãƒãƒ¼ãƒ‰
            SELECT id, name, 1.0, 0
            FROM nodes
            WHERE name = ?
            
            UNION ALL
            
            -- å†å¸°: æ¬¡ã®ãƒãƒ¼ãƒ‰ã¸
            SELECT 
                n.id,
                n.name,
                gw.path_strength * e.strength,
                gw.level + 1
            FROM graph_walk gw
            JOIN edges e ON gw.node_id = e.from_id
            JOIN nodes n ON e.to_id = n.id
            WHERE gw.level < ?
              AND e.strength >= ?
              AND n.id NOT IN (SELECT node_id FROM graph_walk)
        )
        SELECT DISTINCT node_name, MAX(path_strength) as strength
        FROM graph_walk
        WHERE level > 0
        GROUP BY node_name
        ORDER BY strength DESC
        LIMIT 20
        """
        
        cursor = self.conn.execute(query, (start_concept, depth, threshold))
        return cursor.fetchall()
```

### 6.2 Neo4j vs SQLite Graphæ¯”è¼ƒ

| é …ç›® | Neo4j | SQLite Graph |
|------|-------|-------------|
| **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹** | âš¡âš¡âš¡ 50-200ms | âš¡âš¡âš¡ 10-50ms |
| **ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡** | ğŸ§  2GB+ | ğŸ§  50-100MB |
| **ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡** | ğŸ’¾ 1GB+ | ğŸ’¾ 20-100MB |
| **ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—** | â­â­â­ è¤‡é›‘ | â­ ç°¡å˜ |
| **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£** | æ•°ç™¾ä¸‡ãƒãƒ¼ãƒ‰ | æ•°ä¸‡ãƒãƒ¼ãƒ‰ |

**æ¨å¥¨: SQLite Graphï¼ˆååˆ†ãªæ€§èƒ½ï¼‹è¶…è»½é‡ï¼‰**

---

## 7. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### 7.1 æœ€é©åŒ–æˆ¦ç•¥

```python
class OptimizedAssociativeMemory(AssociativeMemory):
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ç‰ˆ"""
    
    def __init__(self):
        super().__init__()
        self.cache = LRUCache(maxsize=1000)
    
    def retrieve_associated_concepts_cached(self, trigger, depth, threshold):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãé€£æƒ³æ¤œç´¢"""
        cache_key = f"{trigger}:{depth}:{threshold}"
        
        if cache_key in self.cache:
            return self.cache[cache_key]
        
        result = self.retrieve_associated_concepts(trigger, depth, threshold)
        self.cache[cache_key] = result
        
        return result
    
    def batch_strengthen(self, concept_pairs, delta=0.1):
        """ãƒãƒƒãƒå‡¦ç†ã§é–¢é€£æ€§å¼·åŒ–"""
        query = """
            UPDATE edges
            SET strength = MIN(strength + ?, 1.0),
                co_occurrence_count = co_occurrence_count + 1
            WHERE (from_node = ? AND to_node = ?)
               OR (from_node = ? AND to_node = ?)
        """
        
        self.graph_db.executemany(query, [
            (delta, a, b, b, a) for a, b in concept_pairs
        ])
        self.graph_db.commit()
```

### 7.2 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›®æ¨™

| æ“ä½œ | ç›®æ¨™æ™‚é–“ | å®Ÿæ¸¬æ™‚é–“ |
|------|---------|----------|
| é€£æƒ³æ¤œç´¢ï¼ˆæ·±åº¦3ï¼‰ | < 50ms | 10-30ms |
| æ¦‚å¿µè¿½åŠ  | < 5ms | 2-3ms |
| é–¢é€£æ€§å¼·åŒ– | < 3ms | 1-2ms |
| æ¸›è¡°å‡¦ç†ï¼ˆå…¨ä½“ï¼‰ | < 1ç§’ | 0.5-0.8ç§’ |

---

## é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

- **è¦ªæ–‡æ›¸**: [ä¼šè©±LLM_ä»•æ§˜.md](./01_ä¼šè©±LLM_ä»•æ§˜.md)
- **è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ **: [ä¼šè©±LLM_è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ ä»•æ§˜.md](./02_ä¼šè©±LLM_è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ ä»•æ§˜.md)
- **ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼**: [ä¼šè©±LLM_ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ä»•æ§˜.md](./03_ä¼šè©±LLM_ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ä»•æ§˜.md)
- **æ„Ÿæƒ…ãƒ»å¯¾è©±**: [ä¼šè©±LLM_æ„Ÿæƒ…ãƒ»å¯¾è©±ä»•æ§˜.md](./04_ä¼šè©±LLM_æ„Ÿæƒ…ãƒ»å¯¾è©±ä»•æ§˜.md)
- **3Då¯è¦–åŒ–**: [ä¼šè©±LLM_3Då¯è¦–åŒ–ä»•æ§˜.md](./06_ä¼šè©±LLM_3Då¯è¦–åŒ–ä»•æ§˜.md)

---

**æ–‡æ›¸ãƒãƒ¼ã‚¸ãƒ§ãƒ³:** 3.1.0  
**æœ€çµ‚æ›´æ–°:** 2025-11-19
