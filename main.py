"""
main.py
LangGraphãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³

ãƒãƒ«ãƒLLMä¼šè©±ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ¡ã‚¤ãƒ³ãƒ•ãƒ­ãƒ¼åˆ¶å¾¡ã€‚
LangGraphã‚’ä½¿ç”¨ã—ã¦å„ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒãƒ¼ãƒ‰ã‚’æ¥ç¶šã—ã€ä¼šè©±ãƒ•ãƒ­ãƒ¼ã‚’ç®¡ç†ã€‚
"""

from langgraph.graph import StateGraph, END
from typing import Dict, Any, TypedDict, Annotated
from datetime import datetime
import operator

from config import Config
from conversation_state import ConversationState
from llm_nodes import LuminaNode, ClarisNode, NoxNode, RouterNode
from memory_manager import MemorySystemManager
from exceptions import LLMNodeError
from metrics import get_metrics_collector


class GraphState(TypedDict):
    """LangGraphã®çŠ¶æ…‹å‹å®šç¾©"""
    user_input: str
    history: Annotated[list, operator.add]
    current_turn: int
    max_turns: int
    last_speaker: str
    next_character: str
    session_id: str
    start_time: str


class MultiLLMChat:
    """ãƒãƒ«ãƒLLMä¼šè©±ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.config = Config()
        self.conv_state = ConversationState()
        
        # è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
        self.memory = MemorySystemManager()
        self.memory.initialize_characters()
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã®åˆæœŸåŒ–
        self.metrics = get_metrics_collector()
        self.metrics.record_session_start()
        
        # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒãƒ¼ãƒ‰ã®åˆæœŸåŒ–
        self.lumina_node = LuminaNode(self.config)
        self.claris_node = ClarisNode(self.config)
        self.nox_node = NoxNode(self.config)
        self.router_node = RouterNode(self.config)
        
        # LangGraphã®æ§‹ç¯‰
        self.graph = self._build_graph()
        self.compiled_graph = self.graph.compile()
    
    def _build_graph(self) -> StateGraph:
        """LangGraphã®ãƒ•ãƒ­ãƒ¼æ§‹ç¯‰"""
        
        # ã‚°ãƒ©ãƒ•ã®å®šç¾©
        workflow = StateGraph(GraphState)
        
        # ãƒãƒ¼ãƒ‰ã®è¿½åŠ 
        workflow.add_node("router", self._router_node)
        workflow.add_node("lumina", self._lumina_node)
        workflow.add_node("claris", self._claris_node)
        workflow.add_node("nox", self._nox_node)
        workflow.add_node("check_continue", self._check_continue)
        
        # ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
        workflow.set_entry_point("router")
        
        # ãƒ«ãƒ¼ã‚¿ãƒ¼ã‹ã‚‰å„ã‚­ãƒ£ãƒ©ã¸ã®æ¡ä»¶ä»˜ãã‚¨ãƒƒã‚¸
        workflow.add_conditional_edges(
            "router",
            self._route_decision,
            {
                "lumina": "lumina",
                "claris": "claris",
                "nox": "nox"
            }
        )
        
        # å„ã‚­ãƒ£ãƒ©ã‹ã‚‰ç¶™ç¶šãƒã‚§ãƒƒã‚¯ã¸
        workflow.add_edge("lumina", "check_continue")
        workflow.add_edge("claris", "check_continue")
        workflow.add_edge("nox", "check_continue")
        
        # ç¶™ç¶šãƒã‚§ãƒƒã‚¯ã‹ã‚‰ã®åˆ†å²
        workflow.add_conditional_edges(
            "check_continue",
            self._should_continue,
            {
                "continue": END,
                "end": END
            }
        )
        
        return workflow
    
    def _router_node(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """ãƒ«ãƒ¼ã‚¿ãƒ¼ãƒãƒ¼ãƒ‰å‡¦ç†"""
        return self.router_node.decide_next(state)
    
    def _lumina_node(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """ãƒ«ãƒŸãƒŠãƒãƒ¼ãƒ‰å‡¦ç†ï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãï¼‰"""
        try:
            return self.lumina_node.generate(state)
        except LLMNodeError as e:
            self.memory.logger.log_error(e, context="lumina_node")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ãƒ•ãƒ­ãƒ¼ã‚’ç¶™ç¶šï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”ï¼‰
            return {
                **state,
                "history": state.get("history", []) + [{
                    "speaker": "system",
                    "msg": "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚ãƒ«ãƒŸãƒŠã®å¿œç­”ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚",
                    "timestamp": datetime.now().isoformat()
                }]
            }
    
    def _claris_node(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """ã‚¯ãƒ©ãƒªã‚¹ãƒãƒ¼ãƒ‰å‡¦ç†ï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãï¼‰"""
        try:
            return self.claris_node.generate(state)
        except LLMNodeError as e:
            self.memory.logger.log_error(e, context="claris_node")
            return {
                **state,
                "history": state.get("history", []) + [{
                    "speaker": "system",
                    "msg": "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚ã‚¯ãƒ©ãƒªã‚¹ã®å¿œç­”ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚",
                    "timestamp": datetime.now().isoformat()
                }]
            }
    
    def _nox_node(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """ãƒã‚¯ã‚¹ãƒãƒ¼ãƒ‰å‡¦ç†ï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãï¼‰"""
        try:
            return self.nox_node.generate(state)
        except LLMNodeError as e:
            self.memory.logger.log_error(e, context="nox_node")
            return {
                **state,
                "history": state.get("history", []) + [{
                    "speaker": "system",
                    "msg": "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚ãƒã‚¯ã‚¹ã®å¿œç­”ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚",
                    "timestamp": datetime.now().isoformat()
                }]
            }
    
    def _route_decision(self, state: Dict[str, Any]) -> str:
        """ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æ±ºå®š"""
        return state.get('next_character', 'lumina')
    
    def _check_continue(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """ç¶™ç¶šãƒã‚§ãƒƒã‚¯"""
        state['current_turn'] = state.get('current_turn', 0) + 1
        return state
    
    def _should_continue(self, state: Dict[str, Any]) -> str:
        """ä¼šè©±ã‚’ç¶™ç¶šã™ã¹ãã‹åˆ¤å®š"""
        current_turn = state.get('current_turn', 0)
        max_turns = state.get('max_turns', self.config.system.max_turns)
        
        if current_turn >= max_turns:
            return "end"
        return "continue"
    
    def chat(self, user_input: str, session_id: str = None, user_id: str = None) -> Dict[str, Any]:
        """
        ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’å‡¦ç†ã—ã¦å¿œç­”ã‚’ç”Ÿæˆ
        
        Args:
            user_input: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
            session_id: ã‚»ãƒƒã‚·ãƒ§ãƒ³IDï¼ˆçœç•¥æ™‚: å†…éƒ¨ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’ä½¿ç”¨ï¼‰
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼IDï¼ˆPhase 3çµ±åˆç”¨ã€çœç•¥å¯èƒ½ï¼‰
            
        Returns:
            å¿œç­”ã‚’å«ã‚€çŠ¶æ…‹è¾æ›¸
        """
        # å…¥åŠ›æ¤œè¨¼
        from validators import InputValidator
        try:
            user_input = InputValidator.validate_user_input(user_input)
        except Exception as e:
            self.memory.logger.log_error(e, context="chat_input_validation")
            return {
                "response": f"å…¥åŠ›æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {str(e)}",
                "speaker": "system",
                "turn": self.conv_state.current_turn,
                "session_id": self.conv_state.session_id
            }
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã®å‡¦ç†ï¼ˆå¤–éƒ¨æŒ‡å®š or å†…éƒ¨ç®¡ç†ï¼‰
        if session_id:
            # Phase 3çµ±åˆ: å¤–éƒ¨æŒ‡å®šã®ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’ä½¿ç”¨
            if self.conv_state.session_id != session_id:
                # æ–°è¦ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¾ãŸã¯ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ‡æ›¿
                self.conv_state.session_id = session_id
                if not self.conv_state.history:
                    self.conv_state.start_new_session()
        else:
            # Phase 1äº’æ›: å†…éƒ¨ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’ä½¿ç”¨
            if not self.conv_state.history:
                self.conv_state.start_new_session()
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’å±¥æ­´ã«è¿½åŠ 
        self.conv_state.add_turn("User", user_input)
        
        # ã‚°ãƒ©ãƒ•çŠ¶æ…‹ã®æ§‹ç¯‰
        initial_state: GraphState = {
            "user_input": user_input,
            "history": self.conv_state.history.copy(),
            "current_turn": self.conv_state.current_turn,
            "max_turns": getattr(self.config, 'max_turns', 12),
            "last_speaker": self.conv_state.last_speaker or "",
            "next_character": "",
            "session_id": self.conv_state.session_id,
            "start_time": self.conv_state.start_time.isoformat()
        }
        
        # ã‚°ãƒ©ãƒ•å®Ÿè¡Œ
        result = self.compiled_graph.invoke(initial_state)
        
        # ä¼šè©±çŠ¶æ…‹ã®æ›´æ–°
        self.conv_state.history = result['history']
        self.conv_state.current_turn = result['current_turn']
        self.conv_state.last_speaker = result['last_speaker']
        
        # è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ ã«ä¼šè©±ã‚¿ãƒ¼ãƒ³ã‚’ä¿å­˜
        last_response = result['history'][-1] if result['history'] else None
        if last_response:
            self.memory.add_conversation_turn(
                session_id=result['session_id'],
                speaker=last_response['speaker'],
                content=last_response['msg'],
                metadata={
                    'turn': result['current_turn'],
                    'user_input': user_input
                }
            )
        
        return {
            "response": last_response['msg'] if last_response else "",
            "speaker": last_response['speaker'] if last_response else "",
            "turn": result['current_turn'],
            "session_id": result['session_id']
        }
    
    def reset_conversation(self):
        """ä¼šè©±çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ"""
        # ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä¿å­˜
        if self.conv_state.session_id:
            self.memory.save_session(self.conv_state.session_id)
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›
        print("\n" + self.metrics.get_performance_report())
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        self.metrics.record_session_end()
        filepath = self.metrics.export_to_json()
        print(f"\nãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ: {filepath}")
        
        # HTMLãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”Ÿæˆ
        from dashboard import generate_html_report
        html_path = generate_html_report(self.metrics.get_summary())
        print(f"HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ: {html_path}")
        
        # æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹
        self.conv_state = ConversationState()
        self.metrics.reset()
        self.metrics.record_session_start()
        print("ä¼šè©±ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸã€‚")
    
    def get_history(self) -> list:
        """ä¼šè©±å±¥æ­´ã‚’å–å¾—"""
        return self.conv_state.history
    
    def export_conversation(self, filename: str = None):
        """ä¼šè©±å±¥æ­´ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        return self.conv_state.export_to_json(filename)


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("=" * 60)
    print("ğŸŒ ä¼šè©±LLM - ãƒãƒ«ãƒLLMä¼šè©±ã‚·ã‚¹ãƒ†ãƒ  v3.0")
    print("=" * 60)
    print()
    print("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼:")
    print("  - ãƒ«ãƒŸãƒŠï¼ˆå¸ä¼šãƒ»é›‘è«‡ï¼‰")
    print("  - ã‚¯ãƒ©ãƒªã‚¹ï¼ˆè§£èª¬ãƒ»ç†è«–ï¼‰")
    print("  - ãƒã‚¯ã‚¹ï¼ˆæ¤œè¨¼ãƒ»è¦ç´„ãƒ»æ¤œç´¢ï¼‰")
    print()
    print("ã‚³ãƒãƒ³ãƒ‰:")
    print("  /reset   - ä¼šè©±ã‚’ãƒªã‚»ãƒƒãƒˆ")
    print("  /export  - ä¼šè©±å±¥æ­´ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
    print("  /history - ä¼šè©±å±¥æ­´ã‚’è¡¨ç¤º")
    print("  /memory  - è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ ã‚µãƒãƒªãƒ¼")
    print("  /quit    - çµ‚äº†")
    print()
    print("=" * 60)
    print()
    
    # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    chat_system = MultiLLMChat()
    
    # ä¼šè©±ãƒ«ãƒ¼ãƒ—
    while True:
        try:
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
            user_input = input("You: ").strip()
            
            if not user_input:
                continue
            
            # ã‚³ãƒãƒ³ãƒ‰å‡¦ç†
            if user_input.startswith('/'):
                command = user_input[1:].lower()
                
                if command == 'quit':
                    print("\nä¼šè©±ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                    break
                elif command == 'reset':
                    chat_system.reset_conversation()
                    continue
                elif command == 'export':
                    filename = chat_system.export_conversation()
                    print(f"ä¼šè©±å±¥æ­´ã‚’ {filename} ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã¾ã—ãŸã€‚")
                    continue
                elif command == 'history':
                    history = chat_system.get_history()
                    print("\n=== ä¼šè©±å±¥æ­´ ===")
                    for turn in history:
                        print(f"{turn['speaker']}: {turn['msg']}")
                    print("=" * 60)
                    continue
                elif command == 'memory':
                    stats = chat_system.memory.get_statistics()
                    print("\n=== è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ ã‚µãƒãƒªãƒ¼ ===")
                    print(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°: {stats['sessions']['total']}")
                    print(f"ä¼šè©±ã‚¿ãƒ¼ãƒ³æ•°: {stats['conversations']['total']}")
                    print(f"çŸ¥è­˜ãƒ™ãƒ¼ã‚¹é …ç›®æ•°: {stats['knowledge']['total']}")
                    print("\nã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æˆé•·:")
                    for char in ['lumina', 'claris', 'nox']:
                        kpi = stats['characters'].get(char, {})
                        print(f"  {char.capitalize()}: Lv{kpi.get('level', 0)} (KPI: {kpi.get('total_kpi', 0)})")
                    print("=" * 60)
                    continue
                else:
                    print(f"ä¸æ˜ãªã‚³ãƒãƒ³ãƒ‰: /{command}")
                    continue
            
            # é€šå¸¸ã®ä¼šè©±å‡¦ç†
            response = chat_system.chat(user_input)
            print(f"\n{response['speaker']}: {response['response']}\n")
            
        except KeyboardInterrupt:
            print("\n\nä¼šè©±ã‚’ä¸­æ–­ã—ã¾ã—ãŸã€‚")
            break
        except Exception as e:
            print(f"\nã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            continue
    
    # çµ‚äº†æ™‚ã®å‡¦ç†
    print("\nè¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ ã‚’ä¿å­˜ä¸­...")
    chat_system.memory.save_all_sessions()
    print("ä¿å­˜å®Œäº†ã€‚ã¾ãŸãŠä¼šã„ã—ã¾ã—ã‚‡ã†ï¼")


if __name__ == "__main__":
    main()
